number,id,title,author,advisor,year,abstract,university,degree,URI,department,discipline,language,schooltype,oadsclassifier,borndigital
0,1436,Plasma Diagnostics and Plasma-Surface Interactions in Inductively Coupled Plasmas,"Titus, Monica Joy","Graves, David B;",2010,"The semiconductor industry's continued trend of manufacturing device features on the nanometer scale requires increased plasma processing control and improved understanding of plasma characteristics and plasma-surface interactions. This dissertation presents a series of experimental results for focus studies conducted in an inductively coupled plasma (ICP) system. First novel ""on-wafer"" diagnostic tools are characterized and related to plasma characteristics. Second, plasma-polymer interactions are characterized as a function of plasma species and processing parameters. Complimentary simulations accompany each focus study to supplement experimental findings.Wafer heating mechanisms in inductively coupled molecular gas plasmas are explored with PlasmaTempTM, a novel ""on-wafer"" diagnostic tool. Experimental wafer measurements are obtained with the PlasmaTempTM wafer processed in argon (Ar) and argon-oxygen (Ar/O2) mixed plasmas. Wafer heating mechanisms were determined by combining the experimental measurements with a 3-dimensional heat transfer model of the wafer.  Comparisons between pure Ar and Ar/O2 plasmas demonstrate that two additional wafer heating mechanisms can be important in molecular gas plasmas compared to atomic gas discharges.  Thermal heat conduction from the neutral gas and O-atom recombination on wafer surface can contribute as much as 60 % to wafer heating under conditions of low-energy ion bombardment in molecular plasmas.Measurements of a second novel ""on-wafer"" diagnostic sensor, the PlasmaVoltTM, were tested and validated in the ICP system for Ar plasmas varying in power and pressure. Sensor measurements were interpreted with a numerical sheath simulation and comparison to scaling laws derived from the inhomogeneous sheath model. The study demonstrates sensor measurements are proportional to the RF-current through the sheath and the scaling is a function of sheath impedance. PlasmaVoltTM sensor measurements are proportional to the square root of the plasma density at the plasma-sheath interface, one-fourth root of the electron temperature, and one-fourth root of the RF bias voltage under conditions where the sheath is predominantly capacitive. When the sheath impedance becomes increasingly resistive, the sensor measurements deviate from the scaling law and tend to be directly proportional to the plasma density. Vacuum ultraviolet (VUV) emissions in Ar ICPs are characterized and the chemical and physical modifications to 193 nm photoresist (PR) polymer materials processed in Ar ICPs are investigated. Fourier transform infrared (FTIR) transmission measurements as a function of VUV photon fluence demonstrate that VUV-induced bond breaking occurs over a period of time.  A numerical model demonstrates that VUV photons deplete near-surface O-containing bonds, leading to deeper, subsequent penetration and more bond losses, while the remaining near-surface C-C bonds absorb the incident radiation and slow VUV photon penetration. The roughening mechanism of blanket and patterned 193 nm PR samples are explored in a well characterized Ar ICP.  FTIR and atomic force microscopy (AFM) analysis of plasma processed 193 nm PR suggests that ion-induced generation of a graphitized layer at high energies, combined with VUV bulk modification of 193 nm PR may initiate PR roughening. The roughness of blanket samples increases as a function of VUV fluence, ion energy, and substrate temperature.  Line width roughness (LWR) measurements of patterned samples demonstrate a similar trend suggesting that LWR may correlate with surface roughness of patterns. The results are compared to PR studies previously conducted in an ultra-high vacuum beam system demonstrating that the vacuum beam system is a useful tool that can deconvolute and simplify complex plasma systems.",ucb,,https://escholarship.org/uc/item/0hn5z4f1,,,eng,REGULAR,0,0
1,1437,Declarative Systems,"Condie, Tyson","Hellerstein, Joseph M;",2011,"Building system software is a notoriously complex and arduous endeavor.Developing tools and methodologies for practical system software engineeringhas long been an active area of research.  This thesis explores system softwaredevelopment through the lens of a declarative, data-centric programminglanguage that can succinctly express high-level system specifications and bedirectly compiled to executable code.  By unifying specification andimplementation, our approach avoids the common problem of implementationsdiverging from specifications over time.  In addition, we show that using adeclarative language often results in drastic reductions in code size (100Ã— andmore) relative to procedural languages like Java and C++.  We demonstrate theseadvantages by implementing a host of functionalities at various levels of thesystem hierarchy, including network protocols, query optimizers, and schedulingpolicies.  In addition to providing a compact and optimized implementation, wedemonstrate that our declarative implementations often map very naturally totraditional specifications: in many cases they are line-by-line translations ofpublished pseudcode.We started this work with the hypothesis that declarative languages --originally developed for the purposes of data management and querying -- couldbe fruitfully adapted to the specification and implementation of core systeminfrastructure.  A similar argument had been made for networking protocols afew years earlier [61].  However, our goals were quite different: we wanted toexplore a broader range of algorithms and functionalities (dynamic programming,scheduling, program rewriting, and system auditing) that were part of complex,real-world software systems.  We identified two existing system components --query optimizers in a DBMS and task schedulers in a cloud computing system --that we felt would be better specified via a declarative language.  Given ourinterest in delivering real-world software, a key challenge was identifying theright system boundary that would permit meaningful declarative implementationsto coexist within existing imperative system architectures.  We found thatrelations were a natural boundary for maintaining the ongoing system state onwhich the imperative and declarative code was based, and provided an elegantway to model system architectures.This thesis explores the boundaries of declarative systems via two projects.We begin with Evita Raced; an extensible compiler for the Overlog language usedin our declarative networking system, P2.  Evita Raced is a metacompiler -- anOverlog compiler written in Overlog -- that integrates seamlessly with the P2dataflow architecture.  We first describe the minimalist design of Evita Raced,including its extensibility interfaces and its reuse of the P2 data model andruntime engine.  We then demonstrate that a declarative language like Overlogis well-suited to expressing traditional and novel query optimizations as wellas other program manipulations, in a compact and natural fashion.  FollowingEvita Raced, we describe the initial work in BOOM Analytics, which began as alarge-scale experiment at building ""cloud"" software in a declarative language.Specifically, we used the Overlog language to implement a ""Big Data"" analyticsstack that is API-compatible with the Hadoop MapReduce architecture andprovides comparable performance.  We extended our declarative version of Hadoopwith complex distributed features that remain absent in the stock Hadoop Javaimplementation, including alternative scheduling policies, online aggregation,continuous queries, and unique monitoring and debugging facilities.  We presentquantitative and anecdotal results from our experience, providing concreteevidence that both data-centric design and declarative languages cansubstantially simplify systems programming.",ucb,,https://escholarship.org/uc/item/0sn1r9st,,,eng,REGULAR,0,0
2,1438,Portrait of the Rugged Individualist: The Nonverbal Pride Display Communicates Support for Meritocracy,"Horberg, Elizabeth Jane","Keltner, Dacher;",2010,"Emotions profoundly influence beliefs about morality and justice (Haidt, 2001) and emerging research suggests that expressions of emotion communicate an individual's moral attributes to others (e.g., Brown, Palameta, & Moore, 2002). The present research examines the moral beliefs signaled by the nonverbal pride display. Pride is triggered by appraisals that the self merits high status and greater access to resources (Tracy & Robins, 2004) and pride's nonverbal expression has been shown to convey these appraisals to observers (Shariff & Tracy, 2009). Guided by appraisal-tendency frameworks of the association between distinct emotions and moral beliefs (Horberg, Oveis, & Keltner, 2010), I predicted that the nonverbal expression of pride would communicate greater support for meritocracy--the belief that social and material resources ought to be distributed according to merit--relative to egalitarianism, or beliefs that resources ought to be distributed in ways that promote equality of outcomes. Study 1 demonstrated these effects using unfamiliar male and female targets posing pride or joy in photographs. Study 2 found that individuals previously shown a photo of Barack Obama expressing pride, relative to a neutral expression, subsequently rated Obama as more likely to endorse meritocracy. Finally, Study 3 tests the validity of pride-based inferences of support for meritocracy. This study demonstrated that individuals who spontaneously expressed pride to a greater degree were more likely to advocate dividing a resource between the self and another on the basis of merit rather than equally. Moreover, consistent with Studies 1 and 2, observers rated the high-pride expressers as more likely to support meritocracy and less likely to support egalitarianism.",ucb,,https://escholarship.org/uc/item/0v37d9g2,,,eng,REGULAR,0,0
3,1439,Essays in Empirical Macroeconomics,"Nelson Mondragon, John Alexander","Gorodnichenko, Yuriy;",2015,"This dissertation provides evidence on the eï¬€ects of changes in the supply of credit to households during the 2000s on employment and other outcomes of interest during the 2000s. In the ï¬rst chapter I study the eï¬€ects of contractions in household credit supply during the ï¬nancial crisis of 2007-2009. I exploit a countyâ€™s exposure to the collapse of a large and previously healthy lender as a natural experiment. I show that exposure to this shock appears to be uncorrelated with other important shocks at the time. Reduced form estimates suggest that this shock had large eï¬€ects on the ï¬‚ow of credit, housing and non-housing expenditures, and employment. Using exposure to this shock as an instrument gives an estimated elasticity of employment with respect to household credit of about 0.3, caused by declines in both housing and non-housing demand. In the second chapter I study the size of the credit supply shock using non-parametric methods. I identify lender-speciï¬c supply-side shocks, which I then aggregate into a simple  measure of credit supply shocks to counties. I provide conditions under which this measured shock can be used to quantify the importance of supply shocks to credit in both the cross-section and, in a partial equilibrium sense, the aggregate. Combining this measure with various estimates of the elasticity of employment with respect to the measure, I calculate that shocks to household credit can be responsible for 30 to 60% of the decline in employment from 2007 to 2010.",ucb,,https://escholarship.org/uc/item/0wh0h5bj,,,eng,REGULAR,0,0
4,1440,Control and Trajectory Generation of a Wearable Mobility Exoskeleton for Spinal Cord Injury Patients,"Swift, Timothy Alan","Kazerooni, Homayoon;",2011,"There are currently nearly 1.3 million people in the United States who have some form of lower extremity paralysis due to a spinal cord injury (SCI).  For many of these subjects, a wheelchair is their primary means of mobility which brings along with it a collection of health complications stemming from extended periods of time in a seated position.  To provide these SCI patients with a viable upright mobility option, this work presents the control structure and trajectory generation method for a mobility exoskeleton that allows them to ambulate while reliably generating a gait similar to that of an unimpaired subject.  Also included are theoretical extensions to the trajectory generation structure and results from initial rounds of subject testing.",ucb,,https://escholarship.org/uc/item/0xc9q3b6,,,eng,REGULAR,0,0
5,1441,Errors as a Productive Context for Classroom Discussions: A Longitudinal Analysis of Norms in a Classroom Community,"Leveille Buchanan, Nicole Therese","Saxe, Geoffrey;",2016,"How do teachers and students create classroom environments in which mathematical errors are regarded as important opportunities for learning?  What norms support students in learning from their errors, and how to these norms develop in a classroom community?  This dissertation addresses these questions through a longitudinal case study investigating the emergence of classroom norms related to the treatment of errors.  Classroom norms are here understood to be taken-as-shared expectations for behavior in a classroom. The fifth-grade case study classroom was selected because in prior research studies the experienced and highly-regarded teacher had engaged students in rich discussions of their mathematical errors and the opportunities presented by these errors for learning.  To answer the questions of (a) what norms related to mathematical errors were taken up, and (b) how these norms developed over the course of the school year, Saxeâ€™s (2012) framework describing the relation of micro-, onto-, and sociogenetic processes was used as a guide for determining methods.  Sociogenetic processes were the focus of this investigation, and Saxeâ€™s framework points to microgenetic constructions, when studied collectively over time, as likely to illuminate otherwise difficult to observe sociogenetic processes, such as norm development.  To provide information about microgenetic constructions related to errors, several types of evidence were collected throughout the school year during three data collection periods lasting two weeks each: at the beginning (September), middle (January), and end (April) of the 2014 to 2015 school year.  During all three time periods, the teacher was interviewed, five â€œfocalâ€ students were interviewed, classroom mathematics lessons were video-recorded daily, and all students in the classroom answered a paper-and-pencil multiple choice survey about their expectations related to errors. Interviews were analyzed using grounded analysis methods, and video-recordings were analyzed using a focused coding procedure and StudioCode software.  Sources of evidence were used in a triangulating fashion to identify norms in the classroom.Through this analysis, seven norms were identified as having been taken up by the majority of members of the class by the end-of-year data collection period. Two of these norms were selected for in-depth description. The norm everyone has some mathematical understandings to which you should pay attention provides a good example of a norm that was closely tied to a specific collective practice, the â€œcoachingâ€ practice that was used frequently in the case-study classroom.  The norm there are different types of errors, only some of which are acceptable provides an example of a norm that emerged part-way through the school year in response to a problem with the way errors were being treated.  Classroom interactions and teacher and student interview statements exemplifying these norms are described. The process through which these two norms emerged in the case study classroom over the course of the school year is detailed, using evidence collected throughout the school year.  In general, the teacher strongly promoted these norms by frequently and persistently modeling, describing, and praising behaviors consistent with these norms and by correcting inconsistent behaviors. Implications for how Saxeâ€™s framework may be productively applied in future investigations of classrooms norms are discussed.  In particular, attention to ontogenetic processes â€“ that is, individualsâ€™ shifting expectations over time â€“ was found to be useful as an access point for identifying the norms of a classroom community, and the teacherâ€™s actions and expectations were found to be especially important indicators of classroom norms.  Examination of collective practices related to errors was also useful for the identification of norms because some norms were strongly associated with collective practices, such as the â€œcoachingâ€ practice.  The results of this study also have implications for teaching practice.  The findings indicate that children are capable of taking up challenging practices related to the study of errors, and teachers who promote these practices in their classrooms may be successful if they are persistent in modeling, explaining, and praising the desired practices.",ucb,,https://escholarship.org/uc/item/0zz775v7,,,eng,REGULAR,0,0
6,1442,Interrogating the Role of Spatial Organization in Receptor Function: Eph-Ephrin Signaling in Breast Cancer,"Nair, Pradeep","Groves, Jay T.;",2010,"Cells in living tissue integrate multiple signals from their environment to govern numerous aspects of both healthy and diseased behavior.  The cell membrane serves as an exquisite functional filter that regulates information transmission between a cell and its surrounding environment.  This viscoelastic plasma membrane, which allows lateral diffusion while restricting the orientation of signaling molecules within the plane of a phospholipid bilayer, is uniquely well suited to make sense of the myriad biochemical, mechanical, and spatial cues that constantly stimulate receptors on the cell surface.  The chemical basis for the cell membrane, a fluid phospholipid bilayer, can be used to create a supported membrane that retains these properties while allowing precise control over the physical and chemical aspects of signaling molecules on the supported membrane surface.Cell communication is critical for proper maintenance of multicellular organisms, and tumorigenesis can occur when communication is not properly controlled.  Cancerous cells often display a vastly altered array of cell surface receptors compared to normal cells, and the abnormal signaling that these receptors trigger has grave consequences for the fate of the cell and the organism as a whole.  The dynamics by which these receptors bind to ligands within the environment are not well understood because the cell membrane is a chemically heterogeneous and physically irregular surface that is difficult to study in vivo.  Here we recapitulate signaling events that occur in live cancer cells using the supported membrane to present laterally mobile ligands to receptor-expressing human breast cancer cells.This platform allows for precise control of the spatial organization of signaling molecules on the supported membrane surface, as well as a detailed examination of subsequent changes in signaling events within living cells.  Using this approach we observe receptor reorganization responses that are strongly linked to tissue invasion and our observations reveal a mechanism by which cells respond to the spatial and mechanical aspects of their environment.",ucb,,https://escholarship.org/uc/item/1117n3zf,,,eng,REGULAR,0,0
7,1443,Hydrodynamic Exchange in Estuarine Perimeter Habitats,"HSU, KEVIN KAI-WIN","Stacey, Mark T.;",2013,"Hydrodynamic exchange in estuaries is forced by tides, freshwater input, density forcing, and winds, and controls transport of important quantities such as salinity, sediment, nutrients, and pollutants.  Previous work has characterized many aspects of estuarine transport and contributed to our understanding of transport mechanisms such as gravitational exchange, tidal dispersion processes, and residual flows due to tidal asymmetries.  In general, studies of estuarine transport have focused on large-scale transport processes in the along-channel direction of the estuary, which determine the overall salinity and flow structure in estuarine environments.  However, study of hydrodynamic exchange at the perimeter of estuaries has also been recognized to be important, as exchange at the perimeter is relevant for understanding questions related to environmental restoration and management and ecological habitat quality.In this work, hydrodynamic exchange in estuaries and perimeter habitats is studied using numerical modeling and field observations of South San Francisco Bay.  First, the exchange between the estuary and a small perimeter slough is measured using salinity and temperature as tracers to calculate hydrodynamic flushing of the slough through tidal exchange, using a modified tidal prism method.  This method applies quasi-Lagrangian analysis to Eulerian measurements of exchange, and the results are compared to previous results from larger-scale estuarine systems, where tidal flushing is found to be significantly affected by the scale of mixing volumes in the system.  Next, Lagrangian methods of particle-tracking and Lagrangian coherent structure (LCS) analysis, developed from dynamical systems theory in order to analyze complex, chaotic flows, are applied to analyze tidal transport.  The results reveal the significant effects of tidal interactions with perimeter estuarine features on Lagrangian tidal transport over the tidal cycle, where perimeter interactions are found to significantly contribute to longitudinal estuarine dispersion.  Finally, the effect of wind forcing on estuarine transport is examined, using Lagrangian analysis methods applied to cases of constant wind forcing with varying wind direction relative to the main axis of the estuary.  Wind forcing is found to have a significant effect on hydrodynamic exchange and connectivity between the estuary and perimeter habitats, where wind in all directions increases perimeter exchange and connectivity, with the greatest effect for winds aligned with the along-axis direction of the estuary.  The results of these studies are relevant to a wide range of applications requiring analysis of connectivity near the estuarine perimeter, including sediment exchange and transport and seagrass population colonization in the context of wetland habitat restoration.",ucb,,https://escholarship.org/uc/item/11r7t98v,,,eng,REGULAR,0,0
8,1444,An Environmental and Economic Trade-off Analysis of Manufacturing Process Chains to Inform Decision Making for Sustainability,"Robinson, Stefanie","Dornfeld, David A;",2013,"Increasing costs, consumer awareness, and environmental legislation have driven industry to reduce its resource consumption and the impact from that consumption.  So, both traditional economic objectives (e.g., cost, time, and quality) and environmental objectives (e.g., CO2 emissions) have become strategically relevant for the manufacturing sector. For many manufacturing companies, production systems have a major influence on the environmental footprint of a product and therefore represent a major opportunity to minimize the company's overall environmental impact. Currently within industry, there is not an accurate, effective, or widely accepted method to assess the resource consumption of process chains used to manufacture a product.  As a result, this information is often not considered when making decisions about what processes to use. A considerable part of the energy and resource demand in manufacturing is determined during production planning.  An important component of this planning is determining the process chains to be used.  Process chains are a combined sequence of specifically arranged, single processes used to manufacture a product. As manufacturing processes are very resource intensive, it is now necessary to assess the resource consumption as well as the economics of these process chains.  Because of this, additional information must be considered when selecting the process chains used to manufacture a product.     Many life cycle assessment (LCA) tools focus on the materials and final disposition of a product, but do not include detailed information or data on the manufacturing required to fabricate the product. Sustainability impacts of discrete manufacturing processes and product value streams are needed to develop more complete LCAs. The development of a methodology and user tool to quantify sustainability impacts, leading to the identification of gaps and opportunities, is essential to facilitate decision making to support sustainability in manufacturing facilities.     To address these issues, this dissertation proposes an approach to evaluate and quantify the resource use in addition to the environmental and economic impacts associated with discrete manufacturing processes as part of a complex process chain. A methodology to evaluate multiple process chain configurations will be presented.       First, a database of industrial assessment metrics was compiled.  This database allows users to sort and select from a list of key metrics in order to choose the metrics that are relevant for the performance that they want to measure.  Next, an industrial assessment methodology was developed.  This methodology gives users an overview of the key areas to address when conducting an industrial assessment.  This methodology, which was applied to three case studies, can be used in combination with the key metrics.      In the second part of the dissertation, a resource consumption assessment and mapping methodology for complex manufacturing process chains was developed. This systematic methodology was developed to identify and quantify the resource consumption (energy, water, materials) for discrete manufacturing processes.  The processes mapped include: welding (manual and robotic), cutting (plasma arc and laser), rework (air carbon arc cutting and hand grinding), and machining (milling).      Next, a model consisting of database modules for each process was developed. This model quantifies the sustainability impacts (energy, water, and material consumption, waste generation, emissions, and resource consumption cost) of manufacturing process chains.  The model was validated using a case study with Caterpillar Inc. for a process chain including welding, plasma arc cutting, laser cutting, and milling.       Next, a process chain assessment tool was created.  This tool enables manufacturers to assess the resource consumption and associated impacts of multiple fabrication process chain configurations. This enables a more comprehensive assessment compared to other software tools.  Finally, a methodology modeled after the Six Sigma DMAIC (Define, Measure, Analyze, Improve, Control) process was presented to show how to translate the results from the model and tool to an Environmental Value Stream Map and to translate those results into improvements in manufacturing systems. This methodology was validated on a machining operation in a Caterpillar facility.         This research has developed and evaluated an effective approach for the analysis of energy, water, and other resource use in multiple processes in a manufacturing process chain.  This allows manufacturers to better understand the resource consumption and environmental and economic impacts of fabrication process chains used to make a product. This dissertation helps to provide the technical understanding and tools to enable designers and manufacturing engineers to create manufacturing systems that are truly more sustainable.  The implementation of this work can be directly applied to assessing and optimizing manufacturing process chains and the work presented in this dissertation directly contributes to the realization of a sustainable and prosperous manufacturing sector.",ucb,,https://escholarship.org/uc/item/1513r3t9,,,eng,REGULAR,0,0
9,1445,Essays on Markets and Institutions in Emerging Economies,"GHANI, TAREK FOUAD","Tadelis, Steven;Dal Bo, Ernesto;",2015,"Market frictions pervade emerging economies and constrain private sector development. In such settings, formal institutions to help address contract enforcement, property rights and information asymmetries are typically weak or absent. Instead, market participants must rely on informal practices and institutions to mitigate uncertainty, instability and opportunism. For example, personalized exchange relationships are useful when contract enforcement is weak, and cash holdings can be attractive when financial institutions are unreliable. In three specific emerging economy settings, I explore how informal practices and institutions interact with formal market development, and in particular the role that market frictions play in determining outcomes for firms, technologies and employees. The first chapter of this dissertation explores how changes in formal upstream market structure affect the economics of downstream relationships using original data from the ice industry in Sierra Leone. In this setting, a monopoly ice manufacturer sells through independent retailers to fishermen buyers. I demonstrate that a shock that increases upstream competition among manufacturers improves the contractual terms offered by retailers to buyers.  Under the monopoly manufacturer, late deliveries are common due to outside demand shocks. To help mitigate this uncertainty, retailers prioritize loyal customers when faced with shortages, and buyers respond by rarely switching retailers. When manufacturers compete, prices fall, quantities increase and services improve with fewer late deliveries. Entry upstream also disrupts collusion among retailers by increasing the value of competing for buyer relationships. Competing retailers expand trade credit provision as a new basis for loyalty, and stable buyer relationships reemerge after a period of intense switching. The findings suggest that market structure shapes informal contractual institutions, and that competition can reconstitute the nature of relationships.  The second chapter addresses the relationship between violence and financial decisions in Afghanistan. In particular, I investigate how violence affects the tradeoff between informal cash holdings - which are liquid but insecure - and usage of a more secure but less liquid formal financial account. Using three separate data sources, I find that individuals experiencing violence retain more cash and are less likely to adopt and use mobile money, a new financial technology. First, combining detailed information on the entire universe of mobile money transactions in Afghanistan with administrative records for all violent incidents recorded by international forces, I find a negative relationship between violence and mobile money use. Second, in the context of a randomized control trial, violence is associated with decreased mobile money use and greater cash balances. Third, in financial survey data from nineteen of Afghanistan's 34 provinces, I find that individuals experiencing violence hold more cash. Collectively, the evidence indicates that individuals experiencing violence prefer cash to mobile money. More speculatively, it appears that this is principally because of concerns about future violence. These results emphasize the difficulty of creating robust financial networks in conflict settings.Finally, in the third chapter, I study how informal behaviors interact with incentives to affect employees' decisions to formally save in the context of a large firm in Afghanistan. I analyze a mobile phone-based account that allows savings to be automatically deducted from salaries. Employees who are automatically enrolled in this defined-contribution account are 40 percentage points more likely to contribute than individuals with a default contribution of zero. Analyzing randomly assigned employer matching contributions, I find that the effect of automatic enrollment on participation is approximately equivalent to providing financial incentives equal to a 50 percent match. To understand why default enrollment increases participation, some employees are randomly offered an immediate financial consultation, and others a financial consultation in one week. Employees are more likely to discuss changing their savings contributions in one week, suggesting that defaults raise contributions because of the perceived complexity of financial decisions, and because employees procrastinate in developing a financial plan for the future.",ucb,,https://escholarship.org/uc/item/15g1g7dv,,,eng,REGULAR,0,0
10,1446,A Nexus Between Two Disruptions: A Multiscale Analysis of Transportation Electrification to Forecast the Impacts of Vehicle Grid Integration,"Sheppard, Colin John Ritter","Walker, Joan;",2019,"In this dissertation, I present a body of work that advances our understanding of the technical and economic potential for vehicle grid integration based on a variety of methodological approaches that quantify the opportunity at multiple scales, across multiple geographies, and that cover scenarios with both personally owned plug-in electric vehicles (PEVs) and shared autonomous electric vehicles (SAEVs). The key research questions addressed in this dissertation include:* How can charging infrastructure be cost-effectively deployed to maximize utilization and value to PEV drivers?* How much flexibility exists in the charging demand from PEVs? * What is the economic opportunity to manage the charging of PEVs to occur at lower cost time periods?* How will fleets of electrified autonomous vehicles serving mobility on-demand differ in how they are managed to minimize the cost of charging or to serve as a source of electricity for buildings?These questions are motivated by the fact that transportation electrification and emerging forms of mobility are dramatically changing how the transportation system is planned, operated, and analyzed. PEVs present new challenges and constraints around the siting and operation of refueling infrastructure. Electric load from PEVs can exacerbate grid congestion at either transmission or distribution scales if left unmanaged. Sharing and autonomy are changing mobility which will have unique implications for the grid integration of PEVs. Meanwhile, there are strong social and environmental forces compelling planners, regulators, and private industry to electrify transportation as soon as possible. The transportation sector is the largest emitter of greenhouse gases in the United States. With the exception of the great recession, emissions in the transportation sector have been growing for the last three decades, in contrast to the electric power and industrial sectors which have been on a downward trend in emissions. Transportation, therefore, represents one of the primary challenges to achieving deep decarbonization of the U.S. economy.In the electric power sector, policy and economic forces are upending incumbent generation technologies (coal and natural gas) in favor of lower cost and lower carbon alternatives, particularly wind and solar power. As these intermittent renewable resources increase in capacity, the incidence of renewable energy (RE) curtailment increases due to time periods when supply is greater than demand and generators are turned down or shut off from the level that they would otherwise be producing. Curtailment raises the overall system cost of supplying electricity. In addition, some utilities must meet an energy production standard to satisfy state mandates for renewable production. Renewable curtailment forces utilities to either acquire more RE or introduce sources of grid flexibility to relieve the curtailment. One low cost strategy to mitigate these challenges is to manage the temporal profile of electricity demand to make use of the renewable resources when they are available.PEVs are generally analyzed through modeling using one of two approaches, statistical modeling and activity-based modeling. Statistical models typically summarize or infer travel patterns from travel survey data and use them to characterize the need for PEV charging and the temporal opportunities to charge. The key disadvantage of such approaches is that they cannot account for the individual mobility constraints of travelers and they typically require an assumption that charging infrastructure is unlimited. Another common approach is to develop Markov Chain models of mobility and PEV charging. In these models, transitions between states are treated as random events. Because they lack a representation of the causal mechanism for these transitions, these models are difficult to generalize and their utility is degraded if applied in prospective contexts assuming a transportation system with dramatically different characteristics than present. Activity-based models make use of travel diaries from surveys or GPS data logging which are then provided as input to mobility and charging simulations. Agent-based models are a subset of activity-based models, in so far as they treat travelers individually and require a representation of each individual's activity schedule in order to model the travel necessary to engage in those activities. What distinguishes agent-based models are two key features: 1) wrapping the individuals in a virtual environment (e.g. the transportation system) with detailed representation of transportation supply and 2) dynamically simulating the agents' interactions with the virtual environment and with each other. These interactions open the opportunity to model the choices of the agents based on empirical studies of human behavior as well as to make agent behavior contingent on the time-evolving state of their environment and other agents.In the electric power and grid modeling domain, load from PEVs are typically represented as static or derived from very rudimentary estimation techniques. Studies either ignore flexibility entirely or they make simplistic assumptions about the timing and degree to which PEV load can be shaped. The inaccuracy in these modeling choices have had a relatively low impact in the recent past due to the still relatively low penetration of PEVs in the national vehicle fleet. But within a decade it will no longer suffice to ignore or simplify PEV load, which could eventually make up more than 20% of U.S. electricity demand.This dissertation addresses these gaps by coupling models of electric mobility and the grid at multiple scales. Each paper presented in this dissertation was produced in collaboration with co-authors across multiple projects and contexts. I employ reduced-form models in the context of optimization to solve the charger scheduling and vehicle mobility problems, as well as detailed agent-based models that simulate context-specific traveler behaviors and the dynamics of resource-constrained charging infrastructure.To address the infrastructure siting problem, I develop a spatially explicit agent-based simulation model that represents charging infrastructure, charging behavior, competition for scarce chargers, and driver adaptation. A differential evolution and a heuristic optimization scheme are employed to find a cost-effective distribution of charging infrastructure. I then address the question of flexibility in two ways. First I develop a scheme for optimizing the charging profiles of individual PEV drivers based an objective that simultaneously considers the costs of charging and the benefits associated with providing ancillary services to the grid. Then I employ a much higher fidelity approach to simulate both the electrified mobility system as well as the power sector. I develop the BEAM modeling framework (Behavior, Energy, Mobility, and Autonomy), which is an agent-based model of PEV mobility and charging behavior designed as an extension to MATSim (the Multi-Agent Transportation Simulation model). I apply BEAM to the San Francisco Bay Area and conduct a preliminary calibration and validation of its prediction of charging load based on observed charging infrastructure utilization for the region in 2016.  I link the BEAM model with PLEXOS, an industry standard production cost model that accurately characterizes grid dispatch constraints.Finally, I consider the impact of grid-integrated fleets of SAEVs providing mobility on-demand. In two separate studies I develop models to consider how such fleets could be used to serve building energy demand during power outages as well as a more general analysis of the battery and charging infrastructure requirements to serve nationwide mobility.The key findings across all of this work are the following:* In today's energy markets, PEV flexibility can reach values of $155/year/vehicle for NYISO and $98/year/vehicle for CAISO. The annual cost savings due to optimizing dispatch come more from savings on the price of energy (74% in CAISO and 61% in NYISO) but providing ancillary services (in the form of regulation) also contributes value to the solution (26% in CAISO and 39% in NYISO).* When we project the energy market of California to a future year when renewables make up 50% of the annual energy produced, PEV flexibility is even more beneficial to the power sector, primarily in lowering grid operating cost and the amount of RE that must be curtailed to avoid over-generation when supply and demand are mismatched. For example, if treated as flexible loads, 2.5 million smart charging PEVs avoid 50\% of incremental system operating costs annually and reduce renewable energy curtailment by 27% annually relative to when the same number of unmanaged charging PEVs are added to the grid. * When SAEVs serve power to buildings during an extreme outage, the fleet can generate 32%-40% more revenue than is earned serving mobility alone. While the overall value of providing on-demand power depends on the frequency and severity of power outages, the results show that serving power demand during large-scale outages can provide a substantial value stream, comparable to what can be earned providing grid services. * All mobility in the United States currently served by 276 million personally owned vehicles could be served by 12.5 million SAEVs at a cost of $0.27/vehicle-mile or $0.18/passenger-mile. The energy requirements for this fleet would be 1142 GWh/day (8.5% of 2017 U.S. electricity demand) and the peak charging load 76.7 GW (11% of U.S. power peak). In total, this body of work contributes new insights into the opportunity for electric mobility to reduce the cost of operating the electric grid, enabling deeper and faster adoption of renewable power in the electric sector, and providing reliable mobility to travelers in the transportation sector. The domain of vehicle grid integration is still relatively new, there are many areas of research that require additional attention, such as increased research on traveler preferences around PEV charging, the intersection between electric mobility and the distribution grid, electrification of medium and heavy duty vehicles, as well as properly incentivizing electric vehicles to ride hail drivers in the gig economy.",ucb,,https://escholarship.org/uc/item/1663f91r,,,eng,REGULAR,0,0
11,1447,Tracing Patterns of Textiles in Ancient Java (8thâ€“15th century),"Sardjono, Sandra","Williams, Joanna;Klokke, Marijke;",2017,"Few attempts have been made to study the numerous textile depictions in Java from the eighth to fifteenth centuries, also known as the Hindu-Buddhist or the Ancient Javanese Period. This thesis seeks for the textiles that inspired these depictions and considers their techniques. It also traces the evolution of particular patterns in Java over time. To do so, I employ close art-historical analysis of works of art and draw supportive materials from archaeology, epigraphy and literature, as well as ethnography. After the introductory chapter, Chapters One and Two focus each on a different textile pattern: the connected circles and the overlapping circles patterns. These chapters follow the evolution of the patterns with particular interest to search for connections to current textile tradition in Indonesia. A similar approach of inquiry is applied in Chapter Three to a type of short sleeve jacket. Chapter Four investigates the depiction of weavers in Ancient Javanese textual and visual sources. This study of textile depictions will underscore the global connection between Java and the outside world, particularly China and India, from where many prototypes of the textile images originated. The study will also reveal that these images, in addition to being historical records, were also ornamentations, which the Javanese artists were adept at translating, decontextualizing, and re-contextualizingâ€”as a whole or in partâ€”into the local aesthetic and usage.",ucb,,https://escholarship.org/uc/item/16f914tm,,,eng,REGULAR,0,0
12,1448,"Microtopographical control of cell adhesion, organization, and proliferation in a cardiac tissue engineering scaffold","Patel, Anuj Ashwin","Kumar, Sanjay;",2011,"Myocardial infarction, commonly known as a heart attack, is caused by the blockage of blood flow to heart, resulting in the death of cardiomyocytes, or heart muscle cells. Scar tissue formation occurs in the area of the damage due to the heart's inability to regenerate myocardial tissue. Therefore, regeneration of myocardial tissue through the use of synthetic scaffolds requires strategies to promote cardiomyocyte attachment while minimizing proliferation of the fibroblast cells that contribute to scar tissue. Previous studies have demonstrated that a synthetic platform consisting of an array of microscale polydimethylsiloxane (PDMS)-based pillars (""micropegs"") can accomplish both of these goals, but the mechanism through which this occurs has remained a mystery.   In this work the interaction between microtopographical cues and both fibroblasts and cardiomyocytes is further explored. It is shown that a fibroblast that is attached to a micropeg is less likely to proliferate than ones on a flat surface, but this difference can be partially abrogated in the presence of drugs that inhibit cell contractility. The cells also show increased adhesion to the micropegs as opposed to flat surfaces, as demonstrated by measurements of the dynamics of deadhesion from the surface and changes in expression of specific mechanotransductive genes. Together, these data support a model in which microtopographical cues alter the local mechanical microenvironment of cells by modulating adhesion and adhesion-dependent mechanotransductive signaling, thereby leading to a reduction in proliferation capability.   The research focus then shifts to the use of microtopographical cues to control cardiomyocyte adhesion and organization. Cardiomyocytes cluster around and interact with the full length of the micropegs, exhibiting three-dimensional organization on a two-dimensional surface. By controlling the diameter and spatial arrangement of the micropegs, the degree of clustering can be regulated. The expression of functional markers N-cadherin and connexin 43 also exhibit a dependence on the spatial arrangement of the micropegs. The preference of cardiomyocytes for three-dimensional adhesion is further investigated in the final part of the thesis. By isolating cardiomyocytes in PDMS microwells, the cells are presented with the option of attaching to a vertical wall or a flat space. The cells demonstrate a preferential attachment to the side walls and corners of the microwell. Introduction of the myosin inhibitor blebbistatin reduces the percentage of cells attached to these side walls. Cells attached to a side wall also are less likely to proliferate, similar to the behavior of fibroblasts attached to micropegs. Taken together, these data indicate that incorporation of microtopographical features into cardiac tissue engineering scaffolds can be used to control the adhesion and organization of cardiomyocytes while simultaneously limiting the formation of scar tissue.",ucb,,https://escholarship.org/uc/item/1c78p3zh,,,eng,REGULAR,0,0
13,1449,"Grocery Stores: Neighborhood Retail or Urban Panacea? Exploring the Intersections of Federal Policy, Community Health, and Revitalization in Bayview Hunters Point and West Oakland, California","Elias, Renee Roy","Corburn, Jason;",2013,"Throughout the nation, grocery retailers are reentering underserved communities amidst growing public awareness of food deserts and the rise of federal, state, and local programs incentivizing urban grocery stores. And yet, even with expanding research on food deserts and their public health impacts, there is still a lack of consensus on whether grocery stores truly offer the best solution. Furthermore, scholars and policymakers alike have limited understandings of the broader neighborhood implications of grocery stores newly introduced into underserved urban communities.This dissertation analyzes how local organizations and agencies pursue grocery development in order to understand the conditions for success implementation. To do this, I examine the historical drivers, planning processes, and outcomes of two extreme cases of urban grocery development: a Fresh and Easy Neighborhood Market (a chain value store) in San Francisco's Bayview Hunters Point and the Mandela Foods Cooperative (a worker-owned cooperative) in Oakland's West Oakland districts. Through a comparative institutional analysis, I find that both Fresh and Easy and Mandela Foods reflect distinctive neighborhood revitalization legacies, critical moments of institutional capacity building, localized versions of national policy narratives, and the role of charismatic leaders in grocery store implementation. While national narratives shape the rhetoric of urban grocery development, ultimately local context dictates how food access issues are defined, who addresses them, and how. These findings suggest that federal grocery incentive programs should: 1) maintain a broad framework that enables local communities to define food access problems and their solutions on a case-by-case basis, 2) encourage diverse solutions not limited to grocery stores and supermarkets, and 3) emphasize community reinvestment goals.",ucb,,https://escholarship.org/uc/item/1d45296j,,,eng,REGULAR,0,0
14,1450,Wavefront metrology for high resolution optical systems,"Miyakawa, Ryan","Attwood, David;",2011,"Next generation extreme ultraviolet (EUV) optical systems are moving to higher resolution optics to accommodate smaller length scales targeted by the semiconductor industry.  As the numerical apertures (NA) of the optics become larger, it becomes increasingly difficult to characterize aberrations due to experimental challenges associated with high-resolution spatial filters and geometrical effects caused by large incident angles of the test wavefront.  This dissertation focuses on two methods of wavefront metrology for high resolution optical systems.  The first method, lateral shearing interferometry (LSI), is a self-referencing interferometry where the test wavefront is incident on a low spatial frequency grating, and the resulting interference between the diffracted orders is used to reconstruct the wavefront aberrations.  LSI has many advantages over other interferometric tests such as phase-shifting point diffraction interferometry (PS/PDI) due to its experimental simplicity, stability, relaxed coherence requirements, and its ability to scale to high numerical apertures. While LSI has historically been a qualitative test, this dissertation presents a novel quantitative investigation of the LSI interferogram.   The analysis reveals the existence of systematic aberrations due to the nonlinear angular response from the diffraction grating that compromises the accuracy of LSI at medium to high NAs. In the medium NA regime (0.15 < NA < 0.35), a holographic model is presented that derives the systematic aberrations in closed form, which demonstrates an astigmatism term that scales as the square of the grating defocus.  In the high NA regime (0.35 < NA), a geometrical model is introduced that describes the aberrations as a system of transcendental equations that can be solved numerically.  The characterization and removal of these systematic errors is a necessary step that unlocks LSI as a viable candidate for high NA EUV optical testing.The second method is a novel image-based reconstruction  that characterizes the aberrations of an optical system with arbitrary numerical aperture and illumination coherence.   In this method a known pattern is imaged by the test optic at several planes through focus.  A computer model is created that iterates through possible sets of wavefront aberrations until the through-focus series of aerial images matches the aerial images from the experiment.  Although the sample space of Zernike coefficients is non-convex, a hybrid algorithm consisting of pattern search and simulated annealing methods is used to search for the global minimum.The computation of aerial images from a partially coherent optical system is expedited with a novel decomposition of the Hopkins equation known as the Reduced Optical Coherent Sum (ROCS).  In this method, the Hopkins integral is described by an operator S which maps the space of pupil aberrations directly to the space of aerial images.  This operator is shown to be semipositive definite and well-approximated by a truncated sum of its spectral components.  The ROCS decomposition has a customizable error bound allowing one to tradeoff aerial image fidelity for significant speed improvements.  For aerial image errors of 1-3%, the ROCS algorithm can compute aerial images up to 15 times faster than the Hopkins integration.  The ROCS-based wavefront test is extremely versatile since it is applicable in nearly all optical systems that measure aerial image intensity regardless of numerical aperture or illumination coherence and requires little or no experimental modifications.  This test is used to characterize the field-dependent aberrations of the SEMATECH Berkeley Actinic Inspection Tool (AIT), and the results match an independent analysis of the astigmatism aberrations to within lambda/20 rms.",ucb,,https://escholarship.org/uc/item/1dd5j7ss,,,eng,REGULAR,0,0
15,1451,Investigating Innovation Practice: Cross-Disciplinary Studies in International Development,"Gordon, Pierce Edward Cornelius","Agogino, Alice M;",2018,"Innovation practice is a transdisciplinary field that aims to create a better world out of an existing one by pooling methods and mindsets of inquiry and creation. The field observes design contexts, assimilates the collected knowledge into problems to be addressed, ideates solutions to those problems, and iteratively tests those solutions in real environments to determine how they address these problems. Over the past decade, the field has become more accessible to a much broader collection of amateur designers. They utilize the field to understand more diverse contexts, to include and adapt more disciplines, and to address a wide variety of complex and seemingly intractable issues. Due to the evolution of the fieldsâ€™ popularity, debates began to arise about the fieldsâ€™ utility and place in society. Development professionals treated design thinking and related fields as a silver bullet that could easily address issues of global poverty. Critics asked if the field was different from existing disciplines, whether the field delivers demonstrable impact, and if the democratization of design practice to â€˜amateurâ€™ designers is even worthwhile. However, these debates revealed how little knowledge is collected about how practitioners conduct innovation practice in the first place. To learn about the activities, benefits, methods, and obstacles of beneficial development-focused design practice, I detail three studies that apply lenses of analysis to innovation narratives to see how various collectives of self-determined innovators actually practice their craft. The first study outlines a systematic literature review of human-centered design for development. By applying design principles to a population of researcher-designers and their narratives, we learn if these designers actually practice innovation with these principles of human-centeredness in mind. I outline three previously conducted studies about the nature of this field, which describe the population, location, history, and methods these projects use across various contexts. and detail an analysis of the participatory nature of human-centered design for development. In so doing, I describe statistics about the prevalence of participatory design practice, reveal how the studies report the complexities of participation, and collect insights about the stakeholders who are allowed to design. The study then sums up the importance of investigative analysis methods across populations of design narratives, so that researchers can learn more about how â€˜good practiceâ€™ is perceived. The second study describes an ethnographic evaluation study of notable actors in the Botswana innovation community. This study begins with a reflection on epistemological frictions between the popular fields of innovation practice and impact evaluation. After revealing the theoretical and practical gaps in how innovators evaluate, I introduce the Botswana history, policies, and institutions that support innovation practice on the national level, while describing their activities and how innovation actors perceive them. I then detail the creation of a grassroots innovation community that practices participatory co-design of locally beneficial technologies by outlining the history of its indigenous stakeholders and describing an ethnographic narrative of two formative innovation workshops. I then describe the methods, approaches, purpose, and stakeholders involved in the evaluation of innovation in the local and national institutions. This analysis reveals evaluation tools applicable to many innovation contexts, and insights about how these evaluation approaches are aligned and misaligned with each other. Finally, I describe insights on the practice and facilitation of innovation in the country, to clarify cultural, institutional, and practical barriers and qualities that hinder the potential benefit of innovation. The final study is a reflection on the inadequacies of ethics systems in Botswana to support beneficial innovation practice. While investigating the previous chapter, I happened upon narratives with no simple solutions, and few resources for development-centric designers to effectively navigate this ethics space. Moreover, while facing the countryâ€™s institutional review board system, I gained first-hand experience with the goals, dynamics, and limitations of the Botswana research system of ethics. This chapter unpacks how the ethical system fails to align with the needs of beneficial innovation practice and suggests theoretical alternatives to draw upon for future use. This dissertation describes the complex possibilities of participatory design practice, the various goals, activities, and perceptions of the evolving Botswana innovation ecosystem, and details the frictions between the understudied field of ethics in design for development and existing institutions. These studies reveal how â€˜goodâ€™ innovation practice is wholly based on the context it is applied: on its practitioners, their tools, their goals, the environment where it is used, and the stakeholders with whom the designers interact. Though these studies outline how the methods and mindsets of innovation practice are accessible to more communities than ever, it does not mean that innovation practice itself becomes simpler. These lenses of cross-contextual analysis, participation, evaluation, and ethics reveal how the amorphous, evolving field requires innovators who are responsive and respectful of the contexts in which they are situated. These studies outline a few of many approaches that reveal the unique dynamics in development-centered innovation practice but are essential for any designersâ€™ toolbox to ensure we collectively create a better world.",ucb,,https://escholarship.org/uc/item/1f20709j,,,eng,REGULAR,0,0
16,1452,Optimal Reconstruction of Cosmological Density Fields,"Horowitz, Benjamin Aaron","Seljak, Uros;",2019,"A key objective of modern cosmology is to determine the composition and distribution of matter in the universe. While current observations seem to match the standard cosmological model with remarkable precision, there remains tensions between observations as well as mysteries relating to the true nature of dark matter and dark energy. Despite the recent increased availability of cosmological data across a wide redshift, these tensions have remained or been further worsened. With the explosion of astronomical data in the coming decade, it has become increasingly critical to extract the maximum possible amount of information available across all available scales. As the available volume for analysis increases, we are no longer sample variance limited and existing summary statistics (as well as related estimators) need to be re-examined. Fortunately, parallel with the construction of these surveys there is significant development in the computational techniques used to analyze that data. Algorithmic developments over the past decade and expansion of computational resources allow large cosmological simulations to be run with relative simplicity and parallel theoretical developments motivate increased interest in recovering the underlying large scale structure of the universe beyond the power spectra.The detailed study of this large scale structure has the potential to shed light on various unanswered questions and under-constrained physical models for the dark sector and the nature of gravity. As we reach higher redshifts with statistically significant samples, the large scale structure can serve as a link between local observations and the cosmic microwave background. These surveys rely on a variety of biased probes, including the lensing and distribution of galaxies, imprints of large scale structure in secondary anisotropies of the CMB, and absorption lines in the spectra of high redshift quasars. These observations are complementary; they probe different scales, have different sources of astrophysical and observational uncertainties, have unique degenercies in parameter space, and require their own methods to extract cosmological parameters from.In this thesis, I discuss a number of new developments in the analysis of these diverse cosmological datasets. After introductory material, I discuss work re-examining the lensing of the Cosmic Microwave Background by cluster-sized objects and implement techniques for accurate mass estimation. I demonstrate that this analysis is optimal in the low noise, small scale limit. In the second part, I develop a maximum likelihood formalism for linear density fields, applicable for reconstructing underlying signal from a variety of cosmological probes including projected galaxy fields and cosmic shear, showing that effects of anisotropic noise and masking can be mitigated. Finally, I extend this work to nonlinear observables by using a forward modeling approach for Lyman Alpha forest tomography, finding more accurate cosmic web reconstruction verses existing techniques. The unifying theme of all these works is revisiting existing matter density reconstruction techniques with a critical eye and using new statistical and computational techniques to efficiently perform an unbiased, lower variance, estimate. Included is discussion of the possible impacts of these methods to improve constraints of cosmological parameters and/or astrophysical processes.",ucb,,https://escholarship.org/uc/item/1fk125d0,,,eng,REGULAR,0,0
17,1453,Effects of shape and surfaces on fluid-dynamic performance of organisms at intermediate Re,"Dolinajec, Trevor Hendry","Koehl, Mimi A.R.;",2015,"An organism's performance in relation to the fluid it lives and operates in is importantacross size and time scales, but the effects on performance of body shape andproximity to a surface become particularly nuanced at intermediate Re. This physicalregime in which both viscosity and inertia play important roles has not been studiedas extensively as that of macroscopic animals in which inertia dominates or that ofmicroscopic animals in which viscosity dominates. However, many ecologically importantanimals such as the copepod occupy these intermediate flow conditions, as doboth airborne and aquatic propagules such as the sporocarps of fungi and the larvae ofbenthic animals. Through recorded observation and modeling this dissertation arrivesat biological implication regarding these organisms' habitats and life cycles. This workalso creates a fuller understanding of general principles that govern intermediate Re.Zooplankton contain a range of morphologies, and life cycles that bring them in contactwith surfaces that act as crucibles. The purpose of this study was to determinehow the morphology and orientation of a variety of ecologically-important microscopicmarine animals (adult copepod, snail veliger larva, barnacle nauplius and cyprid larvae)affect the forces they experience while swimming in the water column, and whileon surfaces (e.g. prey captured on tentacles of benthic predators, larvae settled ontobenthic substrata). Drag, lift, and side forces as well as moments were measuredabout three axes for dynamically-scaled physical models of each animal. These forcesand moments can transport and reorient swimming animals, and can push, lift, peel,or shear animals o surfaces, and thus affect important ecological processes such asdispersal, predation, and larval settlement. The Reynolds numbers (Re, the ratio ofinertial to viscous forces) for the zooplankton and the models was in the range of 10^2to 10^3. Body shape and orientation of small animals were found to have significant effects on the magnitudes of fluid dynamic forces and moments at Reynolds numbersof order 10^3, but were less important at lower Re's. The magnitude and direction ofthe net force on an organism was found to change drastically as an organism nears,and then lands on a surface. The shear stress on the attachment of a small animal toa surface that is caused by drag pushing the animal downstream is greater than theshear stress due to rotation of the organism by flow-induced spinning, thus zooplanktonon surfaces are more likely to be pushed than twisted o the surfaces by water currents.For phytopathogenic fungi in the order Erysiphales, the cause of the diseases calledpowdery mildew, reinfection or dispersal to a new host plant is contingent on sporocarpsescaping a fluttering leaf, but the mechanisms that allow for this liberation arelargely unknown and unquantied. The genus Phyllactinia, unlike other members ofthe order, has specialized and upwardly bent radial appendages that allow the body ofthe sporocarp to extend down from the bottom of the host leaf. This causes the tipsof the appendages to be the only physical connection between the sporocarp and theleaf with a gap of up to 300 microns, thus creating an arrangement where fluid flow maycontribute to liberation. To test the importance of ambient fluid flow on sporocarp liberationforces and moments were measured and fluid flow around dynamically-scaledphysical models was observed at Re of 60 - 360. Flow velocities, boundary layer heights,and sporocarp morphologies were varied to match unsteady flow conditions and sporocarpmaturation. To test the importance of aeroelastically induced inertial forces the kinematics of fluttering leaves in a wind tunnel were recorded at a range of wind speeds, and samples of sporocarps were weighed. Physically modeled aerodynamic forces and moments alongside recorded inertial forces were compared to measured adhesive forces. The comparative forces strongly suggest that steady wind flow and realistic turbulent wind flow do not exert force necessary for liberation in magnitude or direction, but that unsteady flow can lead to significant pitching moments. The accelerations of fluttering leaves and the resulting inertial forces on sporocarps varied greatly among leaves, with forces large enough to liberate sporocarps occurring in a small subset of leaves with a characteristic flutter frequency of 25 Hz. Pitch-induced overturning of sporocarps can explain the removal of sporocarps observed on wind-exposed leaves, with more sporocarps liberated at greater wind speeds and towards the tips of leaves.Terminal velocity is an important parameter in the wind dispersal of propagules (seeds,pollen grains, spores). Aerial righting and aerodynamic stability is common amongvertebrate and invertebrate animals, and some propagules. Fungal sporocarps of thepowdery mildew Phyllactinia have shapes that aect their terminal velocity and aerodynamicstability while operating at Re 1.0 - 3.3, thus Phyllactinia represents a modelorganism for aerodynamic performance at near-unity Re. The reproductive success ofthese mildew species is dependent on stability during aerial transport so that a particularorientation is achieved upon deposition. High speed videography was used tomeasure terminal velocity, angular velocities, and angular accelerations of free-fallingsporocarps during aerial righting. Physical models allowed for quantification of forcesand moments acting on sporocarps falling at terminal velocity, as well as providing fine-scaleflow visualization. The morphology of sporocarps is dependent on their maturity,and experiments carried out with collected sporocarps showed that terminal velocityis partially a function of morphological parameters. Terminal velocities of sporocarpsranged from 8 to 28 cm/s. Flow visualizations showed that both the width and lengthof the wake formed around a falling sporocarp were dependent on the spread of thecharacteristic radial appendages of the genus. Sporocarps were recorded rotating whilefalling prior to reaching stability, and angular velocity and angular accelerations decreasedas sporocarps approached zero angle of attack. Models conrmed that a stablexed point existed at an angle of attack of zero for all tested morphologies of Phyllactiniasporocarps. However, naturally occurring morphologies that were the most likelyto have smaller terminal velocities also displayed smaller aerial-righting moments, andsporocarps most likely to have larger terminal velocities displayed larger aerial-rightingmoments. This suggests a potential trade-o between sporocarps that are more stable(larger aerial-righting moments) and those that can disperse longer horizontal distances(smaller terminal velocity).",ucb,,https://escholarship.org/uc/item/0jd1746s,,,eng,REGULAR,0,0
18,1454,Fabrication and Optimization of Nano-Structured Composites for Energy Storage,"Carrington, Kenneth Russell","Mao, Samuel S;Carey, Van P;",2009,"This dissertation is focused on the development and characterization of a novel class of solid-state nano-structured composites for hydrogen storage based on silica aerogel. It is organized sequentially around experiments conducted to fabricate, optimize and characterize silica aerogel and the composites for hydrogen storage. First, the basics of nano-structured media, silica aerogel technology and solid-state hydrogen storage are introduced. Next, the fabrication and optimization of silica aerogel for hydrogen storage is described in detail. The key result is that varying fabrication parameters can improve the physical properties of the resultant silica aerogel in the context of hydrogen storage. The fabrication of solid-state nano-structured composites using chemical vapor infiltration is then discussed. A series of experiments is used to parameterize the fabrication process, which results in a collection of parameters that minimize variation and structural damage in the composites. Silica aerogel and the composites are then physically characterized using transmission electron microscopy, X-ray diffraction and porosimetry in order to investigate their nano-structuring.An overview of hydrogen storage characterization and two innovations that improve the accuracy and efficiency of hydrogen storage characterization of low-bulk density media like silica aerogel and the composites are then presented. Finally, the innovations are applied to silica aerogel and the composites to characterize their hydrogen storage performance. Silica aerogel and the composites are found to outperform the most common benchmark in physisorption media, and one composite in particular shows unique hydrogen storage performance.",ucb,,https://escholarship.org/uc/item/0nc0p6fm,,,eng,REGULAR,0,0
19,1455,Worlds of Desire: Gender and Sexuality in Classical Tamil Poetry,"Segran, Elizabeth Rani","Hart, George L;",2011,"This dissertation contributes to the nascent study of the Tamil Cankam corpus, a collection of poetic anthologies produced in the first three centuries CE. The Cankam poems are constructed around the two complementary themes of the ""inner world"" relating to emotions, romance and family life, and the ""outer world"" relating to kingship, warfare and public life. This dissertation argues that the thematic division within the corpus is gendered, as the ""inner world"" is associated with the feminine while the ""outer world"" is associated with the masculine. Each chapter explores the way that the poets establish the boundaries of femininity and masculinity through both the form and content of their verses. This dissertation focuses closely on the moments of rupture in the poets' system of gender construction, for these moments suggest that the poets acknowledged that gender is more fluid and complex than it initially appears. To better understand the workings of gender and sexuality in these poems, this study juxtaposes recent theoretical frameworks with these poems from the distant past. Methodologically, this dissertation collapses traditional historical time, bringing the ancient Cankam anthologies into conversation with ideas that are circulating now. In doing so, it seeks to elucidate both the poems and the theory, while also opening up new questions in both fields.",ucb,,https://escholarship.org/uc/item/0nk260ck,,,eng,REGULAR,0,0
20,1456,Cellodextrin Transporters of Neurospora crassa and their Utility in Saccharomyces cerevisiae During a Biofuel Production Process,"Galazka, Jonathan Matthew","Cate, Jamie H. D.;",2011,"The filamentous fungus, Neurospora crassa, is capable of depolymerizing and metabolizing plant cell walls. When grown on plant cell walls or pure cellulose, N. crassa upregulates an overlapping set of 114 genes. Amongst this set are 10 major facilitator superfamily transporters. I have shown that two of these, CDT-1 and CDT-2, transport cellodextrins, which are the major degradative product of fungal cellulases. Deletion of cdt-2 affects the growth of N. crassa on crystalline cellulose. Furthermore, diverse fungi transcriptionally upregulate orthologs of cdt-1 and cdt-2 when in contact with plant cell walls, suggesting that cellodextrin transporters are important to fungal interactions with plants. Engineering the cellodextrin transport pathway into Saccharomyces cerevisiae allows this yeast to ferment cellodextrins to ethanol with high yields, and facilitates the simultaneous saccharification and fermentation of cellulose to ethanol. Cellodextrin transport can be coupled to downstream hydrolysis or phosphorolysis of cellodextrins by a cellodextrin hydrolase or cellobiose phosphorylase, respectively. Cellodextrin transport circumvents a major limitation of yeast in fuel production: the inability to simultaneously transport and ferment pentose sugars and glucose to ethanol. S. cerevisiae did not evolve to co-ferment cellobiose and xylose and unintended consequences are likely.  For example, we speculate that S. cerevisiae may not sense cellobiose as a fermentable carbon source.",ucb,,https://escholarship.org/uc/item/0nr9n5zw,,,eng,REGULAR,0,0
21,1457,Dynamics of Viral Packaging: Single-Molecule Observations in Multiple Dimensions,"Hetherington, Craig Lee","Bustamante, Carlos J;",2011,"During the self-assembly of bacteriophage phi29, the viral genome is packaged into a pre-formed capsid by a molecular motor. The packaging motor is a complex of several oligomers including a dodecameric connector ring and a pentameric ATPase ring. These rings coordinate with each other, generating high forces in order to compact the dsDNA genome into the capsid at high pressures.The connector was proposed to engage and directly perform work on the DNA during packaging. Consideration of the symmetry of the connector and the capsid predicts that the connector must rotate relative to the capsid as part of the mechanism for translocating the DNA. An experiment designed to directly measure rotation of the connector is discussed in Chapter 2 of this dissertation. A combination magnetic tweezers and total internal reflection microscope is used to track the polarization of single fluorescent dyes attached to the connector. No evidence of polarization changes were found, indicating that the connector does not rotate at the expected rates. This further suggests that the connector does not directly perform mechanical work on the DNA during packaging.Viral packaging can be observed in optical tweezers by monitoring the length of the DNA as it is drawn into the capsid. Past studies have revealed many details of the packaging mechanism by following the dependence of the packaging velocity on factors like ATP concentration and applied load. In Chapter 3, I propose an experimental design intended to measure the effect of the packaging motor on the angle of the DNA in addition to its length and thus recover the full three-dimensional trajectory of the DNA as it passes into the capsid. In addition, this scheme can be used to apply torque and thus provides an additional tool with which to probe the packaging mechanism.In Chapter 4, we find that during packaging the downstream DNA is twisted in an underwinding direction, with a magnitude that depends on the extent to which the capsid is filled. The change in twisting can be attributed to cumulative looping of the DNA within the capsid, and the data predicts that the loops formed in the last kilobasepair of packaging are as small as 4 nm in radius. In addition, a non-lethal method of rupturing the viral capsids prior to packaging was discovered. Observations of DNA twisting by those packaging complexes revealed that, in the absence of internal pressure, the DNA is twisted by -1.2 Â°/bp. This number suggests that one of the packaging motor's five subunits makes contact with the DNA every ten basepairs, and that the cycle repeats with that subunit performing the same function every time. Such a strict functional segregation, in addition to the catalytic segregation revealed in previous high-resolution optical tweezers experiments, is an important part of the mechanism by which the motor packages DNA against high forces.",ucb,,https://escholarship.org/uc/item/0pw8703c,,,eng,REGULAR,0,0
22,1458,Viral Politics: Sex Worker Activism and HIV/AIDS Programs from Bangalore to Nairobi,"Vijayakumar, Srigowri","Ray, Raka;",2016,"This dissertation studies the international success story of Indiaâ€™s HIV/AIDS response and the activism of sex workers and sexual minorities that produced it. A number of recent ethnographies have turned their attention to the workings of state programs in middle-income countries (e.g. Baiocchi 2005; Sharma 2008; A. Gupta 2012; Auyero 2012), demonstrating both the micro-effects of state strategies for managing poverty on poor people and the ways in which state programs are produced outside the visible boundaries of â€œthe stateâ€â€”through NGOs and social movement organizations as well as transnational donors and research institutes.  Yet, even as state programs are constituted through struggles over resources and representations within and outside the official agencies of the state, states also derive legitimacy from projecting themselves as cohesive rather than disaggregated, and as autonomous from society rather than anchored within it (Abrams 1988; Mitchell 1991b; Mitchell 1999; A. Gupta 2012). The representation of state programs as cohesive, pre-constituted, exportable â€œmodelsâ€ serves as a new way of consolidating state legitimacy within a global, hierarchical order of development â€œsuccess.â€ However, this dissertation argues that the traveling policies disseminated through transnational expert communities are a selective codification of hard-fought struggles among institutions within the state, between the state and organizations, among organizations, and among groups within organizations over the aims and strategies of social policies and programs.  These struggles shape what travels in traveling policies and what is left out.  Drawing on over 150 in-depth interviews and a year of participant observation with sex workers involved in implementing policy in community-based organizations, NGOs, and activist groups, I show how the material and social conditions of men, women, and transgender women in sex work, mediated through community-based organizations, constituted the successful approaches to HIV prevention that were later, sometimes selectively, translated around the world.",ucb,,https://escholarship.org/uc/item/0qs1n4fh,,,eng,REGULAR,0,0
23,1459,Optodynamical Measurement and Coupling of Atomic Motion and Spin,"Kohler, Jonathan","Stamper-Kurn, Dan M;",2018,"The quantum nature of light makes it a basic component for models of quantum measurement and information exchange between disparate quantum modes, pioneered in the field of cavity quantum electrodynamics. The interaction of atomic ensembles with the mode of an optical cavity provides a flexible platform for exploring the coherent interaction of light with diverse macroscopic dynamics, such as collective motion and spin. This dissertation presents experimental results and theoretical models for continuous measurement and control of the center of mass motion and collective spin precession of an atomic ensemble, mediated by coupling to a high-finesse optical cavity. First, the theory of dispersive coupling between the cavity mode and the collective motion and spin of an atomic ensemble is derived, and then a general time-domain formalism is developed for theoretical analysis of multi-mode optodynamical systems. Single-mode optodynamical effects are introduced through experimental demonstrations of measurement and control of the collective atomic spin, providing a close analogy to cavity optomechanics.Next, multiple collective atomic modes are considered within a single cavity, in order to assemble optically mediated interactions within multi-mode optodynamical systems. A demonstration of optodynamical interactions between the center of mass motion of two atomic ensembles is presented, coupled through an optical spring mediated by the cavity mode. Then simultaneous coupling of the center of mass motion and total spin precession of a single ensemble of atoms is described, yielding an experimental realization of a negative-mass instability, facilitated by the novel resource of the spin ensembles inverted state. A theoretical analysis of the negative-mass instability is presented, which indicates the possibility of generating two-mode squeezed states in the absence of excess incoherent noise. Finally, linear state retrodiction from the optodynamical signals is discussed, providing background and supplemental material for a forthcoming manuscript.",ucb,,https://escholarship.org/uc/item/0hn835xt,,,eng,REGULAR,0,0
24,1460,"Searching for Sustainable Utopia: Art, Political Culture, and Historical Practice in Germany, 1980-2000","Allen, Jennifer Leigh","Jay, Martin E;",2015,"At the end of the twentieth century, the gradual triumph of liberal democracy and capitalism over â€œreally existing socialismâ€ brought to many West Germans not relief but melancholy. Facing what they interpreted as the dissipation of radical social and political alternatives, academics and public intellectuals pronounced the death of ideology, of history, and of utopian ambitions. This dissertation asks how West Germans nevertheless found ways to challenge this resignation by giving voice to new, radical hopes for Germanyâ€™s future. For their broad popularity and sustained impact, this study traces the grassroots efforts of three groups. First, it follows the Berlin History Workshop, a collection of amateur and professional historians, as they attempted to liberate the process of researching and writing history from the rigid confines German universities. This group sought, instead, to bring the historianâ€™s craft into Berlinâ€™s local neighborhoods in order to enable ordinary Germans to narrate their own histories. Second, this dissertation analyzes the Green Party, which practiced localized plebiscitary policy making in an effort to endow German citizens with greater political agency. The Greens brought this political practice to numerous cultural projects in an effort to democratize German society by democratizing the cultural encounters of its citizens. Third, this project investigates a loosely-connected group of artists who echoed the investments of the historians and politicians by creating art installations with ordinary objects in ordinary spaces that prompted passersby to reevaluate their relationships to the topography of their daily lives.This dissertation argues that, through these groups, everyday Germans adopted a set of cultural practices in the 1980s and â€˜90s that not only critiqued established institutions but also crafted new institutions in their place. Their critical practices followed three conventions. First, they championed radical grassroots democracy by giving citizens opportunities to create socially-significant cultural products like museums and monuments. Second, they decentralized the creative process, locating it in the spaces of everyday life in order to make it widely accessible. Finally, they borrowed from the environmental movement the concept of sustainability, which demanded that any alternative to existing society be both enduring and adaptable. These practices put culture to work in realizing a more democratic, more socially-integrated Germany. In doing so, they permitted their practitioners to reclaim utopian hope from the dustbin of historical ideas.These three case studies span Germanyâ€™s academic, political, and aesthetic terrain. As such, together they offer evidence that efforts to battle twentieth-century apathy signaled a broad shift in German cultural sensibilities, not an isolated phenomenon. The first three chapters of the dissertation treat each of these groups individually as they began to advocate for new, more democratic geographies of cultural engagement, or â€œalternative public spheres,â€ in the early 1980s. Their focus on Germanyâ€™s cultural environment made them particularly receptive to the idea of sustainability popularized after the convening of the World Commission on Environment and Development in the middle of the decade. The next three chapters trace their pursuit of sustainability in culture. A sustainable culture, they came to realize, had to regard its projects as part of an ongoing process rather than as static goals: theirs was a renewable, future-oriented cultural movement in the present, or a â€œsustainable utopia.â€ Faced with radical changes to the international political landscape and the rapid expansion of their constituencies to include sixteen million East Germans alongside more pedestrian concerns like funding difficulties and interpersonal conflicts, these groups weathered the last decade of the twentieth century with varying success. The study concludes by underscoring the irony that the most durable component of their cultural programs in the wake of German political reunification was their push for cultural decentralization.",ucb,,https://escholarship.org/uc/item/0j67m8xp,,,eng,REGULAR,0,0
25,1461,"Conservation, Economics, and Management of Hunting on Private Land: An International, National and California Analysis","Macaulay, Luke Thomas","Huntsinger, Lynn;Barrett, Reginald;",2015,"Privately owned land accounts for significant areas of land internationally, nationally, and in California. In the U.S. and elsewhere, private land tends to support high levels of biodiversity because land with more productive natural resources was settled and privatized first. These lands, which are integral to conservation goals, are often the most vulnerable to habitat degradation and loss through changes in land-use and fragmentation. In 1930, Aldo Leopold encouraged the development of an incentive scheme to better conserve private lands in the U.S. where hunters would pay landowners for access to conserved wildlife habitat and game populations that could be sustainably harvested. Although a wide body of literature has discussed this approach, much of the research is either theoretical or limited to particular regions and these studies have rarely tested for an explicit connection to whether conservation is ultimately improved as a result of paid hunting. The goal of this dissertation is to evaluate the economic, conservation and management aspects of hunting on private land internationally, nationally, and in California. The first chapter uses a case study approach to explore the environmental and economic issues surrounding hunting in the context of Spain and California. The study found that increased game management rights in Spain appears to yield improved economic return, but at an environmental cost. The second chapter evaluates the scale, distribution and conservation aspects of spending to access private land for fishing, hunting, and wildlife-watching in the United States. This study found that that approximately 440 million acres of private land, an estimated 22% of the contiguous land area of the U.S. and 33% of all private land in the U.S., are either leased or owned for wildlife-associated recreation. Much of these lands are private rangelands and forestlands.  Land utilized for hunting accounted for 81% of that total, while land utilized for fishing and wildlife-watching, although comparatively small, likely includes riparian zones and areas with high environmental or amenity values. Hunters own or lease properties of larger size classes than anglers or wildlife-watchers, providing a possible economic incentive for maintaining large unfragmented properties that provide a variety of conservation benefits. Results show that Americans annually spend an estimated $814 million in day-use fees, $1.48 billion for long-term leases, and $14.8 billion to own private land primarily for wildlife-associated recreation. Hunting, in particular big game hunting, comprises some of the largest contributions to payments for wildlife-associated recreational use on private land. This finding suggests that hunting may be an important market-based mechanism to maintain large unfragmented parcels of wildlife habitat.  Chapter 3 utilizes interviews with a random sample of landowners in California to evaluate conservation practices associated with hunting enterprises. This study found relatively low adoption of hunting enterprises among landowners, and that there were mixed conservation outcomes associated with hunting. Landowners who enrolled in the California Department of Fish & Wildlifeâ€™s Private Land Management program, which provides enhanced game management rights to landowners in exchange for habitat improvement practices, performed the most comprehensive habitat improvement practices, including riparian zone restoration and adjustment of grazing practices to enhance cover and forage resources for wildlife. Many other landowners, however, earned some income from hunting, but either did not implement additional conservation practices to enhance wildlife habitat or performed practices that could cause some ecological problems, such as planting of feed crops that can create openings for invasive noxious weeds to be established on a property. This study found significant opportunities in California to not only increase adoption of hunting enterprises, but to engage in educational efforts to encourage ecologically-friendly wildlife management practices as a way to enhance both revenue from hunting enterprises and conservation outcomes. The final chapter focuses on the development of methods to better understand the population characteristics of the Columbian black-tailed deer (Odocoileus hemionus columbianus) in order to improve harvest recommendations. Using camera-traps on a 2,500 acre private ranch in San Benito County, California, the study estimates the density and sex ratios of deer by using a Bayesian spatial mark-resight model. It also evaluates the effect of using bait in developing population estimates. The study found that deer densities on the property are estimated to be 9.9 (SE 0.91) individuals/km2, and that antlered bucks make up only 11% (SE 1%) of the population. Bait increased encounter rates of deer by a factor of 3.7, showing that the use of bait can help reduce the length of time that cameras must be operational and may create more precise population estimates due to increased detectability of deer.In conclusion, this dissertation found the game management rights for hunting were important for economic return from hunting on private land, but without regulation may result in negative environmental impacts. Across the United States, hunting contributes significantly to landowner income, especially to properties of larger size classes in rangeland and forestry habitats, which suggests that hunting provides an economic incentive to maintain large unfragmented properties. In the context of California, programs that give landowners greater game management rights in exchange for habitat improvement practices resulted in benefits for landowners and the environment. Finally, this dissertation has developed a statistical model that can be utilized to evaluate population parameters for one of the most economically important game species in California. In sum, recreational hunting can provide income to the private landowner and with the appropriate regulations, education and management, can incentivize the enhancement and maintenance of wildlife habitat on private land.",ucb,,https://escholarship.org/uc/item/0jm6t2jx,,,eng,REGULAR,0,0
26,1462,Quantum Trajectories of a Superconducting Qubit,"Weber, Steven Joseph","Siddiqi, Irfan;",2014,"In quantum mechanics, the process of measurement is intrinsically probabilistic.  As a result, continuously monitoring a quantum system will randomly perturb its natural unitary evolution.  An accurate measurement record documents this stochastic evolution and can be used to reconstruct the quantum trajectory of the system state in a single experimental iteration.   We use weak measurements to track the individual quantum trajectories of a superconducting qubit that evolves under the competing influences of continuous weak measurement and Rabi drive. We analyze large ensembles of such trajectories to examine their characteristics and determine their statistical properties.   For example, by considering only the subset of trajectories that evolve between any chosen initial and final states, we can deduce the most probable path through quantum state space.  Our investigation reveals the rich interplay between measurement dynamics, typically associated with wavefunction collapse, and unitary evolution.  Our results provide insight into the dynamics of open quantum systems and may enable new methods of quantum state tomography, quantum state steering through measurement, and active quantum control.",ucb,,https://escholarship.org/uc/item/0k0687ns,,,eng,REGULAR,0,0
27,1463,Project Planning Algorithms: Lowering Cost and Improving Delivery Time in Capital Projects,"Jabbari, Arman","Kaminsky, Philip;",2020,"With the goal of developing models and approaches leading to better operation of large-scale project delivery supply chains, we interviewed a variety of consultants and project and supply chain managers (with a particular emphasis on oil and gas major capital project delivery) and asked them a set of questions so that we could better understand current capital project delivery views of supply chain management, inventory, risk management tools, and related topics (Appendix A). Our interviewees expressed surprisingly diverse opinions, particularly regarding the future of mega-project delivery and the need for more closely coordinating supplier deliveries with onsite needs.The work in the dissertation is particularly motivated by mega-projects in the oil and gas industry, and our goal is to build models that lead to better operation of capital project delivery supply chains. The characteristics of this industry, and of these projects, place specific requirements on project scheduling models, and many of the existing models in the literature do not meet these requirements. Our focus in this dissertation is to formulate models and develop approaches that are particularly useful for mega-projects in the oil and gas industry, and that enable the concurrent determination of the project schedule and inventory delivery times in order to efficiently manage the project supply chain, and to effectively control project delivery time and cost.We consider the Stochastic Resource-Constrained Project Scheduling Problem with inventory, where the objective is to minimize a weighted combination of the expected project makespan and the expected inventory holding costs. Motivated by the requirements of major oil and gas industry projects, we introduce a class of proactive policies for the problem. We develop several effective heuristics for this problem, as well as deterministic and probabilistic lower bounds on the optimal solution. In computational testing, we demonstrate the effectiveness of these heuristics and develop insights into the value of explicitly considering inventory in this setting.A related problem that arises is the scheduling of oil field drilling operations, where the goal is to maximize the expected revenue generated by oil extraction. For this problem, we build a model and propose a heuristic approach. We confirm the effectiveness of our heuristic approach by analyzing its performance compared to the current practice in a real-world case study. Our results demonstrate the potential to increase the efficiency and productivity of drilling operations significantly and to boost profitability by decreasing the time until wells start the extraction.Through our interviews, and through analysis in subsequent models, it is clear that suppliers, and the timely delivery of supplies, plays a critical role in the successful implementation of large-scale projects. In the context of oil and gas projects, our focus is on the suppliers that provide customized materials. While the bulk of this dissertation focuses on projects from the project plannerâ€™s point of view, we were also motivated to consider these problems from the perspective of the supplier, and hence, to consider scheduling models with due dates. We present a stylized model, where we consider sequencing decisions on a single processor, here representing a supplier, in an online setting where no data about the future incoming opportunities is available. With the goal of minimizing total weighted (modified) earliness and tardiness cost, we introduce a new scheduling policy, which we refer to as the list-based delayed shortest processing time policy, and develop lower and upper bounds on the performance of this policy.Finally, we consider an alternative view of managing construction in projects, a location-based method known as the Work Density Method for takt planning. Given a work space and the number of zones in which to divide that space, the so-called WoLZo problem is to identify the shape and dimensions of each zone while minimizing the peak in the tradesâ€™ workloads per zone. We model this problem and develop an optimization algorithm to divide a work space into zones while leveling work densities across trades in a process.The tools presented in this dissertation are useful for managing different elements of mega-projects and significantly advance the state-of-the-art in those areas. We confirm the effectiveness of these tools by analyzing their performance compared to current practice in real-world case studies as well as their performance over the benchmark test problems that are available in the literature.",ucb,,https://escholarship.org/uc/item/0xt4s766,,,eng,REGULAR,0,0
28,1464,Risk Management and Combinatorial Optimization for Large-Scale Demand Response and Renewable Energy Integration,"Yang, Insoon","Tomlin, Claire J;",2015,"To decarbonize the electric power grid, there have been increased efforts to utilize clean renewable energy sources, as well as demand-side resources such as electric loads. This utilization is challenging because of uncertain renewable generation and inelastic demand. Furthermore, the interdependencies between system states of power networks or interconnected loads complicate several decision-making problems. Growing interactions between power and energy systems and human agents with advances in sensing, computing and communication technologies also increase the need for personalized operations.In this dissertation, we present three control and optimization tools to help to overcome these challenges and improve the sustainability of electric power systems. The first tool is a new dynamic contract approach for direct load control that can manage the financial risks of utilities and customers, where the risks are generated by uncertain renewable generation. The key feature of the proposed contract method is its risk-limiting capability, which is achieved by formulating the contract design problem as mean-variance constrained risk-sensitive control. To design a globally optimal contract, we develop a dynamic programming solution method based on a novel dynamical system approach to track and limit risks. The performance of the proposed contract framework is demonstrated using data from the Electricity Reliability Council of Texas. The second tool is developed for combinatorial decision-making under system interdependencies, which are inherent in interconnected loads and power networks. For such decision-making problems, which can be formulated as optimization of combinatorial dynamical systems, we develop a linear approximation method that is scalable and has a provable suboptimality bound. The performance of the approximation algorithm is illustrated in ON/OFF control of interconnected supermarket refrigeration systems. The last tool seeks to provide a personalized control mechanism for electric loads, which can play an important role in demand-side management. We integrate Gaussian progress regression into a model predictive control framework to learn the customer's preference online and automatically customize the controller of electric loads that directly affect the customer's comfort. Finally, we discuss several future research directions in the operation of sustainable cyber-physical systems, including a unified risk management framework for electricity markets, a selective optimal control mechanism for resilient power grids, and contract-based modular management of cyber-physical infrastructure networks.",ucb,,https://escholarship.org/uc/item/0zh6b007,,,eng,REGULAR,0,0
29,1465,"Ecological Restoration for Community Benefit: People and Landscapes in Northern California, 1840-2010","Diekmann, Lucy Ontario","Huntsinger, Lynn;",2011,"Restoration has important ecological work to do, particularly maintaining biological diversity and repairing impaired ecological functions. In addition, many people anticipate and hope that restoration will also produce changes in and provide benefits to human communities. Although these expectations are widespread, relatively little is known about how well restoration projects achieve their goals generally, and even less about the social and cultural consequences of restoration work.This dissertation draws on the experiences of two communities in northwestern California--the American Indians and non-Indians who are part of the United Indian Health Services (UIHS) and the resource managers, scientists, and landowners who work together to implement restoration projects throughout Humboldt County--to explore the impact of ecological restoration on human communities that undertake, use, or are home to restoration projects. I used qualitative interviews along with a review of historical and contemporary documents to develop an understanding of restoration goals and outcomes that is grounded in the experiences of UIHS community members and members of the broader Humboldt County restoration community.UIHS community members share a vision of restoration that is rooted in cultural understandings of the relationship between people and the environment and in historical changes to the local landscape and American Indian communities that have affected their ability to enact this relationship and to apply key cultural values. In the contemporary cultural landscapes of northwestern California, UIHS community members' access to culturally significant places and natural resources is restricted. Restoration offers one way to restore a role for American Indians in the landscape through active management, traditional activities, and applications of cultural knowledge. I find that the process of restoring and using the Ku' wah-dah-wilth Restoration Area has had at least six outcomes that contribute to community wellbeing. These are: encouraging healthy behaviors; offering opportunities for cultural and environmental education; serving as a source of inspiration; facilitating community interaction; providing a culturally meaningful place that produces a range of positive emotional responses; and acting as positive symbol of living American Indian cultures. However, the Restoration Area's potential for meaningful change is constrained at present by the limited number of people who access the site or receive information about it and the relatively small number of opportunities to actively engage with the site.Members of the Humboldt County restoration community are also motivated by the hope that restoration will benefit communities culturally and economically. Although restoration contributes significantly to the county's economy and has led to relationship building and improved knowledge about local ecosystems, general uncertainty about restoration's community impacts suggests that restoration goals are not necessarily reflected in restoration outcomes. Taken together the experiences of these two communities indicate that restoration has a range of social and cultural outcomes. They also suggest that more effectively realizing cultural and social goals will take active planning, engagement with the broader political and social forces that have contributed to current conditions, ongoing involvement with restored sites to create opportunities for education and use, monitoring and evaluation of social outcomes, and attention to who is and who is not benefitting from restoration.",ucb,,https://escholarship.org/uc/item/1365d8cr,,,eng,REGULAR,0,0
30,1466,Development and Application of Oxidative Coupling Bioconjugation Reactions with ortho-Aminophenols,"Obermeyer, Allie","Francis, Matthew B;",2013,"The synthetic modification of proteins plays an important role in the fields of chemical biology and biomaterials science. As applications of protein-based materials continue to become more complex, improved methods for the covalent modification of proteins are needed. Although many methods for the modification of native and artificial amino acids exist, they often require long reaction times or lengthy syntheses of reactive substrates. This work describes the development and application of a suite of bioconjugation reactions that utilize ortho-aminophenols. The oxidative coupling of aniline residues with o-aminophenol substrates was optimized. Potassium ferricyanide was identified as an alternative, mild oxidant for this coupling. These new conditions enabled the use of the oxidative coupling reaction in the presence of free cysteines and glycoslated substrates. Aminophenols were also discovered to react with native residues on protein substrates in addition to artificial aniline moieties. Cysteine and the N-terminus were identified as the reactive residues. The oxidative coupling of o-aminophenols with the N-terminus was optimized to achieve high levels of modification on peptide and protein substrates. The oxidative coupling of anilines and o-aminophenols was applied to the synthesis of a targeted, virus-like particle and to the detection of protein tyrosine-nitration. Overall, these updated and novel oxidative coupling methods expand the utility ortho-aminophenols for the modification of proteins.",ucb,,https://escholarship.org/uc/item/15p1m5m0,,,eng,REGULAR,0,0
31,1467,Effects of Market Approaches to Green Technologies for the Poor: The Case of Improved Cookstoves,"Booker, Kayje Merrea","Huntsinger, Lynn;",2011,"""Sustainable"" or ""green"" technologies for the global poor have been proposed as solutions to the difficult problem of how to improve the lives of the world's poorest without contributing to climate change or other environmental catastrophes. While such technologies were once the domain of non-profit and government funded initiatives, theyare now increasingly developed and deployed through market mechanisms. Using improved biomass cookstoves as a representative technology, this dissertation seeks to assess the social and technological effects of this shift to market-based approaches for development and dissemination of sustainable technologies for the poor.Chapter 2 uses a Science and Technology Studies theoretical framework to follow the coproduction of the material form of improved biomass cookstoves and the cookstove movement from the 1960s to the present. The chapter shows that during the 1980s, particular conceptions and articulations of the problem that cookstoves were meant to solve led to a definition of technological ""improvement"" that included fuel efficiency, consistency of performance, and ability to scale quickly. This particular type of cookstove was much more compatible with mass-production than traditional artisanal production, creating social organizations that could mass-produce cookstoves, which then encouraged commercial approaches in order to recover costs. The move to a market-based approach was in part driven by and in part the cause of a particular kind of technology, demonstrating the mutual coproduction of the social and technological.Chapter 3 takes one market-based tool, intellectual property, and analyses the effect of deploying it in the realm of green technologies for the poor. Using the contrasting cases of UV Waterworks and the Berkeley-Darfur Stove the chapter identifies some of the salient social and technical characteristics that determine whether such effect is positive. The complex social arrangements involved in developing technologies for the poor mean that tools such as intellectual property can be useful but must be compatible with the organizations involved at the level at which the tool is targeted, each of which may have different orientations and incentives. The type of funding at each level, donor versus investor, appears to be a particularly important variable in predicting positive or negative outcomes.Chapter 4 examines one specific environmental policy market mechanism, the carbon market, and its role in stimulating technological change, invention, innovation, and dissemination (Schumpeter, 1942) in biomass cookstoves. It shows that carbon credits are thus far improving diffusion of current cookstoves but failing to stimulate innovation in cookstoves with stronger health and environmental impacts. Additionally, the chapter shows that the carbon market is influencing the selection of cookstoves for dissemination. The characteristics selected for are most compatible with centralized, mass production, which is likely to strengthen the shift towards these approaches.",ucb,,https://escholarship.org/uc/item/16v148bg,,,eng,REGULAR,0,0
32,1468,Seiberg-Witten and Gromov invariants for self-dual harmonic 2-forms,"Gerig, Chris","Hutchings, Michael;",2018,"For a closed oriented smooth 4-manifold X with $b^2_+(X)>0$, the Seiberg-Witten invariants are well-defined. Taubes' ""SW=Gr"" theorem asserts that if X carries a symplectic form then these invariants are equal to well-defined counts of pseudoholomorphic curves, Taubes' Gromov invariants. In the absence of a symplectic form there are still nontrivial closed self-dual 2-forms which vanish along a disjoint union of circles and are symplectic elsewhere. This thesis describes well-defined counts of pseudoholomorphic curves in the complement of the zero set of such near-symplectic 2-forms, and it is shown that they recover the Seiberg-Witten invariants (modulo 2). This is an extension of Taubes' ""SW=Gr"" theorem to non-symplectic 4-manifolds.The main results are the following. Given a suitable near-symplectic form w and tubular neighborhood N of its zero set, there are well-defined counts of pseudoholomorphic curves in a completion of the symplectic cobordism (X-N, w) which are asymptotic to certain Reeb orbits on the ends. They can be packaged together to form ""near-symplectic"" Gromov invariants as a map on the set of spin-c structures of X. They are furthermore equal to the Seiberg-Witten invariants with mod 2 coefficients, where w determines the ""chamber"" for defining the latter invariants when $b^2_+(X)=1$.In the final chapter, as a non sequitur, a new proof of the Fredholm index formula for punctured pseudoholomorphic curves is sketched. This generalizes Taubes' proof of the Riemann-Roch theorem for compact Riemann surfaces.",ucb,,https://escholarship.org/uc/item/1730608x,,,eng,REGULAR,0,0
33,1469,Pathway and organelle engineering for production of useful chemicals in yeast,"Grewal, Parbir","Dueber, John E;Clark, Douglas S;",2020,"Researchers in the field of metabolic engineering aim to develop processes to produceuseful chemicals, sustainably and responsibly, using biotechnology. These processes areoften designed to replace products derived from fossil fuels, which are unsustainable andcontribute to climate change, or plant-based products, which compete with foodproduction for scarce land and are subject to supply uncertainty due to weather, cropdisease, and climate change. Here, we present two research projects in metabolicengineering. First, we demonstrate microbial production of the red food dye betanin byengineering the betalain biosynthesis pathway into yeast. Betanin is currentlymanufactured through extraction from red beets specifically grown for dye production.We achieved betanin production levels of 17 mg/L, which is equivalent to the amount ofbetanin found in 10 g/L of beet extract. With further production improvements, thisbioprocess may become cost-competitive with agricultural production and is likely tolead to a purer product. We also demonstrate the synthesis of a suite of non-naturalbetalain dyes achieved through feeding of diverse amines to a yeast production host,including several which have never been reported. In the second research project, wediscover that an enzyme that limits production levels of a drug family is toxic to the yeastproduction host. This enzyme, norcoclaurine synthase, is critical to the production ofbenzylisoquinoline alkaloids, an important family of medicines that are extracted fromplants like the opium poppy. We devised a novel subcellular compartmentalizationstrategy, sequestering norcoclaurine synthase in the peroxisome to alleviate cytotoxicitywhile maintaining access to the enzymeâ€™s substrates. By targeting norcoclaurine synthasefor organellar compartmentalization, we achieved improved cell growth, final titer, andculture productivity. These projects highlight the potential of engineering complex plantpathways into microbial hosts for economical and sustainable chemical production.",ucb,,https://escholarship.org/uc/item/17p341hd,,,eng,REGULAR,0,0
34,1470,Slow Photoelectron Velocity-Map Imaging of Transient Species and Infrared Multiple Photon Dissociation of Atmospherically Relevant Anion Clusters,"Yacovitch, Tara Irene","Neumark, Daniel M;",2012,"Two different types of vibrationally resolved spectroscopies are used in the experimental study of reactive species: slow-electron velocity map imaging (SEVI) and infrared multiple photon dissociation (IRMPD).SEVI spectroscopy is used to study the series of vinoxy and substituted vinoxy radicals: vinoxy (H2C=CH-O), i-methylvinoxy (H2C=C(-O)-CH3) and n-methylvinoxy (H3C-HC=CH-O). Vibrational resolution of their ground and first excited electronic states is achieved, leading to accurate measurement of electron affinities, term energies and vibrational frequencies. Radical geometries are deduced and conformational isomers for the larger species are identified. The i-methylvinoxy radical is found to be most stable when the methyl substituent is eclipsed in the ground-state radical and staggered in the excited state radical and ground state anion. Both cis and trans isomers of the n-methylvinoxy radical are observed, with the lower-energy cis isomer contributing to most of the spectral peaks. The SEVI experiment is also used to study the transition state region of the F + H2 and F + CH4 reactions. The F + H2 results improve on previous spectra, resolving narrow features and suggesting that additional theoretical treatment is necessary to fully describe and assign the experimental results. The entrance valley of the F + CH4 reaction coordinate is measured, showing extended structure attributed to bending or hindered rotation of the methane moiety. The significance of these results in terms of reactive resonances is discussed.The final SEVI experiments involve a series of alkoxy radicals and their sulfur-substituted analogs: methoxy (CH3O), thiomethoxy (CH3S), ethoxy (CH3CH2O),  thioethoxy (CH3CH2S), i-propoxy ((CH3)2CHO) and n-propoxy (CH3CH2CH2O). The two lowest electronic states are close in energy (or formally degenerate) leading to a slew of nonadiabatic effects such as vibronic coupling from the Jahn-Teller or pseudo-Jahn-Teller effect and spin-orbit splitting. Precise determinations for the electron affinities and splittings between the electronic states are made. Variation of the size, symmetry and O/S atoms significantly affects the potential energy landscape of these radicals, leading to drastically altered spectra governed by differing contributions of the various nonadiabatic effects. IRMPD spectra of negatively charged cluster species containing inorganic acids and water are studied, revealing structural information and size-dependent trends. The small bisulfate-water clusters, HSO4-(H2O)n, show lengthening of the acidic bond in the bisulfate anion, H-OSO3-. This is observed through the characteristic SOH bending vibration. The small mixed clusters of sulfuric and nitric acid, HSO4-(HNO3), NO3-(H2SO4)(HNO3) and HSO4-(H2SO4)(HNO3), show charge localization effects that in some cases counter the structural assumptions made based on the gas phase acidities of the molecular acids. Finally, the clusters containing bisulfate, sulfuric acid and water, HSO4-(H2SO4)m(H2O)n show the recurrence of the triply hydrogen-bound HSO4-(H2SO4) configuration for n = 0, while incorporation of water disrupts this stable motif for clusters with m > 1.",ucb,,https://escholarship.org/uc/item/1862c66d,,,eng,REGULAR,0,0
35,1471,Variability Modeling and Statistical Parameter Extraction for CMOS Devices,"Qian, Kun","Spanos, Costas J;",2015,"Semiconductor technology has been scaling down at an exponential rate for many decades, yielding dramatic improvements in power, performance and cost, year after year. Todayâ€™s advanced CMOS transistors have critical dimensions well below 24nm. This means that controlling the manufacturing process is increasingly difficult. Process and material fluctuations cause device and circuit characteristics to deviate from design goals, and introduce significant device-to-device variability due to spatial variations across silicon wafers. Accurate modeling of these spatial process variations has become critical to both foundries and circuit designers that seek optimal power/speed/area balance. To understand the nature of spatial process variations, we first carried out a comprehensive variability analysis of data measured from thousands of variability-sensitized test structures, including ring oscillators, SRAM bit cells and their internal transistors. We manufactured these test chips using early stage 90nm and 45nm commercial semiconductor processes. We proposed a hierarchical variability model to capture the systematic and random components of device parameter variations across silicon wafers, and across chips. The detailed decomposition of the process variation profile reveals significant across-wafer systematic component for the delay and leakage of ring oscillators, and across-chip systematic component for the read/write margins of SRAM bit cells, as well as their internal transistors. The proper modeling of each hierarchical component proved to be crucial for the accurate estimation of the statistics of device performance distribution and its parametric yield.The knowledge gained about process variation from carefully designed test structures was leveraged into estimating the variation and parametric yield of new devices and circuits. This was accomplished by improved the statistical compact model parameter extraction methodology, and by proposing a stepwise parameter selection method. We used a normalized notional confidence interval and, and the sum of squares of fitting residuals as extraction and fitting quality criteria. This allowed us to determine the essential model parameters for accurate fitting over a large number of transistors. We applied this methodology to EKV and PSP with both simulated and experimental data, demonstrating its effectiveness. Finally, we combined the results from statistical parameter extraction with the hierarchical spatial variability model. This, compared to traditional methods, produced much-improved estimates of device performance and manufacturing yield.",ucb,,https://escholarship.org/uc/item/19x656kn,,,eng,REGULAR,0,0
36,1472,"Gravure-printed electronics: Devices, technology development and design","Grau, Gerd Fritz Milan Nino","Subramanian, Vivek;",2016,"Printed electronics is a novel microfabrication paradigm that is particularly well suited for fabrication of low-cost, large-area electronics on flexible substrates. Applications include flexible displays, solar cells, RFID tags or sensor networks. Gravure printing is a particularly promising printing technique because it combines high print speed with high resolution patterning. In this thesis, gravure printing for printed electronics is advanced on multiple levels. The gravure process is advanced in terms of tooling and understanding of printing physics as well as its application to substrate preparation and device fabrication.Gravure printing is applied to transform paper into a viable substrate for printed electronics. Paper is very attractive for printed electronics because it is low-cost, biodegradable, lightweight and ubiquitous. However, printing of high-performance electronic devices onto paper has been limited by the large surface roughness and ink absorption of paper. This is overcome here by gravure printing a local smoothing layer and printed organic thin-film transistors (OTFTs) are demonstrated to exhibit performance on-par with device on plastic substrates.If highly-scaled features are to be printed by gravure, traditional gravure roll making techniques are limited in terms of pattern definition and surface finish. Here, a novel fabrication process for gravure rolls is demonstrated utilizing silicon microfabrication. Sub-3Î¼m features are printed at 1m/s. Proximity effects are demonstrated for more complex highly-scaled features. The fluid mechanics of this effect is studied and it is suggested how it can be used to enhance feature quality by employing assist features.Finally, advancements are made to printed organic thin-film transistors as an important technology driver and demonstrator for printed electronics. First, a novel scanned thermal annealing technique is presented that significantly improves the crystallization of an organic semiconductor and electrical performance. Second, transistors are fully gravure printed at a high print speed of 1m/s. By scaling both lateral and thickness dimensions and optimizing the printing processes, good electrical performance, low-voltage operation and low variability is demonstrated.",ucb,,https://escholarship.org/uc/item/1bn3t372,,,eng,REGULAR,0,0
37,1473,Actomyosin mediated tension orchestrates thermogenic programs in adipocytes,"Tharp, Kevin Menard","Stahl, Andreas;",2017,"Innovative approaches to shift energy balance are urgently needed to combat metabolic disorders such as obesity and diabetes. One promising approach has been the expansion or activation of thermogenic adipose tissues to improve metabolic homeostasis. My doctoral studies presented in the following text have identified novel approaches to translate adipose based metabolic therapeutics and the underlying mechanisms by which thermogenic adipocytes establish their therapeutically applicable metabolic capacity.In chapter I, I present a novel biomaterial technology optimized to expand metabolically beneficial thermogenic adipose depots in vivo. This system enabled me to determine the degree of metabolic enhancement possible with the exogenous expansion of thermogenic adipose depots. To generate therapeutic adipose implants I modified hyaluronic acid-based hydrogels to support the differentiation of white fat derived multipotent stem cells (ADMSCs) into lipid accumulating, uncoupling protein 1 (UCP1) expressing thermogenic adipocytes. Subcutaneous implantation of the synthetic tissues successfully attracted host vasculature and persisted for several weeks and the implant recipients demonstrated elevated core body temperature during cold challenges, enhanced respiration rates, improved glucose homeostasis, and reduced weight gain demonstrating the therapeutic merit of this highly translatable approach.In chapter II, I outline the experimentation leading to the discoveries presented in chapter III as well as thoroughly review pertinent tissue engineering strategies. Specifically, I sought to define the mechanism by which synthetic ECM components identified in chapter I could alter differentiation outcomes of preadipocytes to yield greater thermogenic capacity. In chapter III, I demonstrate that actomyosin-based mechanical responses provide a critical differentiation cue for the development of thermogenic adipocytes. Since I had determined that the hydrogel optimization techniques described in chapter I were likely acting through cytoskeletal-mediated processes I examined the role of cytoskeletal structure and tension in thermogenic adipose development. I identified that the muscle-like gene expression patterns of UCP1+ adipocytes are critical for the acute induction of oxidative metabolism and uncoupled respiration and regulate mechanosensitive transcriptional co-activators, YAP/TAZ, that control thermogenic gene expression.This dissertation establishes the role of physical mechanics in the development and function of thermogenic adipocytes which may engender future metabolic therapeutics.",ucb,,https://escholarship.org/uc/item/1g26d365,,,eng,REGULAR,0,0
38,1474,"""Other Lovings"": Abjection, Love Bonds, and the Queering of Race","Lee, Seulghee","JanMohamed, Abdul;",2014,"This dissertation discusses the intersection of racial abjection and love bonds in late 20th-century and 21st-century African-American and Asian-American literature and culture. The manuscript deploys affect studies and queer theory to discuss works by Audre Lorde, Amiri Baraka, David Henry Hwang, Adrian Tomine, and Gayl Jones, in addition to the cultural phenomena of ""Linsanity"" and ""afro-pessimism."" Whereas most critical readings of failed love in minority literature have emphasized the tragic interpersonal consequences of internalized racism, this dissertation argues that these writers narrate love's apparent failure in order to explore the positive content emergent in the felt rupture of breakups. Through readings of dissolved love relationships in these authors' works, I inquire into love's operation as an affect that always desires more and better sociality. The appearance of love's failure is precisely what illuminates the ineluctably positive content of love, and I situate this content in the context of recent theoretical discussions of love as narcissistic, not-yet-here, oppressive, or antisocial. The project ultimately argues that blackness, yellowness, and queerness share a privileged access to and familiarity with love's affective positivity.",ucb,,https://escholarship.org/uc/item/0mw1p6xm,,,eng,REGULAR,0,0
39,1475,Phonological Encoding and Phonetic Duration,"Fricke, Melinda",,2013,A Contrastive Study of the Grammatical Structures of Aymara and Cuzco Kechua,ucb,,https://escholarship.org/uc/item/0q71t6xk,,,eng,REGULAR,0,0
40,1476,A Convenient Partnership: The Ribosome and the Nascent Chain Interact to Modulate Protein Synthesis and Folding,"Goldman, Daniel Hershel","Bustamante, Carlos J;",2015,"During translation, the ribosome reads the genetic code of the messenger RNA, adding one amino acid at a time to the nascent protein. The sequence of the polypeptide determines the three dimensional structure of the natively folded protein, and thus encodes its biological activity. Because folding rates are often fast compared to translation, many proteins likely undergo folding transitions during synthesis, with folding potentially modulated by the sequential appearance of the polypeptide and the chemical environment of the ribosome. Traditional experimental approaches to study protein folding employ chemical, temperature or pH-induced denaturation and would irreversibly destroy the ribosome; thus, such techniques cannot be used to probe folding on the ribosome. In this work, we implement a novel single-molecule optical tweezers assay to probe folding transitions of the nascent polypeptide as it emerges from the ribosome. We demonstrate that the ribosome can modulate the kinetics of folding through interactions between the nascent chain and the charged ribosomal surface. Additionally, the ribosome can prevent misfolding of incompletely synthesized protein fragments. These observations point to a chaperone-like role for the ribosome in guiding the nascent protein to its native state.In addition to interacting with the exterior of the ribosome, some nascent chain sequences can form specific contacts with the ribosome exit tunnel. These contacts lead to conformational changes of the ribosome, and reduced translation rates. The Secretion Monitor protein stalls the ribosome upon translation of a 17 amino acid motif. Arrest release requires targeting of the stalled ribosome-nascent chain complex to the translocon; thus, it has been hypothesized that arrest is released by a mechanical pulling force generated as the polypeptide is translocated across the membrane. By applying force to the nascent polypeptide of stalled ribosomes, we demonstrate that translation arrest at SecM is released by mechanical force. Additionally, we show that the force needed to release stalling can be generated by a protein folding in close proximity to the ribosome tunnel exit. Our results demonstrate the feasibility of a feedback mechanism, whereby a folding protein can modulate its synthesis through the generation of force. More generally, since the nascent polypeptide in the cell can undergo a number of potentially force-generating eventsâ€“chaperone binding, protein or ligand binding, translocation and membrane insertionâ€“force applied to the nascent chain may be an important modulator of protein synthesis.",ucb,,https://escholarship.org/uc/item/0rh988bb,,,eng,REGULAR,0,0
41,1477,"An Athenian Commentary on Plato's Republic: Poetry, science and textual engagement in Proclus' In Rem.","Pass, David Blair","Long, Anthony;Ferrari, G.R.F.;",2013,"Proclus' Commentary on Plato's Republic is the only extant ancient Greek commentary on Plato's Republic.  Despite the fact that it includes discussions of most of the major parts of the book, it has received very little scholarly attention.  This dissertation introduces the work in its entirety and tries to identify some of the most important contributions it can make to philosophical and philological scholarship on the Republic.  I am particularly attentive to ways in which Proclus' concerns--such as responding to Epicurean critiques of Platonic myth or defending Homer--may help us see Plato's work in its cultural context.The first chapter focuses on introducing the work and answering basic questions about the place of the Republic in late antique Platonism, the extent of Proclus' sources and what portions of the Republic Proclus discusses.  I consider the form of the commentary, arranged as various essays, in comparison with Proclus' other commentaries which proceed in a line by line manner.  I respond to arguments that have claimed that the commentary is not a unified work by considering the form and extent of the essays relative to the content of the Republic.The second chapter argues that Proclus' commentary is not trimming the Platonic tradition to fit into the religious orthodoxy of late antiquity but rather stressing arguments and interpretative approaches that became most influential in the Renaissance.  I consider several examples such as Proclus' interest in the Orphic and Pythagorean tradition, his emphasis on gender equality and the scientific aspects of his approach to natural philosophy.The third chapter considers some important aspects of Proclus' hermeneutics.  I consider how and why Proclus sometimes disagrees with Plato.  In particular, I focus on some portions of the commentary that demonstrate Proclus' approach to the dramatic aspects of the dialogues and discuss why Proclus' defence of Homer includes some observations about his Platonic hermeneutics.  I consider also his responses to Aristotle's idea of catharsis and his approach to Glaucon's role in the Republic.The fourth chapter translates and discusses a particular portion of the sixth essay in which Proclus argues, contrary to the view Socrates expresses in the Republic, that Homer is a text which teaches the political virtue of sophrosune.  I consider the historical origins of allegorizing interpretations and then distinguish between Proclus' use of allegory and his use of other interpretative methodologies.  I consider in particular Proclus' defence of the idea of euphrosune and compare his approach with earlier philosophical discussions which responded to the same passage of Homer (Odyssey 9.6-10) and interrogated the passage along the lines suggested in the Republic.",ucb,,https://escholarship.org/uc/item/0sn280zv,,,eng,REGULAR,0,0
42,1478,Impacts of Cloud Microphysics on Extreme Precipitation and Lightning,"Charn, Alexander Benedict","Collins, William D;",2020,"The microphysical processes involving water droplets and ice crystals in clouds are too small to be explicitly simulated by climate and weather models. Nevertheless, they play a critical role in the large-scale energy balance of the Earth and its atmosphere, as well as smaller-scale phenomena such as storms. This dissertation examines the impact of microphysics on the latter, specifically extreme precipitation and lightning. Climate change threatens to exacerbate such events, making the understanding of such extremes crucial.We focus primarily on the effects of microphysical processes as they are simulated in a superparameterized climate model, which is better suited to studying clouds and the associated extreme weather events than conventional models. We find statistically significant differences in extreme precipitation rates via two separate mechanisms when replacing one commonly used microphysics parameterization with another. We also find that the sign of changes in lightning flash rates with global warming depends on the microphysics representation used. Finally, we employ observations to address a longstanding question about the necessity of ice as a precursor of lightning. With the data available it is concluded that there is insufficient evidence to suggest that thunderstorm electrification can occur in the absence of ice.",ucb,,https://escholarship.org/uc/item/0sw3x7qx,,,eng,REGULAR,0,0
43,1479,"Cities on the Periphery: Urbanization in Bithynia, Pontus, and Paphlagonia under the Roman Empire","PITT, ERIN MIKAEL","NoreÃ±a, Carlos;",2016,"This dissertation, entitled â€œCities on the Periphery: Urbanization in Bithynia, Pontus, and Paphlagonia under the Roman Empire,â€ seeks to provide the first comprehensive urban history of the region during the period of Roman rule. Modern scholarship on this region has focused on cultural and political topics, including Greek reactions to Roman rule; provincial elites and euergetism; and urban life. This scholarship has ignored dramatic increases in the number of new settlements in north central Anatolia, urban and rural, as well as consistent vitality and even growth during the turbulent 3rd century CE. I address these lacunae and investigate the factors behind this growth and stability. I analyze the complexities of this development across four frameworks: the construction and finance of civic monuments, shifting settlement patterns, the extent of bulk and prestige goods networks, and integration into networks of administration, military affairs, and imperial ideology.The introductory first chapter documents the dramatic increases in the number of urban and rural settlements in the region and poses a set of key questions regarding urbanization, imperial intervention, and local stability. I then set out the methodology of my dissertation. I briefly review and critique previous scholarship on this region, which has focused mainly on cultural and political topics of urban and imperial life. I then indicate the advantages of shifting the focus to consider the diachronic nature of urbanization over the long term, the archaeological record, integration and connectivity, and interpretive questions that address the uniqueness of the region. My approach is highly interdisciplinary, making heavy use of evidence from archaeological surveys, epigraphic finds, and network theory, as well as ancient literary and historical accounts.The second chapter examines how local preferences and financial resources influenced the construction and use of civic monuments. The emphasis on Graeco-Roman cities as lived environments, not synchronic monumental landscapes, plays a critical role in this analysis. My discussion qualifies recent assertions that cities in the eastern empire expressed their Greek identity by building democratic monuments with public money. Monuments such as theaters and temples are clearly prioritized, yet cities also enthusiastically adopted monuments marked as Roman, such as baths, or used democratic structures for Roman entertainment. Though civic funds remained a consistent resource, the patronage of local elites and the emperor were essential in the 1st and later 3rd and 4th centuries, respectively. The third chapter synthesizes five decades of archaeological survey. I identify broad trends in expansion, size, and continuity from the Iron Age to the Late Roman period and assess the extent of Roman influence behind these fluctuations. Administrative, economic, and military priorities guided the efficient management of this region. This was achieved by the creation of a few new cites and by an extensive road network. Both constituted unique developments and indirectly encouraged the proliferation of small towns and villages, which benefitted from the demands of regional capitals and access to roads. This produced a balanced urban system that fashioned a robust administrative hierarchy, but that was relatively moderate in overall urban density. The fourth and fifth chapters discuss connectivity across a range of landscapes: city and hinterland, the Black Sea area, and the Mediterranean basin as a whole. The third chapter focuses on the circulation of staple goods and luxury items. This area was remarkably well integrated and even self-sufficient at the local and regional levels. Its position on the periphery of the Roman empire limited intensive contact with the broader Mediterranean, but encouraged intensive commercial relationships with the Black Sea, Armenia, and Syria. The fourth chapter also examines connectivity, but in the context of imperial administration, communication, and military activity.This project ultimately seeks to provide the first comprehensive synthesis of the urban history of north central Anatolia in the Roman period. Roman intervention and traditional urban ideals were early stimuli; as I argue, however, regional preferences, a geographical position on the Mediterranean periphery, and heightened imperial interests in the 3rd century were the most prominent influences on urban development and stability in north central Anatolia. The region occupied a unique geographical, political, and economic position within the Roman empire and it represents a compelling contrast to the urban character of other Roman provinces. I conclude by stressing the complexity of the urban development of this region as well as the strong role that local traditions and geographical position played in negotiating imperial interaction.",ucb,,https://escholarship.org/uc/item/0t88x6h9,,,eng,REGULAR,0,0
44,1480,Syntactic Agreement in Bilingual Corpora,"Burkett, David","Klein, Dan;",2012,"The task of automatic machine translation (MT) is the focus of a huge variety of active research efforts, both because of the intrinsic utility of this difficult task, and the theoretical and linguistic insights that arise from modeling relationships between natural languages. However, MT systems that leverage syntactic information are only recently becoming practical, and in a typical system of this sort, syntactic information is generated by monolingual parsers; the task of explicitly modeling syntactic relationships between target and source languages is yet to be fully explored.This thesis investigates the problem of finding syntactic parse trees of target and/or source sentences that are more appropriate for use in a syntactic MT system. Two basic methodologies are explored.First, we present a sequence of two statistical models that leverage bilingual information to improve the linguistic quality of syntactic parses, as measured by their ability to replicate human-generated gold-standard annotations. The first model uses word to word alignments as an external source of information, while the second models the alignments jointly. These models are both quite effective at improving the intrinsic quality of the parse trees, and the second model additionally improves word alignment performance. However, while the two models achieve similar parsing improvements, we find that improving parses in conjunction with word alignments is much more helpful for the downstream machine translation task.In the next part of the thesis, we explore this finding further by investigating the effects on MT performance of agreement between parse trees and word alignments. We present a simple method for transforming input trees in a way that ignores gold-standard annotations, concentrating instead on improving syntactic agreement directly. In experiments, we find that though we obviously lose fidelity to more linguistically informed treebank annotation guidelines, this transformation-based approach yields the strongest improvements in syntactic machine translation.",ucb,,https://escholarship.org/uc/item/0k07m9zb,,,eng,REGULAR,0,0
45,1481,Wetland water flows and interfacial gas exchange,"Poindexter, Cristina Maria","Variano, Evan A;",2014,"The flow of water in wetlands may exert significant influence on wetland biogeochemistry, and specifically interfacial gas exchange.  Measuring currents in wetlands requires caution.  The acoustic Doppler velocimeter (ADV) is widely used for the characterization of water flow and turbulence.  However, deployment of ADVs in low-ï¬‚ow environments is hampered by a unique source of bias related to the ADV's mode of operation.  The extent of this bias is revealed by Particle image velocimetry (PIV) measurements of an ADV operating in quiescent fluid.   Image-based flow measurement techniques such as PIV may provide improved accuracy in low-flow environments like wetlands.  Such techniques were applied to observe wind-driven flows in a wetland with emergent vegetation and investigate the effects of the wind shear on gas transfer across the air-water interface.  Wind speed is the parameter most often used to model interfacial gas exchange in other aquatic environments.  In wetlands with emergent vegetation, the emergent vegetation will attenuate wind speed above the water surface, modify fluid shear at the water surface, and influence stirring beneath the water surface.  Direct measurements of gas transfer in a model wetland in the laboratory indicated that unless wind speeds are extreme, interfacial gas transfer in wetlands is typically dominated by another physical force: surface cooling-induced thermal convection.  In an application of these lab results, gas transfer across the air-water interface due to thermal convection in the water column is shown to account for a sizable portion of total methane fluxes from a restored marsh in California's Sacramento-San Joaquin Delta.",ucb,,https://escholarship.org/uc/item/1191m1hx,,,eng,REGULAR,0,0
46,1482,"Nanoscale Optical Devices: Force, Torque and Modulator","Liu, Ming","Zhang, Xiang;",2010,"Manipulating and utilizing light in nanoscale are becoming tasks of not only scientific interest, but also industrial importance. My research includes two major topics in nanoscale optics: 1. Nanoscale optical motor. 2. Optical modulator based on novel materials.Light carries both linear and angular momentum, and therefore generating force or torque with light is feasible. The ability to provide torque in nano-meter scale opens up a new realm of applications in physics, biology and chemistry, ranging from DNA unfolding and sequencing, to active Nano-Electro-Mechanical Systems (NEMS). In the first part of this dissertation, I demonstrate a nano-scale plasmonic structure generating a significantly large rotational force when illuminated with linearly-polarized light. I show that a metallic particle with size of 1/10 of the wavelength is capable of rotating a silica microdisk, 4,000 times larger in volume. Furthermore, the rotation velocity and direction can be controlled by merely varying the wavelength of the incident light, thereby inducing different plasmonic modes which possess different torque directions. The tiny dimensions along with the tremendous torque may have a profound impact over a broad range of applications such as energy conversion, and in-vivo biological manipulation and detection.Compared with the interaction between particles and photons, the optical force between particles is of fundamentally important as well. In the end of the first part, I propose a new technique to measure the optical binding forces between two plasmonic particles. By using localization technique on a build-in cantilever, I prove the potential to measure the force with accuracy up to sub-pico-Newton.The second part of this dissertation is about the modulation of light, an optical modulator. Integrated optical modulator with high modulation speed, small footprint and large optical bandwidth is poised to be the enabling device for on-chip optical interconnects. However, present devices suffer from intrinsic narrow-bandwidth aside from their sophisticated optical design, stringent fabrication, temperature tolerances and large foot print. By using graphene, a monolayer of carbon atoms, I experimentally demonstrated a broadband, high-speed, waveguide-integrated electroabsorption modulator. The extremely strong interaction between light and relativistic electrons in graphene allows us to integrate an optical modulator within an ultra-small footprint while operating at a high speed with broad bandwidth under ambient conditions. Even monolayer of being less than 1 nm in thickness, its modulation effectiveness is comparable with the best materials like Ge and SiGe with tens nanometers. In addition, the athermal optoelectronic properties of graphene make the device immune to harsh operation environments, in sharp contrast to all existing semiconductor approaches.",ucb,,https://escholarship.org/uc/item/12f6b8rg,,,eng,REGULAR,0,0
47,1483,"Total Synthesis of (+)-Spectinabilin, Taiwaniaquinoids, Synthetic Progress toward Aspergillin PZ, and Synthesis of a Photoswitchable Agonist of Glutamate Receptor-dMAG","Xu, Yue","Trauner, Dirk;",2010,"A new and highly enantioselective synthetic route to Î³-methoxypyranone addressed the long unsolved racemization problem in literature. A concise total synthesis of (+)-Spectinabilin was achieved with this method in 10 linear steps. Concept of kinetic resolution with temporary stereocenter was used to improve the enantiomeric excess.A new variant of Nazarov reaction, aromatic Nazarov triflation was discovered which allowed rapid access of polycyclic ring skeleton. The triflation product, indene triflate, was further elaborated with modern palladium cross coupling methods in the total syntheses of many taiwaniaquinoid natural products. Also, the triflation method worked well with electron rich and neutral substrates and was not compatible with electron deficient substrates.Effort toward total synthesis of Aspergillin PZ was described. The biomimetic synthetic hypothesis was pursued. Synthesis of all components was achieved. Future work would be focused on mild reaction condition to bring all components together to for the key intermediate for Aspergillin PZ.Finally, based on the similar principle of previous work in our group, a photoswitchable agonist for metabotropic glutamate receptors was designed and synthesized. Preliminary results confirmed the agonist activity and reversible isomerization with radiation of light of different wavelengths. Further studies are under investigation under collaboration.",ucb,,https://escholarship.org/uc/item/1365h97h,,,eng,REGULAR,0,0
48,1484,"Low Power, Crystal-Free Design for Monolithic Receivers","Wheeler, Bradley","Pister, Kristofer S.J.;",2019,"Predictions of the proliferation of hundreds of billions of connected wireless devices have yet to come true.The economics of such deployments becoming feasible require that current wireless modules become smaller, cheaper, and use less power.A typical wireless device combines a RF System-on-Chip with multiple frequency references, passive components, an antenna, and a battery on a printed circuit board.The Single Chip Mote project aims to reduce the size, weight, power, and cost of these devices by eliminating the off-chip frequency references and passives.The ultimate goal being to form a 2.4 GHz wireless node by attaching only an antenna and energy source to a single CMOS die.Of particular interest is the range of applications this could enable where the size and weight of current wireless devices has prohibited their use.This work implements a crystal-free IEEE 802.15.4 receiver that covers the data path from RF to bits.The receiver utilizes a passive front-end to reduce power and quadrature down-conversion followed by on-chip filtering and digitization.Integrated digital baseband is included for demodulation and clock recovery as well as built-in estimation of the errors in the RF channel frequency and data rate.Initial frequency calibration is performed simultaneously with bootloading using contact-less optical programming.Operation across the 0 - 70 C commercial temperature range has been demonstrated while inter-operating with commercial off the shelf IEEE 802.15.4 devices.The analog portion of the receiver, including the free-running LO, consumes 1.03 mW from a 1.5 V battery while achieving a sensitivity of -83 dBm.",ucb,,https://escholarship.org/uc/item/13f3h6hd,,,eng,REGULAR,0,0
49,1485,"Living Taiwanese Opera: Improvisation, Performance of Gender, and Selection of Tradition","Hsu, Pattie","Wade, Bonnie C.;",2010,"This dissertation investigates the culture and cultural production of itinerant, professional Taiwanese opera performers in Taipei's temple circuit.  I argue that the community of actors and musicians and their occupational and lifestyle practices constitute a subculture that is central to both maintaining and transforming Taiwanese opera.  Drawing on ethnographic research, I characterize the opera subculture's idiosyncratic and fluid features, examine the major ways in which they are manifested--namely in improvisation, performance of gender, and selection of tradition--and discuss the cultural work they perform.Full-time, for-profit troupes--the focus of my research--primarily work for temple patrons in privately contracted performances and occasionally in government-sponsored events.  Performances in the former venue are improvised or, as the performers describe it, ""alive,"" whereas the latter type privileges written practices and marginalizes oral conventions.  I assert that improvisation, a distinctive and crucial attribute in the temple-contracted context, is an imperative performance skill for producing unscripted stories and a professional strategy for adapting to new circumstances.  My analyses of improvisation as a performance skill highlight actor-musician interactions in song performance that shows spontaneous musical processes in opera production.  Improvisation, or the ability to be flexible, is a professional strategy with which performers operate enabling them to maintain the appeal of a traditional art in a rapidly changing cosmopolitan society.  In particular, I argue that the socioeconomic situation in recent decades and the developing hybrid opera style in the temple context opened a space for an alternative model of gender performance, one that expresses female masculinity.  Moreover, improvisation as a professional strategy enables performers to adapt to the demands of recently developed government-sponsored events and participate in a hegemonically-constructed process for selecting a dominant version of the Taiwanese opera tradition.  Through three case studies, I posit that the performers' flexible approach in this process constructs multiple versions of the opera tradition, thereby disrupting authoritative attempts at claiming a singular mode of production.Through these analyses, I suggest that Taiwanese opera is a living tradition with continually shifting conventions and cultural meanings.  The performers rapidly adjust to different and new ways of performance in order to capitalize on opportunities, ensure the cultural relevancy of their creative production, and secure their livelihood.",ucb,,https://escholarship.org/uc/item/1471d868,,,eng,REGULAR,0,0
50,1486,A role for host activation-induced cytidine deaminase in innate immune defense against herpesviruses,"Bekerman, Elena","Coscoy, Laurent;",2013,"Activation-induced cytidine deaminase (AID) is specifically induced in germinal center B cells to carry out somatic hypermutation and class-switch recombination, two processes responsible for antibody diversification. Because of its mutagenic potential, AID expression and activity are tightly regulated to minimize unwanted DNA damage. Surprisingly, AID expression has been observed ectopically during pathogenic infections. However, the function of AID outside of the germinal centers remains largely uncharacterized. This dissertation demonstrates that infection of human primary naive B cells with Kaposi's sarcoma-associated herpesvirus (KSHV) rapidly induces AID expression in a cell intrinsic manner. We find that infected cells are marked for elimination by Natural Killer cells through upregulation of NKG2D ligands via the DNA-damage pathway, a pathway triggered by AID. Moreover, AID impinges directly on the viral fitness by inhibiting lytic reactivation without having a measurable effect on KSHV latency. We extend this analysis to the murine homologue of KSHV, MHV68 and find that AID mutates the viral genome at a rate that exceeds normal somatic mutation by several orders of magnitude. The tremendous mutational load accumulated by sequential passaging of MHV68 through AID-expressing cells leads to the eventual inactivation of the virus. Importantly, we uncover two KSHV-encoded microRNAs that directly regulate AID abundance, further reinforcing the value of AID in the antiviral response. Together our findings reveal an additional role for AID in innate immune defense against herpesviruses with implications for a broader role in innate immunity to other pathogens.",ucb,,https://escholarship.org/uc/item/15150708,,,eng,REGULAR,0,0
51,1487,A Study of Electrolytic Processes in Micro-Electroporation and Electroporation,"Meir, Arie","Rubinsky, Boris;",2015,to be completed,ucb,,https://escholarship.org/uc/item/15p9j6dx,,,eng,REGULAR,0,0
52,1488,Genetically Tuning Cellular Mechanobiology,"MacKay, Joanna Lynn","Kumar, Sanjay;",2013,"The recognition that cells can sense physical cues has inspired numerous investigations into the roles that mechanical forces play in both healthy and diseased cells.  This rapidly growing area of research, often called cellular mechanobiology, has shown that physical interactions between cells and the surrounding extracellular matrix can regulate a number of fundamental cell behaviors.  This insight has prompted the development of new methods to systematically engineer the mechanical properties of extracellular matrices (e.g., rigidity and geometry), both as a way to study the mechanisms behind cellular mechanosensing and as a way to directly control cell behavior in tissue engineering applications.  In contrast, an equally powerful approach for manipulating cell-matrix interactions could be to directly engineer the mechanical properties of the cells themselves by modifying the intracellular signaling pathways that regulate how cells sense and respond to physical cues.  This type of ""inside-out"" strategy would be useful for controlling cell behavior independently from extracellular matrix properties and would allow investigation into how changes in cellular mechanics such as cell shape, stiffness, and contractility can directly alter cell behavior.In these dissertation studies, a genetic strategy was developed to precisely control the mechanical properties and motility of cells by manipulating the activity of cytoskeletal signaling proteins.  Genetic mutants of the signaling proteins RhoA GTPase, Rac1 GTPase, or myosin light chain kinase (MLCK) were introduced into human glioblastoma cells under the control of conditional promoters, thereby enabling graded and dynamic control over their expression through addition and withdrawal of the transcriptional inducers.  Increasing the activity of RhoA or MLCK by inducibly expressing constitutively active (CA) mutants increased both the stiffness and the contractility of cells in a graded manner, which had an inhibitory effect on cell migration.  Interestingly, decreasing RhoA activity through expression of a dominant negative (DN) mutant also produced a graded decrease in cell migration speed, indicating that cell motility varies biphasically with RhoA activity levels.  A similar biphasic dependence was discovered upon varying the activity of Rac1.  These results demonstrate the importance of using quantitative methods to reveal potentially nonlinear relationships between protein activity and cell behavior.Expanding upon this strategy, two orthogonal promoter systems were combined to provide simultaneous control over the activity of two proteins in the same cell.  RhoA and Rac1 are known to suppress each other through crosstalk between their signaling pathways, suggesting that cells can normally have high activity of only one protein or the other.  To investigate the effects of forcing high activation of both proteins, CA RhoA and CA Rac1 were introduced into the same cells under different conditional promoters (either doxycycline-inducible or cumate-inducible).  Expression of CA RhoA did not alter Rac1 activity and vice versa, demonstrating that the activity levels of RhoA and Rac1 can be independently varied with this strategy.  Notably, expressing both CA mutants had a greater inhibitory effect on cell migration than either mutant alone, indicating that the effects of these mutants were additive rather than suppressive.Finally, these orthogonal promoters were used to dynamically control the motility of multiple cell populations in a three-dimensional matrix, providing a new way to spatially pattern cells.  When cells were cultured as multicellular spheroids within a collagen matrix, CA Rac1 expression stimulated cell migration, while DN Rac1 expression strongly inhibited it.  Thus the ability to switch these two phenotypes on and off by adding and withdrawing the transcriptional inducers provided a way to control both the timing and the extent of cell migration.  To exploit this as a patterning method, cells expressing DN Rac1 from either the doxycycline-inducible promoter or the cumate-inducible promoter were mixed together as multicellular spheroids and then subjected to alternating administration of the two inducers.  When the inducer was switched (e.g., doxycycline removed and replaced with cumate), one population was stimulated to migrate while the other was inhibited, and this created radially symmetric patterns of cells over time.The strategies developed in these dissertation studies represent a novel method for tuning cellular mechanical properties and behaviors, which we expect will be useful in a number of tissue engineering applications.  In addition, by enabling graded control over the activity of multiple proteins, these methods provide a unique opportunity to investigate the quantitative relationships describing how protein activity levels influence cell behavior.  Given that cell and tissue mechanics have been discovered to play critical roles in a number of human diseases, a better understanding of these relationships may lead to new therapeutic targets for disease treatments.",ucb,,https://escholarship.org/uc/item/16m4157x,,,eng,REGULAR,0,0
53,1489,Topics in Evidence Synthesis,"Pozzi, Luca","Jewell, Nicholas P.;Hubbard, Alan E.;",2014,"This dissertation considers three different topics related to extracting and merging evidence from heterogeneous sources. This problem is addressed from different angles, from the field of design of experiment to machine learning.Within this dissertation, we add to the existing literature in each area by developing novel methodology and software. Adaptive trial designs can considerably improve upon traditional designs,by modifying design aspects of the ongoing trial, like early stopping,adding or dropping doses, or changing the sample size. We propose a two-stage Bayesian adaptive design for a Phase IIb study aimed at selecting the lowest effective dose for Phase III. In this setting, efficacy has been proved for a high dose in a Phase IIa proof-of-concept study, but the existence of alower but still effective dose is investigated before the scheduled Phase III starts.In the first stage patients are randomized to placebo, maximaltolerated dose, and one or more additional doses within the doserange. Based on an interim analysis, the study is either stopped forfutility or success, or enters the second stage, where newly recruitedpatients are allocated to placebo, some fairly high dose, and oneadditional dose chosen based on interim data. At the interim analysiscriteria based on the predictive probability of success are used todecide on whether to stop or to continue the trial, and, in the lattercase, which dose to select for the second stage.Finally, a dose will be selected as lowest effective dose for Phase IIIeither at the end of the first or at the end of the second stage. The operating characteristics of the procedure are evaluated viasimulations and results are presented for several scenarios comparingthe performance of the proposed procedure to those of the non adaptivedesign.The development of novel therapies in multiple sclerosis (MS) is one area where a range of surrogateoutcomes are used in various stages of clinical research. While the aim of treatments in MS is to preventdisability, a clinical trial for evaluating a drugs effect on disability progression would require a largesample of patients with many years of follow-up. The early stage of MS is characterized by relapses. Toreduce study size and duration, clinical relapses are accepted as primary endpoints in phase III trials. Forphase II studies, the primary outcomes are typically lesion counts based on Magnetic Resonance Imaging(MRI), as these are considerably more sensitive than clinical measures for detecting MS activity.Recently, Sormani and colleagues \cite{sormani2010surrogate} provided a systematic review, andused weighted regression analyses to examine the role of either MRI lesions or relapses as trial levelsurrogate outcomes for disability. We build on this work by developing a Bayesian three-level model,accommodating the two surrogates and the disability endpoint, and properly taking into account thattreatment effects are estimated with errors. Specifically, a combination of treatment effects based onMRI lesion count outcomes and clinical relapse, both expressed on the log risk ratio scale, were used todevelop a study level surrogate outcome model for the corresponding treatment effects based ondisability progression. While the primary aim for developing this model was to support decision makingin drug development, the proposed model may also be considered for future validation.In Genomics and Epidemiology we deal with a high number of features for each observation. Many well known approaches to drawing inferences in this kind of settings use the topology of the feature space, induced by an appropriate metric, to group observations and summarize their main characteristics to get rid of the noise and to predict an outcome of interest. In the present work we generalize this approach in the context of Loss-Based Estimation. We propose an alternative method for constructing a nonparametric multidimensional regression function. This approach is based on the simple idea of clustering data points in the feature space and then fitting a constant to the outcome. HOPACH-PAM is used for partition. This approach results in the choice of a small number of distinct regions easy to interpret. This is specifically illustrated by simulations from which we can see immediately the superiority of this method on CART. Pre-screening and feature selections methods are also developed to improve the performances and reduce the noise. Software is also available in the R package HOPSLAM (HOpach-Pam Supervised Learning AlgorithM) to make this methodology easily accessible.",ucb,,https://escholarship.org/uc/item/1b61431k,,,eng,REGULAR,0,0
54,1490,Evaluating a Telenovela: The Safety of Latino Construction Workers,"Castaneda, Diego Emiliano","Syme, S. Leonard;",2011,"Latino-Hispanic construction workers in the United States are at significantly higher risks for injuries and fatalities at construction worksites than their White and African-American counterparts. Currently the main mode of dissemination of workplace safety information is through direct translation of work safety material delivered at the worksite. Current research, however, suggests that even when translated into Spanish, many of these materials are not culturally or linguistically effective modes of preventable risk education and persuasion. One promising method for far-reaching, cost-effective, and culturally relevant education may be found in the Entertainment-Education (EE) health communication strategy. EE leverages popular entertainment media - such as movies, television shows, music, theater and/or radio - by embedding specific health messages within a storyline and using the power of narrative to stimulate positive health choices. Spanish-language soap operas (telenovelas) are an entertainment media format culturally embraced by Latino Spanish-speaking audiences and have been effectively utilized by health educators and public health officials to promote changes in knowledge, attitudes, and behaviors for a variety of health issues. The Centers for Disease Control/National Institute of Occupational Safety and Health (CDC/NIOSH) worked with two public health partners and the Spanish language TV chain Telemundo to develop and implement an entertainment education intervention that utilized a telenovela embedded with construction worksite safety information. A statistical analysis of audience survey data collected both before and after the airing of the workplace storyline showed improvements in knowledge outcomes but not in changes in perceptions or behavioral intention outcomes. Detailed analyses revealed that survey respondents who reported recognition of the telenovela workplace storyline were more likely to identify key safety messages embedded within the storyline than respondents who did not recognize the storyline. In addition to the quantitative data, semi-structured key informant interviews were conducted with eight (8) individuals associated with the intervention project. The objective of these interviews was to explore how the partnership between public health institutions and media organizations affected the development, implementation, and evaluation of this project. Project stakeholders voiced challenges which stemmed from the chaotic nature of network television, tensions between developing entertaining vs. accurate educational messaging, and difficulty in communicating actionable messages that would be effective in changing workplace behaviors. Despite these challenges partners felt confident that future endeavors using an EE strategy should be made in communicating other workplace safety issues to Latino and other vulnerable populations. Improved collaboration between entertainment media writers/producers and public health experts is needed to create interventions with the power to change viewers behaviors over time. In addition, more refined research methods are needed to examine EE intervention development and outcomes.",ucb,,https://escholarship.org/uc/item/1cj6d90r,,,eng,REGULAR,0,0
55,1491,Statistical Problems in DNA Microarray Data Analysis,"Wang, Nancy Naichao","Speed, Terence P;",2009,"DNA microarrays are powerful tools for functional genomics studies.  Each array contains thousands of microscopic spots of DNA oligonucleotides with specific sequences, which can hybridize with their complementary DNA sequences.  Thus each microarray experiment consists of parallel assays about thousands of genomic fragments.  This thesis concerns some statistical issues in the analysis of DNA microarray data.One common usage of DNA microarrays is to monitor the dynamic levels of gene expression in response to a stimulus.  This is often achieved through a time course experiment, in which RNA samples are extracted at various time points after exposing the organism to the stimulus.  A particularly interesting type of time course experiments involve replicated series of longitudinal samples.  In 2006, Tai and Speed proposed a multivariate empirical Bayes model for analyzing this type of data.  The MB-statistic derived from this model was shown useful for ranking the genes according to changes in their temporal expression profiles.  In the first part of this thesis, we propose an empirical Bayes false discovery rate (FDR)-controlling procedure for multiple hypothesis testing using the MB-statistic.  A null distribution is obtained using the parametric bootstrap.  Critical values are determined according to the empirical Bayes FDR procedure.  This method was compared, through simulations, to the frequentist FDR procedure, which requires a theoretical null distribution for calculating the nominal p-values.  Although our method is slightly anti-conservative, it is more robust to the variability in the estimates of the hyperparameters, when the degree of moderation is small.Another common usage of DNA microarrays is to detect genomic locations that are associated with DNA-binding proteins.  This is often achieved through ChIP-chip experiments that combine chromatin immunoprecipitation with the microarray technology.  Traditional DNA microarrays designed for gene expression studies contain only a few probes for each gene.  A special type of DNA microarrays, called tiling arrays, are often used in ChIP-chip experiments.  They typically contain probes that are placed densely along the chromosomes to cover either the entire genome or contigs of the genome.  A couple of challenges in the analysis of ChIP-chip tiling array data have not been met satisfactorily in the literature.  When large scale genomic studies are carried over a long period of time, tiling arrays with different probe designs are often used for practical reasons.  The first challenge is the integration of replicate experiments performed using different tiling array designs.  When the biological process of interest involves a large protein complex, the investigators often perform ChIP-chip experiments on each component DNA-binding protein individually.  DNA targets that are shared by the individual proteins are thought to be the localization sites of the protein complex.  The second challenge is the joint analysis of multiple DNA-binding proteins, aimed at identifying their shared targets.  In the second part of this thesis, we propose a nonhomogeneous hidden Markov model (HMM) for addressing these two challenges.  The nonhomogeneous time axis represents the genomic positions of the probes.  The hidden states represent the binding statuses of the proteins.  The state-conditional emission distributions of the tiling array data are protein-specific and design-specific.  We derived a modified Baum-Welch algorithm for fitting the model parameters.  We also developed a procedure that converts the probe level summaries into peaks, which represent the putative binding sites, based on both signal strength and peak shape.  To compare our method with existing methods, we curated a set of positive and negative genomic regions from a C. elegans dataset, and performed some receiver operating characteristics (ROC) analyses.  When applied to each experiment separately, our method performs similarly as the three best existing methods.  When applied to the combined data set, which consists of tiling arrays with different probe designs, our method shows a drastic improvement in performance.  A generalization of the nonhomogeneous HMM enables the joint analysis of the ChIP-chip data of multiple proteins.  We present an application of this method to identify the shared localization sites of two DNA-binding proteins, under two different conditions.",ucb,,https://escholarship.org/uc/item/1dm0z29w,,,eng,REGULAR,0,0
56,1492,Employer Preparedness for Pandemic Influenza: Shifting the Conversation from Insurance to Investment,"Lachance, Jennifer Alice","Reingold, Arthur;",2010,"Pandemic influenza is currently one of the most visible public health threats of concern to the general public, and private businesses are an important part of pandemic preparedness. The health of communities is affected by the local economy, which is driven by the businesses in that economy. To date, public health authorities' efforts to engage businesses in pandemic influenza preparedness efforts have justified preparedness based on potential losses due to future, uncertain threats. However, this approach has not successfully engaged businesses on a broad scale. This dissertation proposes that a more effective way to engage the private sector may be to shift the conversation away from justifying preparedness only as a long-term insurance strategy and toward justifying it as an investment strategy with short-term benefits such as improved employee health during interpandemic cold and influenza seasons. The viability and acceptability of this new approach are explored here via three distinct but complementary studies using both quantitative and qualitative methods.       The first study, a prospective observational cohort study, examined the individual characteristics and situations that predicted changes in hand and respiratory hygiene and social distancing behaviors among university students during an interpandemic cold and influenza season. This analysis reveals that individuals have higher adherence to behaviors in situations such as when they are ill. Additionally, some individual characteristics predict higher behavior adherence. In particular, individuals who perceive peer expectations concerning adherence to hygiene behaviors tend to have better adherence to those behaviors over the course of a cold and influenza season.       The second study, a cost-effectiveness analysis of a hand and respiratory hygiene intervention among university students, assessed whether an intervention could be cost-effective in reducing influenza-like illness and associated time lost from productive activities during an interpandemic cold and influenza season. This analysis finds that hand and respiratory hygiene interventions can be cost-effective and may even become cost-saving during a severe cold and influenza season, especially using group-level interventions that may create peer expectations to influence behaviors.      Finally, the third study, an exploratory analysis based on key informant interviews with private sector business continuity managers, consultants, and public sector planners, examined private sector preparedness for pandemic influenza. This analysis assessed the key components of employer pandemic influenza preparedness plans, including whether short-term benefits are a consideration in business planning. The results indicate that the most important components of private sector pandemic influenza plans before and during the 2009 H1N1 influenza pandemic included communications and employee education around hygiene behaviors. Participants further identified that implementation of these initiatives during interpandemic cold and influenza seasons is of interest to organizations due to potential short-term and long-term benefits.      These results together provide evidence that education and provision of materials for hygiene behaviors at a group level can be cost-effective in reducing influenza-like illnesses during interpandemic cold and influenza seasons and are an acceptable strategy to the private sector. This provides a basis for the hypothesis that employer preparedness for public health events such as pandemic influenza can be justified as a short-term business investment strategy rather than only as a long-term insurance strategy.",ucb,,https://escholarship.org/uc/item/0p05b5qx,,,eng,REGULAR,0,0
57,1493,The Role of Distribution Infrastructure and Equipment in the Life-cycle Air Emissions of Liquid Transportation Fuels,"Strogen, Bret","Horvath, Arpad;",2012,"Production of fuel ethanol in the United States has increased ten-fold since 1993, largely as a result of government programs motivated by goals to improve domestic energy security, economic development, and environmental impacts.  Over the next decade, the growth of and eventually the total production of second generation cellulosic biofuels is projected to exceed first generation (e.g., corn-based) biofuels, which will require continued expansion of infrastructure for producing and distributing ethanol and perhaps other biofuels.  In addition to identifying potential differences in tailpipe emissions from vehicles operating with ethanol-blended or ethanol-free gasoline, environmental comparison of ethanol to petroleum fuels requires a comprehensive accounting of life-cycle environmental effects.  Hundreds of published studies evaluate the life-cycle emissions from biofuels and petroleum, but the operation and maintenance of storage, handling, and distribution infrastructure and equipment for fuels and fuel feedstocks had not been adequately addressed.  Little attention has been paid to estimating and minimizing emissions from these complex systems, presumably because they are believed to contribute a small fraction of total emissions for petroleum and first generation biofuels.  This research aims to quantify the environmental impacts associated with the major components of fuel distribution infrastructure, and the impacts that will be introduced by expanding the parallel infrastructure needed to accommodate more biofuels in our existing systems.  First, the components used in handling, storing, and transporting feedstocks and fuels are physically characterized by typical operating throughput, utilization, and lifespan.  US-specific life-cycle GHG emission and water withdrawal factors are developed for each major distribution chain activity by applying a hybrid life-cycle assessment methodology to the manufacturing, construction, maintenance and operation of each component.  Emissions from activities at the end of life of equipment and infrastructure are not included, as these activities have previously been shown to contribute negligibly to life-cycle emissions.  Life-cycle transportation mode GHG emission factors per tonne-kilometer (t-km) are presented for long distance pipelines (5-20 g CO2-e/t-km), ocean tankers (5-17 g/t-km), fuel-carrying barges (31 g/t-km), fuel-carrying unit trains (25 g/t-km), tanker trucks (140-180 g/t-km), and bale-transporting flatbed trucks (200 g/t-km).  Life-cycle emission factors are also presented per tonne of material throughput for several types of agricultural equipment (600-19,000 g CO2-e/t handled), fuel conversion facilities (9,000-98,000 g/t), fuel storage and dispensing facilities (2,000-12,000 g/t), and the portion of passenger vehicle operations dedicated to refueling errands (2,000-200,000 g/t).  The emissions intensity ranges reported for specific transportation modes are largely due to the greater energy efficiency of larger vehicles and pipelines, and the emissions intensity ranges within stationary storage and handling equipment is often due to differences in utilization of capital equipment and/or material losses during storage and handling activities.  Consistent with existing literature, the contribution of non-operation stages to life-cycle GHG emissions ranges from 20% to 40% for most of the components modeled.  Criteria air pollutant (NOx, PM2.5, SOx, VOC, CO) emission factors are also presented for the operation stage (e.g., tailpipe only) of each transportation mode.  In order to apply the new emission factors to policy-relevant scenarios, a projection is made for the fleet inventory of infrastructure components necessary to distribute 21 billion gallons of ethanol (the 2022 federal mandate for advanced biofuels under the Energy Independence and Security Act of 2007) derived entirely from Miscanthus grass, for comparison to the baseline petroleum system.  Due to geographic, physical and chemical properties of biomass and alcohols, the distribution system for Miscanthus-based ethanol is more capital- and energy-intensive than petroleum per unit of fuel energy delivered.  Assuming steady-state annual turnover, operation, and maintenance of infrastructure to supply the projected quantities of ethanol and petroleum fuels, ethanol is estimated to be approximately five times more GHG and water intensive than petroleum (i.e., GHG emissions of more than 17 g CO2-e/MJ versus 3 g/MJ, and water withdrawals of 380 L/MJ vs. 77 L/MJ of consumed fuel, neglecting feedstock production and conversion).  Embodied GHG emissions from manufacturing and maintaining infrastructure, equipment, and vehicles make up less than half of these emissions, at approximately 1 g CO2-e/MJ of petroleum fuel and 8 g CO2-e/MJ of ethanol.  Although petroleum fuels are projected to supply twenty times the energy content of ethanol in 2022, the annual GHG and water withdrawal footprint of petroleum's liquid fuel infrastructure and distribution system is slightly less than four times that of ethanol (i.e., 110 vs. 30 million tonnes of CO2-e and 2,500 vs. 640 billion liters of water).  Opportunities to significantly reduce emissions include shifting transportation to more efficient modes, consuming products closer to producers, and converting biorefineries to produce fuel with higher energy density than ethanol.  Minimizing fuel transportation distance is believed to be the most feasible and cost-effective opportunity to reduce emissions in the near term.The transportation of biofuels away from producer regions poses environmental, health, and economic trade-offs that are herein evaluated using a simplified national distribution network model.  In just the last ten years, ethanol transportation within the contiguous United States is estimated to have increased more than ten-fold in total t-km as ethanol has increasingly been transported away from Midwest producers due to air quality regulations pertaining to gasoline, renewable fuel mandates, and the 10% blending limit (i.e., the E10 blend wall).  From 2004 to 2009, approximately 10 billion t-km of ethanol transportation are estimated to have taken place annually for reasons other than the E10 blend wall, leading to annual freight costs greater than $240 million and more than 300,000 tonnes of CO2-e emissions and significant emissions of criteria air pollutants from the combustion of more than 90 million liters of diesel.  Although emissions from distribution activities are small when normalized to each unit of fuel, they are large in scale.Archetypal fuel distribution routes by rail and by truck are created to evaluate the significance of mode choice and route location on the severity of public health impacts from locomotive and truck emissions, by calculating the average PM2.5 pollution intake fraction along each route.  Exposure to pollution resulting from trucking is found to be approximately twice as harmful as rail (while trucking is five times more energy intensive).  Transporting fuel from the Midwest to California would result in slightly lower human health impacts than transportation to New Jersey, even though California is more than 50% farther from the Midwest than most coastal Northeast states.In summary, this dissertation integrated concepts from infrastructure management, climate and renewable fuel policy, fuel chemistry and combustion science, air pollution modeling, public health impact assessment, network optimization and geospatial analysis.  In identifying and quantifying opportunities to minimize damage to the global climate and regional air quality from fuel distribution, results in this dissertation provide credence to the urgency of harmonizing policies and programs that address national and global energy and environmental goals.  Under optimal future policy and economic conditions, infrastructure will be highly utilized and transportation minimized in order to reduce total economic, health, and environmental burdens associated with the entire supply and distribution chain for transportation fuels.",ucb,,https://escholarship.org/uc/item/0r60z01k,,,eng,REGULAR,0,0
58,1494,Prediction Methods for Astronomical Data Observed with Measurement Error,"Long, James Patrick","Rice, John A;El Karoui, Noureddine;",2013,"We study prediction when features are observed with measurement error. The research is motivated by classification challenges in astronomy.In Chapter 1 we introduce the periodic variable star classification problem. Periodic variable stars are periodic functions which belong to a particular physical class. These functions are often sparsely sampled, which introduces measurement error when attempting to estimate period, amplitude, and other function features. We discuss how measurement error can impact performance of periodic variable star classifiers. We introduce two general strategies, noisification and denoisification, for addressing measurement error in prediction problems.In Chapter 2 we study density estimation with Berkson error. In this problem, one observes a sample from the density $f_X$ and seeks to estimate $f_Y$, the convolution of $f_X$ with a known error distribution. We derive asymptotic results for the behavior of the mean integrated squared error for kernel density estimates of $f_Y$. The presence of error generally increases convergence rates of estimators and optimal smoothing parameters. We briefly discuss some potential applications for this work, including classification tasks involving measurement error.In Chapter 3 we study prediction of a continuous response for an observation with measurement error in its features. Using Nadaraya Watson type estimators we derive limit theorems for convergence of the mean squared error as a function of the smoothing parameters.In Chapter 4 we study the effects of measurement error on classifier performance using data from the Optical Gravitational Lensing Experiment (OGLE) and the Hipparcos satellite. We illustrate some challenges in constructing statistical classifiers when the training data is collected by one astronomical survey and the unlabeled data is collected by a different survey. We use noisification to construct classifiers that are robust to some sources of measurement error and training--unlabeled data set differences.",ucb,,https://escholarship.org/uc/item/0s79z3hk,,,eng,REGULAR,0,0
59,1495,"Social Work Delivered Intervention for Persons with Mild Traumatic Brain Injury: Implementation and Evaluation in an Urban, Public, Trauma Center Emergency Department","Moore, Megan","Segal, Steven P;",2012,"Mild traumatic brain injury (mTBI) is a prevalent and costly public health problem with potentially disabling consequences.  Interventions aimed at alleviating cognitive, emotional and behavioral sequelae are underdeveloped.  This prospective, quasi-experimental cohort study evaluated a brief social work delivered intervention (SWDI) for adults with mTBI discharged from the emergency department.  The SWDI included education, reassurance, coping strategies and community resource information.  Participants were recruited from consecutive admissions to the emergency department.  A total of 64 persons with confirmed mTBI diagnoses were assessed 3 months post-injury.  Participants in the Usual Care group (N=32) were identified via medical record; confirmation of mTBI was based on World Health Organization definition.  Participants in the SWDI group (N=32) were identified and mTBI diagnosis confirmed by emergency department medical staff.  Both groups completed standardized assessments of post-concussion symptoms, depression, anxiety, Posttraumatic Stress Disorder, alcohol use, and community functioning three months after injury.  To assess change in alcohol use and community functioning, participants were asked to recall pre-injury drinking levels and functioning and then asked about current status three months post injury.  The SWDI group also completed an open-ended Patient Experience Survey following their ED service.    The paired sample t test was used to assess community functioning outcomes.  For all other standardized measures, non-parametric Mann Whitney or Wilcoxon Signed Rank tests were used to compare groups.  Qualitative themes from the Patient Experience Survey were identified through systematic review of all survey responses.Three months post injury, both groups reported pre-injury drinking in the ""hazardous"" range.  The SWDI group reported significantly reduced alcohol use from pre-injury to post-intervention (p < 0.05).  The Usual Care group maintained their pre-injury level of drinking.  Analysis of the community functioning measure revealed the SWDI group maintained pre-injury levels of community functioning, while the Usual Care group reported significant decline in functioning (p = 0.05).  All other analyses of standardized measures (anxiety, depression, PTSD, post-concussive symptoms) trended in favor of the intervention group, but were not statistically significant.  Results from the SWDI Patient Experience Survey indicate that 96% of participants who remembered receiving the intervention (N=25) found it helpful.  In response to an open ended question about the most helpful aspects of the intervention, 60% reported it was most helpful to learn about symptoms to expect because this decreased anxiety about symptoms, 28% reported that the recovery tips were most helpful and 24% reported that education about ceasing alcohol use was most helpful. The study provides support for the use of the SWDI in the emergency department.  Decrease in alcohol use and maintenance of community functioning are clinically and functionally significant outcomes.  Alcohol use is a risk factor for re-injury and poor outcome, and the measure of community functioning includes probes about work, school and social activity attendance as well as ability to complete household and daily living activities.  In addition, the SWDI group overwhelmingly found the intervention helpful.  Education about symptoms to expect and decreasing alcohol use was particularly salient for participants.  Future studies should consider survey themes and ways to enhance the intervention in order to increase the impact on additional outcomes of interest.",ucb,,https://escholarship.org/uc/item/0sw9w8t7,,,eng,REGULAR,0,0
60,1496,Understanding and Engineering Cellulase Binding to Biomass Components,"Strobel, Kathryn Lynn","Clark, Douglas S;",2015,"Lignocellulosic biomass is an abundant, low-cost resource for the renewable production of fuels and chemicals. To unlock the potential of lignocellulosic biomass, the cellulose must be broken down into sugars before fermentation to produce ethanol, butanol, or other bio-based products. Unfortunately, lignocellulose is highly resistant to enzymatic degradation, necessitating high enzyme loadings that increase the cost of biofuels. The recalcitrance of biomass stems in part from the presence of lignin, a major component of lignocellulosic biomass. Lignin impedes enzymatic hydrolysis by non-productively binding cellulases and contributing to cellulase denaturation. Despite numerous studies documenting cellulase adsorption to lignin, the structural basis has not been fully elucidated and few attempts have been made to engineer enzymes for reduced lignin affinity. In this work, we investigate and engineer cellulase adsorption to lignin and the resulting effect on hydrolysis of cellulose. The lignin inhibition of two homologous cellulases, T. reesei Cel7A and T. emersonii Cel7A, was found to differ significantly. In Chapter 2, we propose that differences in surface charge, stability, and glycosylation patterns may be the driving force/s behind the observed differences in lignin inhibition and we suggest engineering strategies for improving lignin tolerance of Cel7A catalytic domains.  Chapters 3 and 4 detail our efforts to investigate the mechanisms of cellulase lignin adsorption and engineer an enzyme with reduced lignin affinity using site directed mutagenesis of the T. reesei Cel7A carbohydrate binding module (CBM) and linker. Mutation of aromatic and polar residues on the planar face of the CBM greatly decreased binding to both cellulose and lignin, supporting the hypothesis that the cellulose-binding face is also responsible for the majority of lignin affinity. Cellulose and lignin affinity of the alanine mutants were highly correlated, indicating similar binding mechanisms for cellulose and lignin. CBM mutations that added hydrophobic or positively charged residues decreased the selectivity toward cellulose, while mutations that added negatively charged residues increased the selectivity.  Mutating the linker to alter predicted glycosylation patterns greatly impacted lignin affinity but did not affect cellulose affinity. Beneficial mutations were combined to generate a mutant with 2.5 fold less lignin affinity and fully retained cellulose affinity. This mutant was not inhibited by added lignin during hydrolysis of Avicel and generated 40% more glucose than the wild type enzyme from dilute acid-pretreated Miscanthus. The mutations studied here inform engineering efforts of other homologous CBMs and will hopefully contribute to reducing the cost of biofuels. The final chapter details the development of a high-throughput selection platform for engineering protease enzymes with new sequence specificity. Proteases are commonly used in research, industry, and medicine, and there is considerable promise for new proteases that could cleave at a user-specified sequence. Positive selection and counter-selection were combined to select a tobacco etch virus protease mutant with new substrate compatibility.",ucb,,https://escholarship.org/uc/item/0tw1f2tz,,,eng,REGULAR,0,0
61,1497,"The Therapeutic Turn in International Humanitarian Law: War Crimes Tribunals as Sites of ""Healing""?","Anders, Diana Elizabeth","Butler, Judith;Cohen, David;",2012,"AbstractThe Therapeutic Turn in International Humanitarian Law: War Crimes Tribunals as Sites of ""Healing""?  by  Diana Elizabeth Anders  Doctor of Philosophy in Rhetoric Designate Designated Emphasis in Women, Gender, and SexualityUniversity of California, Berkeley  Professor Judith Butler, Co-Chair  Professor David Cohen, Co-Chair This dissertation examines the growing tendency to figure international war crimes tribunals in terms of their therapeutic value for their victims. My project documents and questions how the discourse of juridical healing emerged from what I term ""the therapeutic turn"" in international humanitarian law (hereafter, IHL). I analyze this phenomenon in terms of its key features, conditions of possibility, modes of legitimization, and effects, focusing on legal institutions designed to adjudicate crimes such as genocide, mass rape, and torture. My central argument is that the rhetoric of juridical healing, despite its commendable achievements, comes at an important cost, in that the appeal to law can invite new forms of regulation and domination. In short, this novel form of justice produces and authorizes its own forms of violence. It does so in part by obscuring the political effects of the law's promise to heal. To bring this uncomfortable fact into relief is but a first step towards countering such ill effects.  This project focuses on the first two international ad hoc tribunals -- the International Criminal Tribunals for the former Yugoslavia and the International Tribunal for Rwanda -- as well as the International Criminal Court (hereafter, the ICTY, the ICTR, and the ICC). All were established in the 1990s in the beginning of what has been called the ""tribunal era,""  which has ushered in an unprecedented emphasis on victims of atrocity. Primarily by means of discourse analysis, I examine court documents and trial transcripts, as well as relevant statements made by diplomats, politicians, court officials, scholars, and non-governmental-organizations. Such analysis aims to chart the expansion of a new norm of justice as healing that has so far largely gone unrecognized.   Chapter One outlines the general problem of the dissertation, introducing the phenomenon of juridical healing and situating it historically. Although such healing has become a powerful, even normative trope in humanitarian discourse, it has not been well defined. The chapter raises questions concerning what juridical healing can realistically achieve, and how it might constitute a new mode of power that paternalistically regulates the very subjects it pledges to heal. It also examines how the special status of healing discourse as ""above reproach"" has shielded it from critical scrutiny.     Chapter Two surveys the growing scholarly discourse on juridical healing, arguing that such inquiries tend to uncritically accept the core terms of the therapeutic turn. This work can thus serve to reify the problematic notion of healing promulgated elsewhere. Such thinking holds that tribunals can occasion forms of ""catharsis"" and ""closure,"" both for individual victim-witnesses and more broadly. I argue that this belief in ""disclosure for closure"" forecloses critical reflection on the effects of juridical healing, or on alternatives to this conception.  In Chapter Three, I develop a genealogy of juridical healing in relation to new legal institutions. I analyze how the promise of healing has served as a means of legitimization, even as it has led courts into uncharted legal territory. Even as the tribunals of the 1990s derived their credibility from the Nuremberg and Tokyo tribunals that followed World War II, they also had to distance themselves from the accusation that the latter had only dispensed ""victors' justice."" In an uncanny echo, recent tribunals can be said to have produced forms of ""victims' justice."" I examine how such rhetoric threatens to undermine the same credibility that it otherwise means to establish, even at the cost of the victims it purportedly champions.  Chapter Four considers the tribunals' adjudication of sexual violence as a war crime. Here I use individual case studies to show the unforeseen costs of such procedures. I examine how the female victim of sexual violence is effectively condemned to victimhood by the very discourse that promises to heal her, but denies her meaningful agency. At the same time, ""other"" victims of wartime sexual violence--such as men, boys, or women from the ""enemy camp""--are marginalized. My analyses of these cases explore how therapeutic-juridical interventions can undermine their avowed aims, while concealing the power relations on which they rely and which they perpetuate.   The final chapter is based on fieldwork that I carried out in 2009 in The Hague, Netherlands, and examines the depoliticizing effects of juridical healing.  Drawing on interviews with ICTY and ICC officials, the chapter outlines the temporal and spatial coordinates of the rhetoric of healing. I focus on the ways in which such rhetoric enacts movements of deferral and displacement, and thus neutralizes potential forms of political activity. As an alternative, I examine Hannah Arendt's account of politics, which is centered on collective, participatory action and antagonistic debate. Such a view allows us to imagine a more capable subject of politics, one with the potential to recover, resist, and revolt.  The Epilogue evaluates the current and future implications of the rhetoric of healing, exploring alternative responses to extreme violence. I claim that juridical healing can be understood as the latest ""last utopia""  or the least ""lesser evil""  in a time when ""human rights"" and ""humanitarianism"" have become increasingly wed to military interventions. I proceed to trace additional contradictions in the discourse of juridical healing, in that contemporary IHL also identifies with the ideology of militarized humanitarianism in its endorsement of the UN doctrine of ""Responsibility to Protect."" I close by suggesting that juridical healing presents the international community with an aporia that might ultimately be generative, insofar as it produces conditions under which the very politics it stifles might also be aroused. By rethinking and reframing this rhetoric, I hope to indicate avenues for differently imagining and producing the future--a future not destined to repeat or be dictated by the violence, injustice, and pain of the past.",ucb,,https://escholarship.org/uc/item/0vc1f4gc,,,eng,REGULAR,0,0
62,1498,Biodiversity and Ecosystem Services in Agriculture: Evaluating the Influence of Floral Resource Provisioning on Biological Control of Erythroneura Leafhoppers (Hemiptera: Cicadellidae) and Planococcus Mealy Bugs (Hemiptera: Pseudococcidae) in California Vineyards,"Miles, Albie Felix","Altieri, Miguel A;",2013,"The research tested the natural enemies hypothesis in an attempt to explain why lower pest densities are observed in some diversified farming systems. The research evaluated the influence of floral resource provisioning (FRP) and chemical ecology strategies on biological control of Erythroneura leafhoppers (Hemiptera: Cicadellidae) and Planococcus mealybug (Hemiptera: Pseudococcidae) in California vineyards. Field and laboratory studies quantified the impacts on crop damage, pest and natural enemy abundance, and natural enemies fitness theorized to be enhanced through floral resource provisioning in agroecosystems. Multiple two-year studies measured the impact of intercropping three flowering ground covers, lacy phacelia (Phacelia tanacetifolia), bishop's weed (Ammi majus), and common carrot (Daucus carota) on biological control of leafhoppers and vine mealybug by the parasitoids Anagrus spp. (Hymenoptera: Mymaridae) and Anagyrus pseudococci (Hymenoptera: Encyrtidae). Using identical intercropping treatments, the research included three large scale and fully replicated research designs located in the central San Joaquin, the northern San Joaquin, and the Napa Valley of California. Laboratory studies quantified the impacts of FRP on the fitness of Anagyrus pseudococci, a key parasitoid natural enemy of vine mealybug. The central San Joaquin Valley field study measured the impact of FRP and pheromone based mating disruption on biological control of vine mealybug. The northern San Joaquin Valley field study measured the impact of FRP and methyl salicylate on biological control of Erythroneura leafhoppers. The Napa Valley field study measured the effect of methyl salicylate alone on biological control of Erythroneura leafhoppers.",ucb,,https://escholarship.org/uc/item/0vt4z0fd,,,eng,REGULAR,0,0
63,1499,Seeing in the Dark: Weak Lensing from the Sloan Digital Sky Survey,"Huff, Eric Michael","Schlegel, David J;Selak, Uros;",2012,"Statistical weak lensing by large-scale structure { cosmic shear { is a promising cosmological tool, which has motivated the design of several large upcoming astronomical surveys. This Thesis presents a measurement of cosmic shear using coadded Sloan Digital Sky Survey (SDSS) imaging in 168 square degrees of the equatorial region, with r < 23:5 and i < 22:5, a source number density of 2.2 per arcmin2 and median redshift of zmed = 0.52. These coadds were generated using a new rounding kernel method that was intended to minimize systematic errors in the lensing measurement due to coherent PSF anisotropies that are otherwise prevalent in the SDSS imaging data. Measurements of cosmic shear out to angular separations of 2 degrees are presented, along with systematics tests of the catalog generation and shear measurement steps that demonstrate that these results are dominated by statistical rather than systematic errors. Assuming a cosmological model corresponding to WMAP7(Komatsu et al., 2011) and allowing only the amplitude of matter fluctuations &sigma8 to vary, the best-t value of the amplitude of matter fluctuations is &sigma8=0.636+0.109-0.154 (1&sigma); without systematic errors this would be  &sigma8=0.636+0.099-0.137 (1&sigma). Assuming a flat &LambdaCDM model, the combined constraints with WMAP7 are &sigma8=0.784super>+0.028-0.026  (1&sigma). The 2&sigma error range is 14 percent smaller than WMAP7 alone. Aside from the intrinsic value of such cosmological constraints from the growth of structure, some important lessons are identied for upcoming surveys that may face similar issues when combining multi-epoch data to measure cosmic shear. Motivated by the challenges faced in the cosmic shear measurement, two new lensing probes are suggested for increasing the available weak lensing signal. Both use galaxy scaling relations to control for scatter in lensing observables.The first employs a version of the well-known fundamental plane relation for early type galaxies. This modified ""photometric fundamental plane"" replaces velocity dispersions with photometric galaxy properties, thus obviating the need for spectroscopic data. We present the first detection of magnication using this method by applying it to photometric catalogs from the Sloan Digital Sky Survey. This analysis shows that the derived magnication signalis comparable to that available from conventional methods using gravitational shear. We suppress the dominant sources of systematic error and discuss modest improvements that may allow this method to equal or even surpass the signal-to-noise achievable with shear. Moreover, some of the dominant sources of systematic error are substantially different from those of shear-based techniques. The second outlines an idea for using the optical Tully-Fisher relation to dramatically improve the signal-to-noise and systematic error control for shear measurements. The expectederror properties and potential advantages of such a measurement are proposed, and a pilot study is suggested in order to test the viability of Tully-Fisher weak lensing in the context of the forthcoming generation of large spectroscopic surveys.",ucb,,https://escholarship.org/uc/item/0z22n08t,,,eng,REGULAR,0,0
64,1500,Exploring Landscapes of Naturalness with Lifshitz Field Theories,"Grosvenor, Kevin Torres","Horava, Petr;",2015,"In this thesis, we examine the question of technical naturalness from the point of view of nonrelativistic quantum field theories of Lifshitz type. Lifshitz field theories are distinguished from standard relativistic quantum field theories by the spacetime scaling symmetries that they enjoy in the vicinity of their renormalization group fixed points. These scaling symmetries are parametrized by the dynamical critical exponent, which measures the degree of scaling of time relative to spatial coordinates. Whereas in relativistic theories, space and time scale equally with each other, in Lifshitz field theories, the dynamical critical exponent may differ from unity. Furthermore, Lifshitz field theories live in spacetimes that possess a foliation structure by spatial leaves of constant time. Therefore, in contrast to relativistic theories, Lifshitz field theories are not invariant under the full diffeomorphism group of spacetime, but rather only those diffeomorphisms that preserve the built-in foliation structure. In the flat spacetime, this would simply exclude the usual spacetime boost symmetries. Since time is treated on a fundamentally different footing as is space, these theories are often referred to as anisotropic. In addition, these theories often require the tuning of multiple parameters in order to approach their fixed points under renormalization group flow, and are consequently called multicritical.We will explore some new and interesting lessons that nonrelativistic theories have to teach us about technical naturalness. We begin this study at the modest level of Lifshitz scalar field theories. We examine the nature of Nambu-Goldstone (NG) bosons that arise from spontaneous symmetry breaking in multricritical systems described by Lifshitz scalar field theories. The NG modes in such nonrelativistic theories were previously classified into two types: (1) Type-A, which disperses linearly, and which derives its kinetic energy from a term which is quadratic in time derivatives; and (2) Type-B, which disperses quadratically, and which is described by a pair of fields with kinetic terms linear in time derivatives. In principle, Type-A modes dispersing by a power different from unity, and Type-B modes dispersing by a power different from two, can exist. However, the naive expectation from relativistic quantum field theory is that these would require fine tuning and are therefore technically unnatural. We discover that this is not the case. Instead of fine-tuning, all one needs is a new type of symmetry by which the fields transform by a polynomial function of some appropriate degree in the spatial coordinates. This polynomial shift symmetry protects the naturalness of the corresponding NG bosons. This leads to a refinement of the classification of technically natural NG modes in nonrelativistic theories.Having discovered these polynomial shift symmetries, we turn our attention to the classification of Lagrangians that are invariant (up to total derivatives) with respect to these symmetries. We develop a novel graph-theoretical technique in order to address this problem. In this language, the invariants display beautiful patterns that otherwise remain obscured. For example, linear-shift invariants are presented as equal-weight sums over all labeled trees with some fixed number of vertices. Furthermore, we develop a graph-theoretical method for constructing invariants under polynomial shifts of high degree from invariants under polynomial shifts of lower degree. In this way, one no longer needs to repeat the entire classification process for each degree of the polynomial shift symmetry.The third part of the thesis uses some of the theories, which are built out of invariants constructed in the second part of the thesis, to study a novel feature that these Lifshitz theories possess as one changes the energy scale at which the systems are examined. We find that these systems can flow from one fixed point described by one value of the dynamical exponent, to another fixed point described by a different value of the dynamical exponent. Furthermore, the system can explore any number of fixed points between the extreme high energy regime and the extreme low energy regime. We refer to this behavior as a cascade. Not only can Type-A modes cascade into other Type-A modes (or similarly for Type-B modes), but Type-A modes can flow towards Type-B at low energies as well. Both mechanisms are protected by symmetries. The purely Type-A or Type-B cascade is protected by the polynomial shift symmetries in space. The Type-A to Type-B cascade can be protected by various symmetries, including a linear shift symmetry in time. Furthermore, we re-examine the Coleman-Hohenberg-Mermin-Wagner (CHMW) theorem, which prohibits the spontaneous breaking of global internal continuous symmetries in relativistic theories in two spacetime dimensions. Naively, this theorem would prevent the existence of a Type-A mode unless its dynamical exponent is strictly less than the spatial dimension, which is when the theory is in its lower critical dimension. The cascade represents a mechanism by which this result can be circumvented.Next, we examine the renormalization group flow of one particular Lifshitz scalar field theory. We perform the analysis explicitly using three different standard techniques of renormalization and show that they are all mutually consistent. Furthermore, we demonstrate that the RG flow of Lifshitz theories can be interpreted physically in many different, but consistent, ways due to the additional freedom of renormalizing the dynamical exponent.The lessons in Lifshitz field theories discussed in this thesis are most readily applied in the area of condensed matter physics, where systems often display a richer spectrum of behavior than is described by relativistic physics. We perform a preliminary study of the effects of coupling these Lifshitz theories with other systems. In particular, we study the naturalness problem of the linear dependence on temperature of the resistivity of so-called strange metals, which are high-temperature superconductors above their critical temperature. We show that this behavior is reproduced by the standard electron-phonon interaction picture of superconductivity, if the phonons are allowed to be multicritical and at their lower critical dimension. We also examine the impact that this model has on the heat capacity of the system.",ucb,,https://escholarship.org/uc/item/0073j1dx,,,eng,REGULAR,0,0
65,1501,Global Innovation Bridges: A new policy instrument to support global entrepreneurship in peripheral regions,"Martinez de Velasco Aguirre, Emilio","Chapple, Karen;",2012,"This dissertation analyzes a new set of policy instruments that several national and regional governments have recently implemented to help their home-grown innovative companies gain access to global technology markets. These initiatives, which in this dissertation are referred to as Global Innovation Bridges (GIBs), introduce a novel spatial approach to supporting global entrepreneurship in peripheral regions. Establishing a physical presence in the most dynamic regions of technological innovation around the world, and having deep ties with organizations in their home country, GIBs have effectively instituted a cross-national business support structure with the capacity to mobilize knowledge, talent, technology and capital across borders. These initiatives are based on the premise that facilitating innovative companies' access to global markets will accelerate their growth at home, generating new jobs and income. But in addition to a quantitative increase in economic activity, governments are implementing GIBs in an attempt to foster a transition towards high-growth, high value-added economic activities. Despite their potential to stimulate economic development and to foster a qualitative transformation in the economic structure of countries and regions, the literature on entrepreneurship and global entrepreneurship policies remains completely silent about GIBs. This dissertation is the first academic contribution to reveal the workings of this emerging economic development tool. The research achieves two main objectives. First, it provides an initial characterization of GIBs, describing their main features and the factors that are driving national and regional governments to implement them. Based on a multiple case-study of six GIBs with operations in Silicon Valley, California, this characterization also introduces a taxonomy that clearly differentiates GIBs from similar organizations supporting entrepreneurship. Second, it develops an in-depth analysis of the Mexican GIB, the Technology Business Accelerator (TechBA) program, in order to explain how GIBs work. This in-depth study reveals the diversity of actors supporting the mission of the TechBA program as well as the learning processes involved in turning a local company into a global player.Applying the concept of `communities of practice'  (Lave 1991; Brown and Duguid 1991; Wenger 1998; Brown and Duguid 2001) to the analysis of the TechBA program, this dissertation advances the following arguments:* The TechBA program articulates a community of practice that involves individuals in various organizations linked together by shared experience, expertise, and commitment to a joint enterprise: supporting the global expansion of Mexican companies. These are individuals whose work is related to the many technological, commercial, financial, and legal aspects of launching a new global venture. While all these individuals work for organizations that have their own agendas and goals, they all contribute in one way or another to advancing the mission of the TechBA program.* TechBA sustains a `distributed' community of practice (Hildreth et al., 2000) that transcends national borders. Through formal partnerships but primarily through informal collaborations with actors in both Mexico and in foreign markets, TechBA articulates a community of practice that operates across distant regions in different countries. The staff and individuals more closely involved in the operation of the TechBA program serve as a `brokers,' mediating among various technical and business communities in distant regions.* Supporting the global expansion of innovative companies involves a transformation in the views and practices of the entrepreneurs leading the global expansion effort as much as it involves adaptations in the strategy, structure, and organization of a firm. Parallel to the activities to support firm-level adaptations, TechBA facilitates a process of enculturation in which Mexican entrepreneurs develop the values and practices of a foreign business community. Through formal training, but primarily through numerous experience-based learning opportunities, Mexican entrepreneurs develop a new language and codes of communication, new know-how in the form of foreign business practices, new know-who or the knowledge to participate in professional networks in foreign markets, as well as new values and views in line with those of a foreign business community. * Rather than simply bridging the geographical distance to markets, the cross-national community of practice built around the TechBA program provides the social context for developing the knowledge, skills, practices, and views that are time- and context-specific and difficult to transmit over long distances. The TechBA community of practice serves as a ""living curriculum"" (Wenger 2006) in which Mexican entrepreneurs can develop a new identity and learn how to be a global entrepreneur.",ucb,,https://escholarship.org/uc/item/1f29r1dw,,,eng,REGULAR,0,0
66,1502,Generalized Arrows,"Joseph, Adam Megacz","Wawrzynek, John;",2014,"Multi-level languages and arrows both facilitate metaprogramming, the act of writing a program which generates a program. The arr function required of all arrows turns arbitrary metalanguage expressions into object language expressions; because of this, arrows may be used for metaprogramming only when the object language is a superset of the metalanguage.This thesis introduces generalized arrows, which are less restrictive than arrows in that they impose no containment relationship between the object language and metalanguage; this allows generalized arrows to be used for heterogeneous metaprogramming. This thesis also establishes a correspondence between two-level programs and one-level programs which take a generalized arrow instance as a distinguished parameter. A translation across this correspondence is possible, and is called a flattening transformation.The flattening translation is not specific to any particular object language; this means that it needs to be implemented only once for a given metalanguage compiler. Support for various object languages can then be added by implementing instances of the generalized arrow type class; this does not require knowledge of compiler internals. Because of the flattening transformation the users of these object languages are able to program using convenient multi-level types and syntax; the conversion to one-level terms manipulating generalized arrow instances is handled by the flattening transformation.A modified version of the Glasgow Haskell Compiler (GHC) with multi-level types and expressions has been produced as a proof of concept. The Haskell extraction of the Coq formalization in this thesis have been compiled into this modified GHC as a new flattening pass.",ucb,,https://escholarship.org/uc/item/1gg3m11q,,,eng,REGULAR,0,0
67,1503,Essays in China's Anti-corruption Campaign,"Lu, Xi","Wright, Brian;",2017,"China's unique system of hiring and promoting talented people within the state, under the supervision of the Communist Party, has been held up as an important institutional factor supporting its remarkably rapid and sustained economic growth. Jointly with Professor Peter L. Lorentzen, we explore this meritocracy argument in the context of Chinese leader Xi Jinping's ongoing anti-corruption campaign. Some question the sincerity of the campaign, arguing that it is nothing but a cover for intra-elite struggle and a purge of Xi's opponents. In the first chapter of my thesis, we use a dataset I have created to identify accused officials and map their connections. Our evidence supports the Party's claim that the crackdown is primarily a sincere effort to cut down on the widespread corruption that was undermining its efforts to develop an effective meritocratic governing system. First, we visualize the ""patron-client'' network of all probed officials announced by the central government and identify the core targets of the anti-corruption campaign. Second, we use a recursive selection model to analyze who the campaign has targeted, providing evidence that even personal ties to top leaders have provided little protection. Finally, we show that, in the years leading up to the crackdown, the provinces later targeted had departed from the growth-oriented meritocratic selection procedures evident in other provinces. 	In addition to its motivation, I also discuss the campaign's effects on economic efficiency. The second chapter of my thesis tests the ""greasing-the-wheels'' hypothesis in the context of China's residential land market. We show that China's anti-corruption campaign, aimed at removing corruption in China's monopoly land market, caused a decrease in land transaction volumes. Furthermore, not removing any form of corruption would also lead to a similar decrease. It is only necessary to remove corruption that enables real estate developers to circumvent red tape and reduce trading costs. Our findings support the ""greasing-the-wheels'' hypothesis hypothesis: when an economy has a low outcome owing to some preexisting distortions, corruption could be a positive factor in that it offers a ""second-best world.''",ucb,,https://escholarship.org/uc/item/16g527r2,,,eng,REGULAR,0,0
68,1504,Efficient Multi-Level Modeling and Monitoring of End-use Energy Profile in Commercial Buildings,"Kang, Zhaoyi","Spanos, Costas J;",2015,"In this work, modeling and monitoring of end-use power consumption in commercial buildings are investigated through both Top-Down and Bottom-Up approaches. In the Top-Down approach, an adaptive support vector regression (ASVR) model is developed to accommodate the nonlinearity and nonstationarity of the macro-level time series, thus providing a framework for the modeling and diagnosis of end-use power consumption. In the Bottom-Up approach, an appliance-data-driven stochastic model is built to predict each end-use sector of a commercial building. Power disaggregation is studied as a technique to facilitate Bottom-Up prediction. In Bottom-Up monitoring and diagnostic detection, a new dimensionality reduction technique is explored to facilitate the analysis of multivariate binary behavioral signals in building end-uses.",ucb,,https://escholarship.org/uc/item/1867c6vm,,,eng,REGULAR,0,0
69,1505,Nations of Retailers: The Comparative Political Economy of Retail Trade,"Watson, Bartholomew Clark","Levy, Jonah;",2011,"This dissertation analyzes the development of the retail sector in the United States and Western Europe.  The predominant literature on the service sector in both economics and political science has argued that the only way to create jobs in services such as retailing is through the low-wage, high-inequality route epitomized by the United States.  Nevertheless, in the retail trade sector, a number of European countries have matched or exceeded American productivity and employment growth, despite considerably higher wage levels.  How do we explain the puzzling combination of rapid job growth and high wages in European retail?This dissertation resolves this puzzle through a cross-national comparison of the retailing strategy in three countries: the United States, Denmark, and France.  It identifies three modes of competition in retail, labeled ""lean retailing"" (US), ""relational contracting"" (Denmark), and ""vertical integration"" (France).  It shows that each approach has strengths and limitations, with none inherently more successful than the others.The first model, American lean retailing, is a cost-squeezing strategy built around scale, turnover, and low margins.  It uses dominating relationships with suppliers and workers to strip costs and retailer control over logistics to improve efficiency.  The second model, Danish relational contracting, illustrates that more collaborative relationships can produce equally efficient retailing outcomes.  Danish retailers work with workers and suppliers, finding ways to share and reduce long-term costs through worker training, improved productivity, and reduced costs from confrontation.  Finally, a third model, French vertical integration, seeks to add and capture as much value as possible throughout the distribution supply chain.  French retailers have built their own partners and brands, developing services and private label products that allow them to add value.Most explanations of retail business strategies emphasize either the imperatives of the technology available to retailers or the vicissitudes of consumer preferences or markets.  This dissertation argues, by contrast, that contemporary retailer strategies are rooted in a series of political battles fought in the 1960s.  The key to this political explanation is the embedded nature of the retail sector.  Retailers are amongst the most connected actors in political economy, with ties to numerous economic and political players, including consumers, suppliers, workers, and both local and national governments.  These connections were activated in the 1960s as a new crop of large-scale retail entrants began shifting the retail sector from shopkeepers to supermarkets.The political coalitions that emerged were a function of national structural factors, notably the power resources of the retail sector, electoral institutions, avenues of interest aggregation, and the economic organization of small shops.  These coalitions set in motion longer economic trajectories of firm management and policymaking.  Where retailers could defend their interests unilaterally, without coalition partners (US), the lean retail model took hold; where retailers forged multiple coalitions with other stakeholders (Denmark), the relational contracting model developed; and where coalitions were partial and unstable (France), vertical integration predominated.In the United States, the fragmented and decentralized political environment meant that the opposition to retailers was local and diffuse.  Consequently retailers were able to counter with unilateral political action.  This unilateral political approach set the stage for a confrontational, and ultimately dominating   lean retail strategy that uses market power and digital information as a club against suppliers and workers.In Denmark, weak retailers confronted powerful small shops, producers, and workers.  Needing support, retailers reached a broad compromise involving all of these groups that divided the gains from consumer distribution in a more stable, long-term and equitable fashion.  Under this relational contracting approach, retailers were forced to work with partners, but eventually found numerous benefits from these alliances, and have continued their cooperation long after the initial political crisis has past.  Policymaking has also continued its history of concertation, and new challenges are still tackled jointly by a broad coalition of groups.Finally, in France, retailers faced vocal and national, but disjointed opposition movements of shopkeepers and workers.  Retailers responded by forging uneasy, partial alliances, but these were constantly contested.  In this unstable political environment, retailers pursued a vertical integration strategy, seeking to maximize value by controlling and internalizing much of the production process.Analysts of the retail sector suggest that new developments, such as trans-national retailing and e-commerce (sales over the Internet) are undermining national models of retailing.  This dissertation shows, however, that retailers are largely integrating these new developments into their existing, nationally distinctive business strategies.  In the United States, retailers are using market power and fragmented politics to dominate where possible.  In Denmark, numerous partners are working collaboratively to share the gains of new opportunities.  Finally, in France, national political fights over digital commerce are reopening unresolved policy questions from the pre-digital era.  Like the previous set of political challenges facing retailers, therefore, national institutions and politics continue to mediate economic transformations and drive divergence in firm strategy, competitive advantage, and national variation in secondary outcomes such as wage equality, price levels, and patterns of technology implementation.",ucb,,https://escholarship.org/uc/item/18z1138t,,,eng,REGULAR,0,0
70,1506,"Inheritance and Inflectional Morphology: Old High German, Latin, Early New High German, and Koine Greek","LeBlanc, MaryEllen","Rauch, Irmengard;",2014,"The inheritance framework originates in the field of artificial intelligence.  It was incorporated first into theories of computational linguistics, and in the last two decades, it has been applied to theoretical linguistics.  Inheritance refers to the sharing of properties: when a group of items have a common property, each item is said to inherit this property.  The properties may be mapped in tree format with nodes arranged vertically.  The most general (i.e. the most widely shared, unmarked) properties are found at the highest nodes, and the most specific (marked) information is found at the lowest nodes.Inheritance is particularly useful when applied to inflectional morphology due to its focus on the generalizations within and across paradigms.  As such, it serves as an alternative to traditional paradigms, which may simplify the translation process; and provides a visual representation of the structure of the language's morphology.  Such a mapping also enables cross-linguistic morphological comparison. In this dissertation, I apply the inheritance framework to the nominal inflectional morphology of Old High German, Latin, Early New High German, and Koine Greek.  The corpus consists of parallel biblical passages in each language which will serve as the basis for comparison.  The trees may be used as a translation aid to those reading these texts as an accompaniment to or substitute for traditional paradigms.  Moreover, I aim to shed light on the structural similarities and differences between the four languages by means of the inheritance trees.",ucb,,https://escholarship.org/uc/item/19n1x8hk,,,eng,REGULAR,0,0
71,1507,An Integrative Approach to Data-Driven Monitoring and Control of Electric Distribution Networks,"Dobbe, Roel Ignatius Jacobus","Tomlin, Claire J.;Callaway, Duncan;",2018,"The commodification of computing, sensors, actuators, data storage and algorithms has unleashed a new wave of automation throughout society. Motivated by the promise of new capabilities, quality improvements, or efficiency gains, data-driven technologies have captured the attention and imagination of the public and many domain experts. Though opportunities are ample, the rapid introduction of data-driven functionality also triggers well-founded concerns about safeguarding critical values, such as safety, privacy and justice.In the context of operating electric distribution networks, the need for data-driven monitoring and control is explained by the irreversible transition from fossil to renewable generation and the accompanied electrification of our economy in areas like transportation and heating.The traditional fit-and-forget paradigm of designing networks conservatively for the projected peak loads assumed unidirectional power flow, predictable future demand and monotonic voltage drops, and allowed for operating at near-100\% reliability with minimal requirement for sensing and actuation. The intermittent nature of Distributed Generation (DG), its ability to feed power back to the grid and cause bidirectional power flow, and the diversifying and nonlinear behavior of electric loads are all eating away at the robustness of this approach, causing Distribution System Operators (DSOs) to put caps on the allowable DG and revisit their design and operating practice. Rather than making traditional expensive network reinforcements in often aging physical infrastructures, DSOs are trying to increase the observability and controllability of their networks by leveraging new sensing and actuation technologies and exploring the ability to use data-driven algorithms to help with the integration of more DG in a more distributed (in space and time) and cost-effective way. This dissertation works towards this vision by formulating a systematic control-theoretic approach for integrating data-driven monitoring and control in the operation of electric distribution networks. Firstly, a Bayesian approach to state estimation overcomes the constraint of limited available real-time sensors by integrating voltage forecasting. A second class of tools discussed is the use of machine learning to decentralize Optimal Power Flow (OPF) methods, by utilizing inverter-interfaced Distributed Energy Resources (DERs). The Decentralized OPF method lets each DER learn a policy that contributes to network objectives from its local historical data and measurements alone. This approach is formulated as a compression and reconstruction problem through an information-theoretic lens, providing fundamental limits of reconstruction and a strategy for optimal communication to improve learning-based reconstruction of optimal policies throughout a network.Lastly, the ambition to control networks in a distributed fashion triggers concerns about privacy-sensitive information that may be inferred from an agent's shared data. For a general class of algorithms, a new notion of local differential privacy is integrated that allows each agent to customize the protection of local information captured in constraints and objective functions.The ultimate goal of the work presented in this dissertation is to contribute to a framework for the integral and value-sensitive design and implementation of data-driven methodologies in critical infrastructure. To address the inherent cross-disciplinary nature of this larger goal, the final chapter explains how each automated decision-making tool reflects and affects values important to its stakeholders. The chapter argues that in order to enable beneficial integration of such tools, practitioners need to reflect on their epistemology and situate the design of automated decision-making in its inherently dynamic and human context.",ucb,,https://escholarship.org/uc/item/1bw112wx,,,eng,REGULAR,0,0
72,1508,"Fine-Grained Soil Liquefaction Effects in Christchurch, New Zealand","Beyzaei, Christine Zahra","Bray, Jonathan D;",2017,"Liquefaction damage from the 2010-2011 Canterbury earthquake sequence devastated parts of Christchurch, New Zealand. There were many sites where state-of-practice liquefaction assessment procedures indicated liquefaction would be expected to occur, and surface manifestations of liquefaction were observed. However, there were also numerous sites, which were predominantly silty soil sites, where state-of-practice liquefaction assessment procedures indicated that liquefaction would be expected to occur, but no surface manifestations of liquefaction were observed. This discrepancy between state-of-practice liquefaction assessments and post-earthquake liquefaction observations led to the development of the research program presented in this dissertation. Several silty soil sites were selected for investigation to further our understanding of fine-grained soil liquefaction response and to evaluate potential limitations in the current state-of-practice liquefaction assessment procedures, which are based primarily on case histories and laboratory testing of sands. This dissertation investigates the liquefaction response of silty soil sites through no-liquefaction case histories from the Canterbury earthquake sequence, evaluating depositional environment effects on observed liquefaction performance, site characterization of silty soil deposits, and laboratory testing to characterize element-scale cyclic response.       Depositional environment effects are evaluated through regional CPT-based analyses and site-specific comparisons. Stratified silty soil swamp deposits are shown to have mitigating effects on the manifestation of liquefaction beyond what can be captured by simplified liquefaction assessment procedures in Christchurch. Differing surficial geology and depositional environments are found through examining historical documents to explain in part the limitations of current liquefaction assessment procedures in the swamps of southwest Christchurch, which contain stratified silt/sand deposits or thick silt layers. Consideration of depositional environment distinguishes between liquefaction performances that could not be differentiated through the CPT-based assessment alone. CPT resolution is not sufficient to capture the thin layering at these stratified sites, and the simplified liquefaction assessment methods do not take into account the effects of the stratification on pore water pressure movement within a soil profile. Continuous sampling and careful logging of high-quality samples provides important insights on in-situ stratification at these silty soil swamp sites, discerning differences in stratigraphy resulting from differences in depositional environment.       Site investigation techniques are evaluated at the silty soil case history sites to discern their capability to characterize thin layers and groundwater table fluctuation, two potential causes for the discrepancies between state-of-practice liquefaction assessments and post-earthquake liquefaction observations. CPT, mini-CPT, sonic borings, and high-quality sampling are critiqued in terms of their ability to capture thin layer stratigraphy, which is of importance for liquefaction assessment. Piezometers, sonic borings, high-quality sampling, crosshole testing, and regional groundwater maps are evaluated to assess their ability to capture groundwater table fluctuation. CPT, mini-CPT, and conventional sonic borings offer important information for site characterization, but they do not capture full details of thin layering at silty soil sites. Detailed logging of high-quality samples captures the actual in-situ layering that helps explain limitations of simplified liquefaction assessment procedures. Use of multiple groundwater measurement methods more fully illuminate fluctuating groundwater conditions. Subsurface investigation programs should utilize tools that characterize features impacting liquefaction potential in adequate detail for the intended engineering purpose. Use of multiple, complementary investigation techniques provides the most robust assessment.       A field investigation and advanced laboratory testing program was conducted in Christchurch. High-quality samples were obtained using a Dames & Moore hydraulic fixed-piston thin-walled sampler for cyclic triaxial testing to characterize the liquefaction response of silty soils at the no-liquefaction sites in southwest Christchurch. These natural silty soil specimens contained heterogeneity and variability that should be considered and is difficult, if not impossible, to replicated with laboratory-prepared specimens. Test results for stress-strain response and axial strain accumulation indicate a nuanced range of transitional responses for these intermediate soils. Post-liquefaction reconsolidation testing shows clear differences in specimen response, ranging from ""sand-like"" immediate reconsolidation to time-dependent reconsolidation. Simplified liquefaction assessment procedures estimate significant liquefaction at these case history sites and yet no liquefaction manifestations were observed during the Canterbury earthquake sequence. Laboratory estimates of cyclic resistance (CRR) are consistent with estimates from the simplified procedures, and both estimates of CRR are well below simplified procedure estimates of seismic demand (CSR). Depositional characteristics such as thin-layering of fine sand and silt may be why manifestations of liquefaction were not observed at these sites. Post-liquefaction reconsolidation testing provides insight that water and ejecta may not accumulate in these stratified silty soils as they would accumulate in thick deposits of liquefiable clean sands. Additional mitigating factors may also contribute to the discrepancy between simplified procedure estimates of liquefaction and the lack of liquefaction observed at these sites. The interaction of several factors contributing to observed liquefaction response at these silty soil sites indicates that in-situ â€œsystemâ€ response should be considered and that further research on silty soils is warranted.",ucb,,https://escholarship.org/uc/item/0s06z6gh,,,eng,REGULAR,0,0
73,1509,Multiexponential T2 and Diffusion Magnetic Resonance Measurements of Glioma Cells,"Jackson, Pamela","McKnight, Tracy R;",2012,"Using monoexponential models, magnetic resonance (MR) parameters transverse relaxation time (T2) and apparent diffusion coefficient (ADC) have been used to nonâ€“invasively assess cell density, which characteristically increases with brain tumor malignancy. Multiexponential models of T2 and ADC may allow for a more accurate evaluation of cell density than the traditionally used monoexponential model. To better understand how cell density affects multicomponent T2 and ADC, tumor models with a range of cell densities were created by suspending astrocytoma cells in agarose at different densities. T2 was measured using a Carrâ€“Purcellâ€“Meiboomâ€“Gill (CPMG) sequence with 64 echo times. ADC was measured using a diffusionâ€“weighted sequence with 32 bâ€“values. Three models were used to fit the data and determine the T2 values, ADC values, and associated fractions: monoexponential, biexponential, nonâ€“negative least squares (NNLS). Spearman Rank was used to test the correlation with cell density. Both the monoexponential T2 and ADC were significantly negatively correlated with cell density. The biexponential model identified two T2 components, short and long. Both T2 componentsâ€™ values and fractions were significantly correlated to cell density. The biexponential model identified two ADC components, slow and fast. Both ADC componentsâ€™ values were significantly correlated with cell density, but not the fractions. The NNLS model identified up to three T2 and three ADC components. For the NNLS identified T2s, the components were labeled short, medium, and long. Both the NNLS short and medium T2 values and fractions were significantly correlated with cell density. For the NNLS identified ADCs, the components were labeled slow, intermediate, and fast. Only the fast fraction was significantly correlated with cell density.The NNLS components obtained from samples of packed cells were further evaluated by washing the samples with a gadolinium contrast agent (Gdâ€“DTPA) to shorten the T2 associated with the extracellular space. Gdâ€“DTPA did not affect the short T2, which was considered to be associated with the intracellular space. The medium T2 component was no longer identified in samples with Gdâ€“DTPA and was considered to be associated with the extracellular space. Overall, the results suggest that separately measurable components exist that could be utilized for compartment specific information.",ucb,,https://escholarship.org/uc/item/00g6d7qg,,,eng,REGULAR,0,0
74,1510,Microfluidic Microbial Fuel Cells for Microstructure Interrogations,"Parra, Erika Andrea","Lin, Liwei;",2010,"The breakdown of organic substances to retrieve energy is a naturally occurring process in nature.  Catabolic microorganisms contain enzymes capable of accelerating the disintegration of simple sugars and alcohols to produce separated charge in the form of electrons and protons as byproducts that can be harvested extracellularly through an electrochemical cell to produce electrical energy directly.  Bioelectrochemical energy is then an appealing green alternative to other power sources. However, a number of fundamental questions must be addressed if the technology is to become economically feasible. Power densities are low, hence the electron flow through the system: bacteria-electrode connectivity, the volumetric limit of catalyst loading, and the rate-limiting step in the system must be understood and optimized.  This project investigated the miniaturization of microbial fuel cells to explore the scaling of the biocatalysis and generate a platform to study fundamental microstructure effects.  Ultra-micro-electrodes for single cell studies were developed within a microfluidic configuration to quantify these issues and provide insight on the output capacity of microbial fuel cells as well as commercial feasibility as power sources for electronic devices.Several devices were investigated in this work. The first prototype consisted of a gold array anode on a silicon dioxide passivation layer that intended to imitate yet simplify the complexity of a 3D carbon structure on a 2D plane. Using Geobacter sulfurreducens, an organism believed to utilize direct electron transfer to electrodes, the 1 mm2 electrode demonstrated a maximum current density of 1.4 Î¼A and 120 nW of power after 10 days. In addition, the transient current-voltage responses were analyzed over the bacterial colonization period. The results indicated that over a 6-day period, the bacteria increased the capacitance of the cell 5-orders-of-magnitude and decreased the resistance by 3X over the bare electrode. Furthermore, over short experimental scales (hours), the RC constant was maintained but capacitance and resistance were inversely related.  As the capacitance result coincides with expected biomass increase over the incubation period, it may be possible for an electrical spectroscopy (impedance) non-invasive technique to be developed to estimate biomass on the electrode. Similarly, the R and C relationship over short experimental scales could be explored further to provide insight on biolm morphology. Lastly, fluorescence and SEM microscopy were used to observe the biofilm development and demonstrated that, rather than growing at even density, the bacteria nucleated at points on the electrode, and dendritically divided, until joining to form the ""dense"" biofilm. In addition, viable microorganisms undergoing cell division were found dozens of microns from electrode surfaces without visible pili connections.To investigate single-cell catalysis or microstructure effects, a sub-micro-liter microfluidic single-channel MFC with an embedded reference electrode and solid-state nal electron acceptor was developed. The system allowed for parallel (16) working ultra-micro-electrodes and was microscopy compatible. With Geobacter sulfurreducens, the semiconducting ITO electrodes demonstrated forward bias behavior and suitability for anodic characterization.  The first prototype demonstrated, with 179 cells on the electrode, a per cell contribution of 223 fA at +400 mV (vs. SHE). The second prototype with a 7 Î¼m diameter electrode produced a current density of 3.9 pA/Î¼m2 (3.9 A/m2) at +200 mV (vs. SHE) and a signal-to-noise ratio (SNR) of 4.9 when inoculated at a seeding density of 109 cells/mL. However, diluting the sample by 10x produced an SNR of 0.5, suggesting that obtaining single cell electron transfer rates to an electrode over short experimental time scales may not be possible with the system as tested.  Nevertheless, the platform allows microstructure characterization and multiplexing within a single microfluidic chamber.",ucb,,https://escholarship.org/uc/item/04r1g2xs,,,eng,REGULAR,0,0
75,1511,Essays in Behavioral Economics and Environmental Policy,"Sexton, Steven E.","Zilberman, David;",2012,"Social planners have long relied upon non-coercive interventions in order to achieve social welfare improvements that are not obtained by markets or direct policy. Such policies are perhaps nowhere more relevant and common than in environmental economics. Environmental goods and services are typically not traded in markets because of the difficulties of property rights assignment. And yet efforts to create markets or correct market failures by coercive policy are fraught with controversy. Thus, in addition to coercive mechanisms, social planners use information provision campaigns, appeals for cooperation, and ""nudges"" to improve the efficiency of environmental resource allocations. Non-coercive interventions have grown in popularity among social planners as behavioral economics has gained acceptance within the mainstream of the field. Indeed, such policies typically affect market outcomes and achieve environmental goals only insofar as they can exploit or correct decision making that deviates from standard theory.In this dissertation, agent behavior is analyzed to assess the potential of non-coercive interventions to achieve socially preferred environmental outcomes. In a first essay, the concept of conspicuous conservation is introduced as a modern variant of conspicuous consumption that affords status for displays of austerity meant to signal environmental preferences rather than displays of ostentation meant to signal wealth. I identify conspicuous conservation in the automobile market and estimate a willingness to pay up to several thousand dollars for the ""green"" signal transmitted by ownership of the Toyota Prius. In a second essay, I demonstrate how automatic bill payment programs can induce excessive consumption of goods and services by boundedly rational consumers who exhibit inattention to prices. As automatic payment programs have spread throughout industries characterized by recurring payments, from utility and telecommunication services to insurance and loan markets, this essay is the first to consider their implications for consumer demand and welfare. It is also the first to test empirically whether enrollment in such programs increases demand, as price salience theory suggests. It is shown that residential electricity consumption increases on average 2-4.5% due to enrollment in automatic payment programs, while commercial electricity consumption grows much as 6%. Moreover, bill-smoothing programs that utilities offer to low-income households are shown to induce an 8-9% increase in electricity consumption.A final essay examines the extent to which free transit fares and appeals for car-trip avoidance reduce car pollution on smoggy days. With data on freeway traffic volumes and transit ridership, public appeals for cooperation are shown to have no significant effect on car trip demand. Free transit fares, however, do have a significant effect on car trip demand. But the effect is perverse in that it generates an increase in car trips and related pollution. Free fares also increase transit ridership. These results suggest that free transit rides do not induce motorists to substitute to transit, but instead subsidize regular transit rides and additional trips. Appeals for cooperation also have no affect on carpooling behavior.Viewed in their totality, these essays communicate the importance of behavioral theories in formulating environmental policies and predicting agents' responses to such policies. Policies formulated without due regard for agents' bounded rationality and multifaceted motivations are doomed to unintended consequeces. However, recognition of these behavioral responses and their incorporation in policy design can result in improved environmental outcomes and efficient policies.",ucb,,https://escholarship.org/uc/item/04x0f3cc,,,eng,REGULAR,0,0
76,1512,The Organizational Weapon: Ruling Parties in Authoritarian Regimes,"Meng, Anne","Arriola, Leonardo;Powell, Robert;",2016,"This project examines party building in authoritarian regimes. The overarching puzzle I seek to address is: why are some autocratic ruling parties stronger organizations than others? What explains variation in the institutional capacity of autocratic rule? The collection of three essays in this dissertation outline the strategic logic of party institutionalization, in addition to providing new and original ways in which to measure this key concept of authoritarian party strength. It tests previously untested hypotheses about the origins of strong autocratic parties and provides insights on the conditions under which leaders will be incentivized to rule through binding institutions. The first paper conceptualizes autocratic party strength as institutionalization and provides new ways of measuring this variable. The second paper describes the strategic logic of party institutionalization in autocracies and explains why and when some autocrats choose to tie their own hands. The third paper evaluates the thesis that parties emerging out of revolutions and independence wars tend to be more durable by examining parties that emerged out of independence struggles in Africa.",ucb,,https://escholarship.org/uc/item/04x1698k,,,eng,REGULAR,0,0
77,1513,Exploring Competing Orders in the High-Tc Cuprate Phase Diagram Using Angle Resolved Photoemission Spectroscopy,"Garcia, Daniel Robert","Lanzara, Alessandra;",2010,"With more than a quarter century of study, the high temperature superconducting cuprates still represent one of the most active areas of research in condensed matter physics. Its complex phase diagram  continues to present challenges to our understanding, stemming from its correlated electronic nature. Being able to tease out the effect of different lattice orderings and their effects on electronic states may be crucial to understanding the physics of the cuprates where such  orderings may be crucial to the phase diagram. Thus, because of its ability to directly probe electronic band structure, Angle Resolved  Photoemission Spectroscopy (ARPES) is an ideal probe to study the effects of competing orders on electronicstates near EF.  This thesis will be organized in the following way. Chapter 1 provides a broad introduction to the physics central to our work including concepts of band structure and Fermi liquid theory, as well as more exotic phenomena explored throughout the thesis. Chapter 2 introduces the ARPES technique, how it is physically understood via concepts like Green's functions, and traditional methods of data analysis. Chapter 3 explores magnetic ordering and its effect on both core level and valance band states in the iron oxypnictides. From the near-EF electronic states, we find that the magnetic physics of the parent compound may still be present even at superconducting dopings. Chapter 4 explores charge density wave (CDW) ordering by looking at the rare earth ditellurides. This ARPES work establishes LaTe2 as the first quasi-2D CDW system to behave like a true Peierls transition, with both Fermi surface nesting tied to a metal - to - insulating transition. Chapter 5 explores the effectof lattice strain on electronic states by studying the single layered Bi2201 cuprates with lanthanide substitution. The effect of this substitution competes with superconductivity and appears to enhance bosonic modes acting on the nodal point states which are otherwise unaffected. Chapter 6 takes the specific case of Nd-Bi2201 and finds evidence of a distinct crossover point in the electronic states near EF segregating the nodal point states. Finally, Chapter 7 provides a summary of our work and its conclusions.",ucb,,https://escholarship.org/uc/item/04x3m7kc,,,eng,REGULAR,0,0
78,1514,Ion Transport and Structure in Polymer Electrolytes with Applications in Lithium Batteries,"Chintapalli, Mahati","Balsara, Nitash P;Minor, Andrew M;",2016,"When mixed with lithium salts, polymers that contain more than one chemical group, such as block copolymers and endgroup-functionalized polymers, are promising electrolyte materials for next-generation lithium batteries.  One chemical group can provide good ion solvation and transport properties, while the other chemical group can provide secondary properties that improve the performance characteristics of the battery.  Secondary properties of interest include non-flammability for safer lithium ion batteries and high mechanical modulus for dendrite resistance in high energy density lithium metal batteries.  Block copolymers and other materials with multiple chemical groups tend to exhibit nanoscale heterogeneity and can undergo microphase separation, which impacts the ion transport properties.  In block copolymers that microphase separate, ordered self-assembled structures occur on longer length scales.  Understanding the interplay between structure at different length scales, salt concentration, and ion transport is important for improving the performance of multifunctional polymer electrolytes.  In this dissertation, two electrolyte materials are characterized: mixtures of endgroup-functionalized, short chain perfluoropolyethers (PFPEs) and lithium bis(trifluoromethanesulfonyl) imide (LiTFSI) salt, and mixtures of polystyrene-block-poly(ethylene oxide) (PS-b-PEO; SEO) and LiTFSI.  The PFPE/LiTFSI electrolytes are liquids in which the PFPE backbone provides non-flammability, and the endgroups resemble small molecules that solvate ions.  In these electrolytes, the ion transport properties and nanoscale heterogeneity (length scale ~1 nm) are characterized as a function of endgroup using electrochemical techniques, nuclear magnetic resonance spectroscopy, and wide angle X-ray scattering.  Endgroups, especially those containing PEO segments, have a large impact on ionic conductivity, in part because the salt distribution is not homogenous; we find that salt partitions preferentially into the endgroup-rich regions.  On the other hand, the SEO/LiTFSI electrolytes are fully microphase-separated, solid, lamellar materials in which the PS block provides mechanical rigidity and the PEO block solvates the ions.  In these electrolytes longer length scale structure (~10 nm â€“ 1 Î¼m) influences ion transport.  We study the relationships between the lamellar grain size, salt concentration, and ionic conductivity using ac impedance spectroscopy, small angle X-ray scattering, electron microscopy, and finite element simulations.  In experiments, decreasing grain size is found to correlate with increasing salt concentration and increasing ionic conductivity.   Studies on both of these polymer electrolytes illustrate that structure and ion transport are closely linked.",ucb,,https://escholarship.org/uc/item/04z7w363,,,eng,REGULAR,0,0
79,1515,Essays in Applied Microeconomics,"Severnini, Edson Roberto","Card, David;",2013,"This dissertation consists of three studies analyzing causes and consequences of location decisions by economic agents in the U.S. In Chapter 1, I address the longstanding question of the extent to which the geographic clustering of economic activity may be attributable to agglomeration spillovers as opposed to natural advantages. I present evidence on this question using data on the long-run effects of large scale hydroelectric dams built in the U.S. over the 20th century, obtained through a unique comparison between counties with or without dams but with similar hydropower potential. Until mid-century, the availability of cheap local power from hydroelectric dams conveyed an important advantage that attracted industry and population. By the 1950s, however, these advantages were attenuated by improvements in the efficiency of thermal power generation and the advent of high tension transmission lines. Using a novel combination of synthetic control methods and event-study techniques, I show that, on average, dams built before 1950 had substantial short run effects on local population and employment growth, whereas those built after 1950 had no such effects. Moreover, the impact of pre-1950 dams persisted and continued to grow after the advantages of cheap local hydroelectricity were attenuated, suggesting the presence of important agglomeration spillovers. Over a 50 year horizon, I estimate that at least one half of the long run effect of pre-1950 dams is due to spillovers. The estimated short and long run effects are highly robust to alternative procedures for selecting synthetic controls, to controls for confounding factors such as proximity to transportation networks, and to alternative sample restrictions, such as dropping dams built by the Tennessee Valley Authority or removing control counties with environmental regulations. I also find small local agglomeration effects from smaller dam projects, and small spillovers to nearby locations from large dams. Lastly, I find relatively small costs of environmental regulations associated with hydroelectric licensing rules. In Chapter 2, I study the joint choice of spouse and location made by individuals at the start of their adult lives. I assume that potential spouses meet in a marriage market and decide who to marry and where they will live, taking account of varying economic opportunities in different locations and inherent preferences for living near the families of both spouses. I develop a theoretical framework that incorporates a collective model of household allocation, conditional on the choice of spouse and location, with a forward-looking model of the marriage market that allows for the potential inability of spouses to commit to a particular intra-household sharing rule. I address the issue of unobserved heterogeneity in the tastes of husbands and wives using a control-function approach that assumes there is a one-to-one mapping between unobserved preferences of the two spouses and their labor supply choices. Estimation results for young dual-career households in the 2000 Census lead to three main findings. First, I find excess sensitivity of the sharing rule that governs the allocation of resources among couples to the conditions in the location they actually choose, implying that spouses cannot fully commit to a sharing rule. Second, I show that the lack of commitment has a relatively larger effect on the share of family resources received by women. Third, I find that the failure of full commitment can explain nearly all of the gap in the interstate migration rates of single and married people in the U.S. Finally, in Chapter 3, I examine unintended consequences of environmental regulations affecting the location of power plants. I present evidence that while hydroelectric licensing rules do conserve the wilderness and the wildlife by restricting the development of hydro projects in some counties, they lead to more greenhouse gas emissions in those same locations. Such environmental regulations aimed to preserve natural ecosystems do not seem to really protect nature. Basically, land conservation regulations give rise to a replacement of hydropower, which is a renewable, non-emitting source of energy, with conventional fossil-fuel power, which is highly pollutant. Restrictions imposed by hydroelectric licensing rules might be used as leverage by electric utilities to get permits to expand thermal power generation. Each megawatt of hydropower potential that is not developed because of those regulations induces the production of the average emissions of carbon dioxide per megawatt of U.S. coal-fired power plants. Environmental regulations focusing only on the preservation of ecosystems appears to stimulate dirty substitutions within electric utilities regarding electricity generation.",ucb,,https://escholarship.org/uc/item/0554c2gv,,,eng,REGULAR,0,0
80,1516,The Development and Evolution of Floral Symmetry in the Zingiberales and Interactive Tools for Teaching Evolution (ArborEd),"Bruenn, Riva Anne","Specht, Chelsea D;",2017,"AbstractThe Development and Evolution of Floral Symmetry in the Zingiberales and Interactive Tools for Teaching Evolution (ArborEd)byRiva Anne BruennDoctor of Philosophy in Plant BiologyUniversity of California, BerkeleyProfessor Chelsea D. Specht, ChairFloral symmetry is a key innovation in the evolution of flowering plants. Zygomorphy, or single-planed symmetry, is associated with the diversification of many flowering plant lineages. The model system for floral symmetry is the snapdragon (Antirrhinum majus). In A. majus flowers, a set of TCP and MYB-related transcription factors form a core gene regulatory network necessary for zygomorphy. The genes involved in this network have been implicated in several independent transitions to zygomorphy from actinomorphy (many-planed symmetry). Although the TCP components of the symmetry network have been investigated across flowering plants, MYB-related transcription factors remain largely unstudied outside of the Asterid group containing A. majus and close relatives. Here we investigate the evolution of MYB-related genes DIVARICATA-like (DIV-like), RADIALIS-like (RAD-like), and DIVARICATA and RADIALIS INTERACTING FACTOR-like (DRIF-like) across flowering plants, and their expression patterns in the developing flowers of two zygomorphic species of the monocot order Zingiberales. We found that RAD-like and DIV-like are sister MYB-related genes which diverged before the diversification of flowering plants. Each gene contains one MYB-like domain that has been closely conserved throughout flowering plant evolution. Furthermore, we identified candidate homologs to A. majus RAD and DIV in several monocot taxa, with at least three copies of each in the Zingiberales. In the Zingiberales, RAD-like and DIV-like genes are expressed in Costus spicatus (Costaceae) and Musa basjoo (Musaceae) in patterns consistent with roles in floral symmetry. Using Reverse Transcription PCR and in situ hybridization we recovered asymmetric expression patterns for some RAD-like genes across the dorsal/ventral plane of developing flowers, and universal expression of DIV-like genes, consistent with the model known from Antirrhinum majus. We identified DRIF-like genes across flowering plants, recovering a previously undescribed duplication in eudicot DRIF Group 1 genes. Furthermore, we recovered candidate DRIF-like genes in Musa basjoo (Musaceae: Zingiberales) with expression patterns similar to those described in A. majus DRIF1 and DRIF2. Finally, we developed a tutorial for high school and college students to investigate a coevolutionary hypothesis in sharpshooters and their bacterial endosymbionts. This tool will help students understand how comparative evolutionary research is performed, and give them hands-on experience performing common analyses.",ucb,,https://escholarship.org/uc/item/01x4k6vh,,,eng,REGULAR,0,0
81,1517,"From Subjects to Citizens: American Colonial Education and Philippine Nation-Making, 1900-1934","Francisco, Adrianne","Candida Smith, Richard;",2015,"This dissertation examines the U.S. colonial state's efforts to promote Filipino national sentiment and patriotism through the public school system between 1900 and 1934. During the early years of American rule, U.S. colonial officials argued that Filipinos lacked a sense of nationality due to their linguistic and religious diversity, cultural heterogeneity, and regionalism. This perception shaped U.S. educational policy in the Philippines, leading to the creation of a curriculum that would attempt to homogenize and foster national affiliation among Filipinos. Using administrator files, Bureau of Education records, textbooks, and curricular materials collected in both the United States and the Philippines, this study reconstructs the colonial curriculum, paying special attention to English language instruction, history and civics, and vocational education. It shows that colonial education aimed to quell Filipino anti-colonial nationalism and facilitate obedience to the colonial state by casting good citizenship and â€œproperâ€ patriotism in terms of economic self-sufficiency and non-violence, and by defining national allegiance as loyalty to both the Philippines and the U.S. Its central contention is that American colonial education created a form of Philippine nationalism that would become the dominant strain of official nationalism among Filipino leaders and educators. Bringing local actors the fore, this study enlists Filipino studentsâ€™ and educatorsâ€™ writings, vernacular novels, newspapers, and Philippine education journals to examine how Filipinos, both in the colony and metropole, responded to colonial education. It finds that Filipinos reformulated colonial lessons to fit in with older strains of Filipino nationalism even as they saw their American education as a path to economic opportunity and Philippine independence. By looking at the U.S. colonial stateâ€™s promotion of a native national identity, this study contributes to and complicates current narratives of U.S. colonial education and Philippine nationalism.",ucb,,https://escholarship.org/uc/item/01x8n57g,,,eng,REGULAR,0,0
82,1518,"Mobiles, Media, and the Agency of Indian Youth","Kumar, Neha","Parikh, Tapan S;",2013,"Technologies have been and are being designed to address varied human needs. Of these, the need for physical and economic well-being is typically considered to trump the need for culture, leisure, fun, and entertainment. Research initiatives in the field of Information and Communication Technology and Development (ICTD) have been in motion to address agricultural, educational, and health care needs, among others. The need for entertainment is central even in the lives of the `have-less', my dissertation affirms. Affordable new media technologies play a critical role towards the procurement of entertainment content and the resulting production of culture. Individuals quickly learn to navigate their way around technology, also paving the way for development-friendly outcomes. It is this phenomenon that my dissertation analyzes, as it studies individual agency in the intertwining of culture (society) and new media (technology) within the larger discourse of development.I use ethnographic methods to investigate the leisure-driven appropriation of the mobile phone by youth from socioeconomically disadvantaged backgrounds in rural, small-town, and urban India. I first analyze the influx of new media and its resulting impact on folk music practices in rural Madhya Pradesh and Rajasthan. Shifting focus to the motivations that drive youth towards mobile consumption of folk and popular media, I examine the unique material affordances of new media technologies and their influence on emerging practices. I use the Actor-Network Theory (ANT) lens to draw particular attention to the notion of agency, both human and material, as I investigate the pirate media actor-network responsible for the widespread dissemination of digital media and technical skills. I then focus on the agency of urban Indian youth that leads them to build further on these skills as they negotiate various linguistic, social, and technological hurdles for engagement with social media towards a new, improved identity for themselves.",ucb,,https://escholarship.org/uc/item/01x9b6bb,,,eng,REGULAR,0,0
83,1519,A Fractured Society: The Socio-Legal Environment of Fracking in the United States,"Kluttz, Daniel N","Fligstein, Neil D;Haveman, Heather A;",2017,"This dissertation examines the relationships between law and society when encountering disruptive, risky economic activities. In doing so, it assesses how culture, politics, civil society, and powerful industry interests influence the laws and legal instruments intended to protect or benefit citizens exposed to such activities. My case is the domestic shale-energy boom brought about by â€œfracking,â€ which, over the past decade, has revolutionized the US energy economy and sparked controversy for its potentially detrimental effects on local communities and the environment. By examining sociological influences on statesâ€™ fracking regulations and revealing inequalities reinforced in individual mineral-rights leasing contracts, I span time and space to analyze the social forces that shape who wins and who loses when fracking comes to an area.The dissertation is organized around three empirical studies. In the first, I draw from theories of social movements, organizations, politics, and markets to examine how social movements, economic industries, and state institutional environments influence the decisions of states to issue new regulations governing fracking or ban it altogether. Analyzing a longitudinal dataset of 34 states at risk of fracking from 2009 to 2016, and consistent with findings from political sociology and social-movement literatures, I find that increased economic security and increased environmental movement organizational capacity in a state boost the likelihood that a state will regulate the fracking industry or even ban fracking entirely. I also find that higher potential profitability (and accordingly, potential environmental risk) for fracking in a state moderates the effects of state government ideology and resource dependence on industry. These findings support my argument that the effects of non-state actors and institutional context on the regulation of disruptive industrial activity in new markets depend, in part, on the extent of potential economic benefits and societal risks posed by the economic activity.In the second empirical chapter, I examine the political, economic, and cultural factors influencing how stringently states regulate fracking. Analyzing state fracking chemical disclosure requirements from 2009 through 2016, I find that a stateâ€™s expected chemical disclosure stringency is most positively influenced by how stringently its geographically proximate peer states regulate. Interacting economic hardship with fossil-fuel industry political influence is associated with less stringent regulation. I argue for a field theory-based approach to state-level regulation, which conceives of states as both constitutive of their own regulatory fields and embedded within broader fields, taking similarly situated states into account but susceptible to industry capture during particularly difficult economic times.Finally, in the last empirical chapter, I move from the state to the local level and investigate how social inequalities become reinforced in legal instruments. Specifically, I analyze economic disparities in a ubiquitous but understudied aspect of the fracking boom: mineral-rights lease contracts. Lease contracts represent an alternative, but no less important, way that socio-legal processes determine who stands to gain, and who stands to lose, when fracking comes to town. I analyze a unique proprietary dataset of nearly 90,000 leases in Texasâ€™s Barnett shale. I find that 1) local-community embeddedness yields expected higher payments to mineral-rights owners when compared to those who reside outside of the local community, and 2) people of color, in particular those of Hispanic/Latino ethnicity, receive significantly lower royalty terms when compared to whites, all else equal. The results hold when extended to a national-level analysis. These findings suggest that local ties can open pathways to locally sourced information and confer social capital, which can be beneficial during contract negotiations. They also support sociological theories of how social biases and categories affect economic transactions, resulting in patterned inequalities and discriminatory effects for socially disadvantaged groups. This chapter opens a new empirical domainâ€”subsurface property rightsâ€”for socio-legal studies of contracts, and it offers new theoretical directions into how social inequalities become reinforced in legal instruments.",ucb,,https://escholarship.org/uc/item/0264r1mc,,,eng,REGULAR,0,0
84,1520,Global Architects Meet the Place - Bridging the Gap through Information and Communication Technology,"Perez, Yael Valerie","Kalay, Yehuda E;Agogino, Alice M;",2013,"In this study, I examine the ability of Information and Communication Technologies (ICTs) to narrow the gap between architects, aspiring to meet the place, and local users that are part of the place. The overarching goal is to identify tools necessary for successful place-driven design, particularly in the extreme design conditions in marginalized places. International architects are often invited to design in difficult to access, marginalized places through aid-organizations or through international developers invested in these places. This scenario propagates the gap between the architect's conceptions of place and the local users' conceptions of place. The design literature provides a range of recommendations for comprehending place. Yet, as expressed by several of the architects interviewed, these commonly used design methods appear to be ineffective in marginalized places, too often leading to designs that are inappropriate. Addressing the gap with marginalized places is especially valuable given their limited resources and the impact that design projects have on human development, which I refer to as `design freedom'.In search for tools to comprehend place I take on Canter's 1977 definition of place as the overlap between physical attributes, activities, and conceptions. Through interviews with architects, designing in marginalized places, both within the non-profit and for-profit realms, I found that while Internet-based ICTs are currently used for capturing physical attributes of place they are underutilized in communicating the subjective conceptions of place. By compiling the recommended methods in the literature together with those used by architects I interviewed I identify five levels of depth of the experiences available for comprehending place: egocentric, passive, active, interactive, and immersive. My hypothesis is therefore that when designing in marginalized places, a set of technologies that communicates the breadth of place through deep experiences will equip designers with comprehensive information about the place, enabling more place-appropriate design.Participatory Action Research (PAR) methodologies were used in two case-studies of design with the Pinoleville Pomo Nation (PPN), a Native American nation located near Ukiah, California. The first case study is a reflection on action through which I evaluated both face-to-face and mediated techniques for meeting the PPN. Through this reflection I identify the most-appropriate ICTs, and assembled them to communicate the PPN's place. In the second study I assess and measure how these technologies are used in an actual design project through ParticiPlace, an international design competition that attracted 17 design teams from around the world, to work on the PPN's Living Culture Center.Through these studies I found that technologies which communicate all three elements of place - physical-attributes, activities, and conceptions - can bridge the gap between designers and place. More specifically, architects who visited the site produced, on average, the same levels of place-appropriate designs compared to those who were too far to visit it and relied solely on ICTs to experience place. I have identified social networks as a technology that enables immersion in the conceptions of place. Nevertheless, while social networks can immerse users in conceptions, several limitations, including privacy setting still hinder its professional design use in marginalized communities. Moreover, integration of social network with technologies to allow interaction with physical attributes and with activities of place is still required to make these more effective place-driven design tools. I conclude with recommendations for ICT attributes to support place-driven design with a focus on marginalized communities.",ucb,,https://escholarship.org/uc/item/02c496hg,,,eng,REGULAR,0,0
85,1521,The Impact of Sleep Deprivation on Anxiety and Affective Brain Function,"Goldstein, Andrea Nicole","Walker, Matthew P;",2014,"Recent evidence suggests there is an intimate and causal relationship between sleep and anxiety. Despite such progress, several unknowns remain. For example which factors predispose some individuals to be vulnerable to the anxiogenic impact of sleep loss while others appear to be resilient have yet to be identified. Furthermore, whether trait-anxiety, in turn, predicts the sensitivity of individuals to amplified emotional brain reactivity associated with a lack of sleep is similarly unknown. Moreover, little is currently known about the embodied interplay between peripheral and central nervous system mechanisms leading to such abnormalities of affective processing caused by sleep deprivation. Characterizing these mechanisms is necessary not only to gain a deeper understanding of the pathophysiological pathways underlying the condition of anxiety, but also for developing effective treatments for the amelioration of anxiety as well as guiding public health policy aimed at anxiety disorder prevention. Targeting these unanswered questions, this thesis combines functional and structural MRI techniques, together with high-density EEG recordings, to test the overarching hypothesis that sleep deprivation leads to dysregulation of the extended-limbic system contributing to, and interacting with, the state of anxiety. Three specific predictions emerged from this overarching hypothesis and were tested in separate experiments. First, experiment 1 confirms the hypothesis that structural brain morphology in a network of limbic brain regions predicts vulnerability to the anxiogenic impact of sleep deprivation, and that sex moderates this interaction. Second, experiment 2 provides evidence supporting the hypothesis that trait anxiety determines the degree to which sleep deprivation amplifies limbic brain reactivity during the anticipation of potentially aversive emotional experiences. Finally, results from experiment 3 affirms the prediction that, beyond central limbic brain changes, sleep deprivation additionally dysregulates peripheral, autonomic cardiac signaling in response to affective stimuli as well as decouples the normally inter-related association between central brain and peripheral nervous systems. Collectively, these results help characterize a framework in which sleep deprivation contributes to anxiety symptomology through impairments in affective processing by both the central (limbic) and peripheral (autonomic) nervous system functioning. Moreover, these data suggest that the co-morbid features of sleep disruption and altered limbic as well as autonomic function commonly reported across anxiety disorders may be causally related. Considering the continued decreases in sleep time across society and the high prevalence of anxiety disorders, these findings have significant therapeutic, clinical and public health ramifications.",ucb,,https://escholarship.org/uc/item/0569x2sd,,,eng,REGULAR,0,0
86,1522,Essays on Environmental Policy in Energy Markets,"Boomhower, Judson Paul","Borenstein, Severin;",2015,"Producing and consuming energy involves costly environmental externalities, which are addressed through a wide range of public policy interventions.  This dissertation examines three economic questions that are important to environmental regulation in energy.  The first chapter measures the effect of bankruptcy protection on industry structure and environmental outcomes in oil and gas extraction.  The second chapter measures additionality in an appliance replacement rebate program.  Finally, the third chapter focuses on the environmental impacts of subsidizing electricity production from forest-derived biomass fuels.   The first chapter measures the incentive effect of limited liability.  When liability is limited by bankruptcy, theory says that firms will take excessive environmental and public health risks.  In the long run, this ``judgment-proof problem'' may increase the share of small producers, even when there are economies of scale.  I use quasi-experimental variation in liability exposure to measure the effects of bankruptcy protection on industry structure and environmental outcomes in oil and gas extraction.  Using firm-level data on the universe of Texas oil and gas producers, I examine the introduction of an insurance mandate that reduced firms' ability to avoid liability through bankruptcy.  The policy was introduced via a quasi-randomized rollout, which allows me to cleanly identify its effects on industry structure. The insurance requirement pushed about 6% of producers out of the market immediately.  The exiting firms were primarily small and were more likely to have poor environmental records.  Among firms that remained in business, the bond requirement reduced oil production among the smallest 80% of firms by about 4% on average, which is consistent with increased internalization of environmental costs. Production by the largest 20% of firms, which account for the majority of total production, was unaffected.  Finally, environmental outcomes, including those related to groundwater contamination, also improved sharply.  These results suggest that incomplete internalization of environmental and safety costs due to bankruptcy protection is an important determinant of industry structure and safety effort in hazardous industries, with significant welfare consequences.The second chapter focuses on the importance of a regulator's inability to distinguish between households responding to a subsidy, and households doing what they would also have done in the absence of policy.  Economists have long argued that many recipients of energy-efficiency subsidies may be ``non-additional,'' getting paid to do what they would have done anyway.  Demonstrating this empirically has been difficult, however, because of endogeneity concerns and other challenges. In this paper we use a regression discontinuity analysis to examine participation in a large-scale residential energy-efficiency program. Comparing behavior just on either side of several eligibility thresholds, we find that program participation increases with larger subsidy amounts, but that most households would have participated even with much lower subsidy amounts. The large fraction of inframarginal participants means that the larger subsidy amounts are almost certainly not cost-effective. Moreover, the results imply that about half of all participants would have adopted the energy-efficient technology even with no subsidy whatsoever.Finally, the third chapter addresses consequences of renewable energy subsidies in other markets.  Electricity generated from logging residues provides a large and growing share of US renewable electricity generation.  Much of the low-value wood used by biomass power plants might otherwise be left in the field.  This increased harvest can negatively affect forest health. I investigate the supply of woody biomass fuel in Maine using a 15-year panel of prices and quantities for whole tree wood chips.  I find that doubling the price of woody biomass increases harvest by about 64%.  I also find that coal prices are a major determinant of woody biomass harvest.  This suggests that environmental policies that raise the price of coal will affect forest health.",ucb,,https://escholarship.org/uc/item/05f4r67b,,,eng,REGULAR,0,0
87,1523,"Machine Learning Techniques in Nuclear Material Detection, Drug Ranking and Video Tracking","Yang, Yan","Hochbaum, Dorit S.;",2013,"The main focus of this thesis is using machine learning and data mining techniques to solve challenging problems.  Three problems from different subject areas are discussed: nuclear material detection, drug ranking and target tracking in video sequences. The techniques of the three problems described are all based on an efficiently solvable variant of normalized cut, Normalized Cut Prime (NC').The first problem concerns detecting concealed illicit nuclear material, an important part of strategies preventing and deterring nuclear terrorism.  What makes this an extremely difficult task are physical limitations of nuclear radiation detectors (arising from energy resolutions and efficiency) and shielding materials terrorists would presumably use to surround the radioactive nuclear material and absorb some of the radiation, thereby reducing the strength of the detected signal. This means the central data analysis problem is identifying a potentially very weak signal, and distinguishing it from both background noise arising from the detector characteristics and naturally occurring environmental radiation.  We aim at enhancing the capabilities of detection with algorithmic methods specifically tailored to nuclear data. A novel graph-theory-based methodology based on NC' is used, called Supervised Normalized Cut (SNC).  This data mining method classifies measurements obtained from very low resolution plastic scintillation detectors.  The accompanying computational study, comparing SNC method with several alternative classification methods shows that in terms of accuracy, the SNC method is on par with alternative approaches, yet SNC is computationally more efficient.The second subject area is in the field of drug ranking.  This problem refers to placing in rank order, according to their effectiveness, several drugs treating the same disease, using data derived from cell images.   Current technologies use the recently developed high-throughput drug profiling (high content screening or HCS).  Despite the potential of HCS for accurate descriptions of drug profiles,   it produces a deluge of data of quantitative and multidimensional nature, posing analytical challenges in the data mining process.  Our new framework is designed to alleviate these difficulties, in the way of producing graph theoretic descriptors and automatically ordering the performance of drugs, called fractional adjusted bi-partitional score (FABS), a way of converting classification to scores.   We experimented with the FABS framework by implementing different algorithms and assessing the accuracy of results by a comparative study, which includes other four baseline methods.  The conclusion is encouraging: FABS implemented with NC' consistently outperforms other implementations of FABS and alternative methods currently used for ranking that are unrelated to FABS.   The third problem is target tracking in video sequences -- it can be framed as an unsupervised learning problem:  the goal is to delineate a target of interest in a video from background.  The tracking task is cast as a graph-cut, incorporating intensity and motion data into the formulation.  Tests on real-life benchmark videos show that the developed technique, NC-track, based on NC', is more efficient than many existing techniques, and that it delivers good quality results.",ucb,,https://escholarship.org/uc/item/05f838rg,,,eng,REGULAR,0,0
88,1524,ARTELIA GREENâ€™S & OLIVIA WILLIAMSâ€™ LEGACY: A STUDY ON THE PEDAGOGICAL PRACTICES THAT IMPROVE HEALTH FOR BLACK CHILDREN,"Johnson, Tiffani Marie","Perlstein, Daniel;",2019,"This dissertation examines the relationship between caring teaching practices and greater health outcomes for black children. Public health theory suggests that Black youth generally experienced greater levels of adversity compared to non-black youth (Schilling et al., 2007; Marie, 2016). Exposure to these frequent and/or sustained stressors without the buffering care of a supportive adult can change childrenâ€™s brains and bodies, including disrupting learning, behavior, immune systems, and even the way DNA is read and transcribed. My research examines the efficacy of critical classroom pedagogy (Duncan-Andrade & Morrell, 2008) and social design-based research (Gutierrez, 2016) as a framework to address and attenuate the impacts of toxic stressors that black youth embody.This study honors research principles grounded in care (Angelou, 1979; Noddings, 1988; Duncan-Andrade, 2006), to generate grounded theory for social transformation. This dissertation anchors data (field notes, classroom video, in-depth interviews) in order to integrate the fields of education and public health to produce ecologically valid findings that: 1) highlight and reproduce that types of teaching practices and conditions that mediate healthier children and 2) reframe our understandings of the possibilities of education.",ucb,,https://escholarship.org/uc/item/05g5p795,,,eng,REGULAR,0,0
89,1525,"The Grammaticalization of Grammatical Relations: A Typological and Historical Study Involving Kashaya Pomo, Old English, and Modern English","Gamon, David",,1997,A Contrastive Study of the Grammatical Structures of Aymara and Cuzco Kechua,ucb,,https://escholarship.org/uc/item/05g8s71b,,,eng,REGULAR,0,0
90,1526,Applying riboswitches for novel sensing and chemistry,"Truong, Johnny","Hammond, Ming C;Francis, Matthew B;",2019,"Riboswitches are cis-regulatory structured RNA elements capable of controlling expression of downstream genes by binding to small molecule ligands. These naturally evolved RNA elements possess remarkable affinity and selectivity for their small molecule ligands, high folding efficiencies, and thermostability for functioning in cellular environments.  Due to these properties, a number of riboswitch-based technologies have emerged such as riboswitch reporters, aptazymes, and RNA-based fluorescent (RBF) biosensors which all have wide applications for detection, imaging, and regulatory circuits. While riboswitch reporters and aptazymes have been robustly studied to better understand how to improve their function, there are fewer studies that expand on RBF biosensor development.  Here, novel approaches towards expanding the functional repertoire of RBF biosensors and systematically probing their properties are described.First, we show that engineering circular permutations of the riboswitch aptamer domain yields functional biosensors for S-adenosyl-L-methionine (SAM), using the SAM-I riboswitch as our model. We reveal that this design can enhance fluorescence turn-on and ligand binding affinity compared to the non-permuted topology. Expanding upon these established design principles, novel biosensors for the ligand guanidine was developed. Two novel designs were added to our existing repertoire that generated functional RBF biosensors using the architecture of the guanidine-I riboswitch. A new base-pair mutation strategy was applied on these guanidine biosensors which, resulting in modest changes to biosensor activation speeds just from single base-pair mutations. Lastly, riboswitches were explored as potent scaffolds to generate a self-labeling ribozyme.  Various natural or engineered riboswitches for the electrophilic ligand, SAM, were screened for reactivity with an analog, Hey-SAM, as a proxy to measure ribozyme activity. In collaboration with Agilent Labs, a high-throughput method was developed for probing and screening latent ribozyme activity using a microarray platform. The efforts and strategies put forth here use riboswitches outside their native context for applications in detection and catalysis further showcasing the broad utility of riboswitch-based tools.",ucb,,https://escholarship.org/uc/item/05n8k3nq,,,eng,REGULAR,0,0
91,1527,Writing the Storyteller: Folklore and Literature from Nineteenth-Century France to the Francophone World,"Gipson, Jennifer","Paige, Nicholas;",2011,"Nineteenth-century modernity, according to Walter Benjamin and other critics, kills storytelling.  Instead of treating this as a real disappearance, I consider how writers continually reinvent this death to work through historically specific questions about tradition, memory, and cultural transmission.  In nineteenth-century France, for example, the recurrent belief in the end of tradition prompted movements for folklore collection--like NapolÃ©on III's decree for the preservation of poÃ©sies populaires--as well as broad reflections about the future of cultural expressivity.  Nodier, Nerval, MÃ©rimÃ©e, and Champfleury, all combined literary creation with folklore study for the eclipse of oral tradition was, paradoxically, the very foundation of modern literature as it was coming to be defined.  Thus, Nerval appends to his Sylvie a folklore collection so as to mark the distance between the written and the oral, reaffirming literary modernity while mourning tradition.  Though far-removed from folklore, Barbey d'Aurevilly's short stories and fragmented frames that impede narrative transmission also question the very possibility of storytelling.  In addition to such formal innovations, writers also revisited earlier storytelling topoi.  In the early eighteenth century, when Antoine Galland introduced Les Mille et une nuits to the West, SchÃ©hÃ©razade's life-or-death storytelling stood as commentary on the tyranny of audience demands as the patronage system was breaking down.  But nineteenth-century writers returned to this ancient storytelling sultana to think about the demands of newspaper editors, growing readerships, and the transformation of literature into mass market entertainment.  Finally, interest in folklore fades on the mainland, but debates about preservation of traditions and ownership of cultural goods--debates once linked to France's colonial projects--become central to post-colonial Francophone literature.  Patrick Chamoiseau and other proponents of crÃ©olitÃ© spotlight the paradox of preserving Creole storytellers' legacies in writing--or in French.  Assia Djebar even intersperses her bloody tale of a modern Algerian SchÃ©hÃ©razade with fragments from Galland's eighteenth-century text, foregrounding the question of what happens to the voice and to stories after a storyteller dies.  In short, folklore has a long history of being a reference point for thinking about the very notions of literature or modernity that supposedly spell its demise.  Literary depictions of storytelling tell a story less about oral culture than about literature itself. And concern about who is no longer telling stories often reveals a deeper cultural anxiety about who is now writing or reading stories.",ucb,,https://escholarship.org/uc/item/05p5h8zd,,,eng,REGULAR,0,0
92,1528,Quasi-Variational Inequalities for Source-Expanding Hele-Shaw Problems,"DeIonno, John Adrian","Evans, Lawrence C.;",2013,"We study nonlinear partial differential equations describing Hele-Shaw flows for which the source of the fluid, which classically is at a single point, instead expands as the moving boundary uncovers new sources. This problem is reformulated as a type of quasi- variational inequality, for which we show there exists a unique weak solution. Our procedure utilizes a Baiocchi integral transform. However, unlike in traditional applications, the inequality solved by the transformed variable continues to depend on the free boundary, and thus standard theory of variational inequalities cannot be immediately applied. Instead, we develop convergent time-stepping scheme. As a further application, we generalize and study a related problem with a growing density function obeying a hard constraint on the maximum density.",ucb,,https://escholarship.org/uc/item/05z2t7br,,,eng,REGULAR,0,0
93,1529,Modern Low-Complexity Capacity-Achieving Codes For Network Communication,"Goela, Naveen","Gastpar, Michael;",2013,"Communication over unreliable, interfering networks is one of the current challenges inengineering. For point-to-point channels, Shannon established capacity results in 1948, and it took more than forty years to find coded systems approaching the capacity limit with feasible complexity. Significant research efforts have gone into extending Shannon's capacity results to networks with many partial successes. By contrast, the development of low-complexity codes for networks has received limited attention to date. The focus of this thesis is the design of capacity-achieving network codes realizable by modern signal processing circuits. For classes of networks, the following codes have been invented on the foundation of algebraic structure and probability theory: i ) Broadcast codes which achieve multi-user rates on the capacity boundary of several types of broadcast channels. The codes utilize ArÃ½kan's polarization theory of random variables, providing insight into information-theoretic concepts such as random binning, superposition coding, and Marton's construction. Reproducible experiments over block lengths n = 512, 1024, 2048 corroborate the theory; ii ) A network code which achieves the computing capacities of a countably infinite class of simple noiseless interfering networks. The code separates a network into irreducible parallel sub-networks and applies a new vector-space function alignment scheme inspired by the concept of interference alignment for channel communications. New bounds are developed to tighten the standardcut-set bound for multi-casting functions. As an additional example of low-complexity codes, reduced-dimension linear transforms and convex optimization methods are proposed for the lossy transmission of correlated sources across noisy networks. Surprisingly, simple un-coded or one-shot strategies achieve a performance which is exactly optimal in certain networks, or close to optimal in the low signal-to-noise regime relevant for sensor networks.",ucb,,https://escholarship.org/uc/item/05z6v4zg,,,eng,REGULAR,0,0
94,1530,SQUID-Detected MRI in the Limit of Zero Static Field,"Kelso, Nathan","Clarke, John;",2009,"The magnetic gradient fields used in magnetic resonance imaging (MRI) have a component which is parallel to the uniform field B0 = B0z, as well as a component perpendicular to B0.  The component parallel to B0 is used in spatial encoding.  The component perpendicular to B0, called the ``concomitant gradient,"" causes image distortions (by altering the magnitude and direction of the total field) if its magnitude approaches B0 at any point in the field of view (FOV).  In a conventional imaging sequence, the presence of the concomitant gradients limits the maximum gradient that can be used with a given B0 field or, conversely, limits the minimum B0 field that can be used with a given gradient field.This thesis describes an implementation of the so-called ``zero-field MRI"" (ZFMRI) pulse sequence, which allows for imaging in an arbitrarily low B0 field.  The ZFMRI sequence created an effective unidirectional gradient field by using a train of Ï€ pulses to average out the concomitant gradient components during encoding.  The signals were acquired using a low-transition temperature dc Superconducting QUantum Interference Device (low-Tc dc SQUID) coupled to a first-order axial gradiometer.  The experiments were carried out in a liquid helium dewar which was magnetically shielded with a single-layer mu-metal can around the outside and a superconducting Pb can contained within the helium space.  We increased the filling factor of the custom-made, double-walled Pyrex insert by placing the liquid alcohol sample, at a temperature of approximately -50Â°C, at the center of one loop of the superconducting gradiometer, which was immersed in the helium bath.Using the aforementioned sequence and apparatus, images were acquired in the limit of zero static field, using gradients of up to 100 Î¼T/m over a 23 mm FOV.  The change in field magnitude over the FOV due to gradients was up to 10 times larger than the magnitude of any static field present in the dewar (static fields arose from residual magnetic fields and were 1 Î¼T or less).  These images were free of concomitant gradient distortions.  Images encoded using aconventional imaging sequence under similar conditions were also acquired; the conventional images were irreparably distorted.The limitations of the present ZFMRI sequence implementation are considered, as well as how the procedure could be made more practical with regard to imaging time.  The extension of the technique to unshielded operation in a uniform ambient field is discussed, as are other methods of mitigating or eliminating concomitant gradient distortions.",ucb,,https://escholarship.org/uc/item/02k9c28f,,,eng,REGULAR,0,0
95,1531,From Another Psyche: The Other Consciousness of A Speculative American Mystic (The Life and Work of Jane Roberts),"Skafish, Peter William","Pandolfo, Stefania;",2011,"This dissertation attempts to develop the beginnings of a new approach to understanding the significance of modes of thought marginal and/or external to those of the modern West. I call this approach an ""anthropology of concepts"" because it examines concepts and themes belonging to scriptural, ""philosophical,"" and poetic traditions as concepts rather than, as normally happens in anthropology, in the context of social practices, historical events, or everyday life. I also call it this because it accordingly involves the close reading and interpretation of the written or oral texts in which concepts are articulated. Concepts, when treated this way, retain their capacity to bring about novel understandings of the real, and to engender thereby theoretical perspectives not attainable through more conventional interpretive means. Such an approach may be necessary if the humanities and social sciences are to continue to hold a critical perspective on a world so enclosed that gaining any distance from its basic schemes of thought has become extremely difficult.The present dissertation undertakes such an ""anthropology of concepts"" in order to elaborate what I intend to be a new theory of the psyche and consciousness. Popularly regarded as one of the founders of the New Age spirituality of the United States, Jane Roberts (1925-1984) was a ""channel"" (a kind of spirit medium) and visionary mystic who published in the 1960's and 1970's over twenty books that she understood to have been dictated or written through her by different spiritual beings, including one she called ""Seth."" Although these texts were crucial to the popularization of Western occult ideas about reincarnation, magic, and health that were at the heart of the New Age, Roberts's intellectual curiosity and background as an author of science fiction give her writings a speculative, intellectually reflexive, and even manifestly ontological tone that is reminiscent of certain mystical thinkers and that sets them apart from popular religious discourse. My engagement with Roberts' writings focuses, first of all, on the concepts she and her cohort of personalities articulated in the course of addressing what was for her the most pressing question raised by the decades she spent channeling: how could her experience during her trances of being herself and another self in the same instant of time be possible? Her answer was that such an experience--what she called ""other-consciousness""--occurs not through language but when the subject sees itself in the non-sensory, mental images of dreams and the imagination. She was right in the sense that such images, as Jean-Paul Sartre makes clear in Psychology of the Imagination, allow two aesthetic figures or persons to appear as one. My argument is that her claim is significant for showing, surprisingly enough, that contrary to what French philosophy claimed for decades, the other can be brought into and made part of consciousness without being appropriated and consciousness therefore takes a radically altered form. The baseline consciousness of oneself, that is, changes from apperception to a consciousness of oneself as both oneself and another--and even of oneself as a plurality of selves. To make this point, I read concurrently with Jane Roberts' texts the work of Deleuze, showing that she raised in her own fashion some of the same questions about being, time, and the subject as he did, but that the strange context in which she thought led her to furnish significantly different--and now for us, novel--responses to them. Given that a subject that would be at once itself and another would also be both what it actually is and what it otherwise only could have been, I furthermore show how Roberts' work allows one to rethink the Deleuzean (and by implication deconstructive) understandings of the categories of actuality and possibility and another concept--time--to which they are integrally tied. The fact that her writings provide a basis for recasting the thought of such a comprehensive philosopher on matters this fundamental is an indication, I think, of the broad value an anthropology of concepts could hold for humanistic research.",ucb,,https://escholarship.org/uc/item/02m143dp,,,eng,REGULAR,0,0
96,1532,Characterization of Complex Genetic Component Contributing to the Susceptibility for Multiple Sclerosis and Rheumatoid Arthritis,"Briggs, Farren Basil Shaw","Barcellos, Lisa F;",2010,"Autoimmune diseases (ADs) are a major public health concern, as the third most common category of disease in the US, after cancer and heart disease. As a result, ADs has become one of the most active genetic and epidemiologic research areas, however, unraveling the etiological mechanisms of ADs has proven difficult. There is strong evidence suggesting a complex genetic component contributing to all ADs. For most ADs, the prominent genetic risk locus is within the major histocompatibility complex (MHC) on chromosome 6p21.3. Unfortunately, identifying non-MHC susceptibility loci has proven difficult in these complex ADs with multigenic patterns of inheritance. Recently, through concerted international efforts, several genome-wide association (GWA) studies and subsequent replication analyses have confirmed several other AD susceptibility loci of modest effects; much of the remaining genetic variants contributing to AD susceptibility are unknown. It is clear that current approaches will be limited to identify all the complex genetic component ADs, therefore this dissertation focuses using strong epidemiological approaches and robust analytical frameworks to identify additional non-MHC genetic risk factors in two complex ADs: multiple sclerosis (MS) and rheumatoid arthritis (RA).In Chapter 1, the relationship between variation in DNA repair pathways genes and risk for MS was investigated. Univariate association testing, epistatic tests of interactions, logistic regression modeling and non-parametric Random Forests analyses were performed using genotypes from 1,343 MS cases and 1,379 healthy controls of European ancestry. A total of 485 single nucleotide polymorphisms (SNPs) within 72 genes related to DNA repair pathways, including base excision repair, nucleotide excision repair, and double strand breaks repair, were investigated. A SNP variant within GTF2H4 on 6p21.33 was significantly associated with MS (odds ratio=0.7, p=3.5 x 10-5) after accounting for multiple testing, and was not due to linkage disequilibrium with HLA-DRB1*1501. Despite clear evidence for an association between GTF2H4and MS, collectively, these results, derived from a well-powered study, do not support a strong role for variation within DNA repair pathway genes in MS.In Chapter 2, the relationship between variation within 8 candidate hypothalamic-pituitary-adrenal (HPA) axis genes and susceptibility to MS were comprehensively investigated. A total of 326 SNPs were investigated in 1,343 MS cases and 1,379 healthy controls of European ancestry using a multi-analytical strategy. Random Forests identified 8 SNPs within the corticotropin releasing hormone receptor 1 or CRHR1 locus on 17q21.31 as important predictors of MS. Based on univariate analyses: five CRHR1 variants were associated with decreased risk for disease following a conservative correction for multiple tests. Independent replication was observed in a large meta-analysis comprised of 2,624 MS cases and 7,220 healthy controls of European ancestry. The results provide strong evidence for the involvement of CRHR1 (rs242936: p=9.7 x 10-5) in MS.In Chapter 3, epistatic interactions with a well-established genetic factor (PTPN22 1858T) in a RA was investigated. The analysis consisted of four principal stages: Stage I (data reduction) - identifying candidate chromosomal regions in 292 affected sibling pairs, by predicting PTPN22 concordance using multipoint identity-by-descent probabilities and Random Forests; Stage II (extension analysis) - testing detailed genetic data within candidate chromosomal regions for epistasis with PTPN22 1858T in 677 cases and 750 controls using logistic regression; Stage III (replication analysis) - confirmation of epistatic interactions in 947 cases and 1,756 controls; Stage IV (combined analysis) - a pooled analysis including all 1,624 RA cases and 2,506 control subjects for final estimates of effect size. A total of 7 replicating epistatic interactions were identified. A SNP variant (rs7200573) within CDH13 demonstrated significant evidence for interaction (p=1.5 x 10-4) with PTPN22. There was also evidence for epistasis between PTPN22 and SNP variants within MYO3A, CEP72 and near WFDC1.The research conducted in Chapters 1 through 3 describe analytical approaches that were based on strong hypotheses, multi-stage analyses, and the use of robust non-parametric methods in tandem with conventional association testing. These chapters are scientifically important, as they contribute to our understanding of the underlying genetic architecture in two debilitating ADs (MS and RA) and provide strong methodological frameworks for investigating other chronic diseases with a complex genetic component.",ucb,,https://escholarship.org/uc/item/02m2x4jz,,,eng,REGULAR,0,0
97,1533,Context in Constructions,"Lee-Goldman, Russell",,2011,A Contrastive Study of the Grammatical Structures of Aymara and Cuzco Kechua,ucb,,https://escholarship.org/uc/item/02m6b3hx,,,eng,REGULAR,0,0
98,1534,Coping with Text Complexity in the Disciplines: Vulnerable Readers' Close Reading Practices,"Buffen, Leslie","Pearson, P. David;",2019,"Early reactions suggest that secondary teachers need support implementing the Common Core State Standards, specifically when teaching close reading strategies with complex disciplinary texts to vulnerable readers. This mixed-methods study conducted in a formative experiment paradigm (Reinking & Bradley, 2008) aimed to provide explanatory theories generated by applying a grounded theory approach to data analysis. An ethnographic case study design framed the grounded theory (Glaser & Strauss, 1967) and the formative experiment. I wanted to understand how two teachers adjusted their curriculum and instruction to create a more rigorous experience for vulnerable readers. I also sought to explore how such an approach affected the academic identities of these students. Teacher surveys, teacher interviews, student interviews, student surveys, student work, reading assessments, classroom observations, and teacher planning sessions provided evidence about how readers in two classrooms make sense of text and the strategies that support their comprehension and engagement during two curricular units that involve close reading of disciplinary texts. The units were used by students in two Special Day English classrooms at two different school sites and were co-designed by each high school teacher and myself. Reflections upon the first curricular unit informed the planning for the second curricular unit in each class. Also, I followed three students into at least one of their other disciplinary classes to understand their experiences with discipline-specific literacy instruction, both in the language arts and their disciplinary classes. Finally, I interviewed students about their in-school and out-of-school literacy practices, again to look for evidence of transfer from the units to their everyday repertoire of practices. Results indicate that both teachers, as they implemented the collaboratively planned lessons, asked predominantly open-ended questions that expected students to include textual evidence in their responses and did not have predetermined answers. This behavior was contrary to what I expected at the beginning of my study because I expected teachers might have predetermined answers. When responding to each teacherâ€™s instruction, students referenced the text in supporting the claims they developed on their own. In both classrooms, some of the studentsâ€™ academic identities improved during the study. All students reported rich relationships with text outside of school; however, only some students experienced success with reading complex disciplinary text in their English class. Overall findings suggest a positive effect of open-ended tasks that require students reference both the text and the knowledge that they bring to the task in forming arguments and applying understandings gained while reading. Future studies including a greater number of teachers from a range of disciplines who implement instruction with more students over a longer period of time would be beneficial in developing a more robust database about the power and influence of close reading practices.",ucb,,https://escholarship.org/uc/item/02w5k412,,,eng,REGULAR,0,0
99,1535,"Translating Sweetness: Type 2 Diabetes, Race, Research, and Outreach","Battle, James","Hayden, Cori;",2012,"Through the lens of Type 2 diabetes this dissertation considers race and problems of difference and risk with developments in treatment, genomic science, and the conduct of research and research priorities. Based primarily on fieldwork in New York and California, I interrogate public health notions of outreach with biotechnology and clinical research concepts of biomedical translation as synonymous practices. Institutional relationships and marketing drivers, I argue, reflect relatedness back onto the Type 2 diabetes patient through causal narratives of risk and inevitability. In effect, kinship--genetic, familial, racial, ethnic, and environmental--becomes the driver of both risk and emergent forms of bioliterary discipline.  I present a narrative of how diabetic risk became racialized over time and how African Americans became seen as a desirable research population. Arguing against biological race, I present an ethnographic example of how one such African American population, or community, emerged from particular social and political histories. Fieldwork uncovered lingering memories of the Tuskegee Experiment combined with cultural incompetency in both public health and biotechnology sectors. Further, I consider the bioethical challenges of African (American) participation in new genomic research aimed toward reducing health disparities. However, as a racial category, genetics researchers debate the precise genetic location and definition of ""Africa"" in the human genome. I suggest that the search for a pathological Africa in the human genome may deepen racial stigmatization as well as author new narratives of difference. I submit that social disparity, not biological disparity, presents the ultimate challenge to successful effective clinical translation and public health outreach.",ucb,,https://escholarship.org/uc/item/06f5s847,,,eng,REGULAR,0,0
100,1536,GB Virus Type C (HGV) and Human Immunodeficiency Virus (HIV) Co-Infection: Incidence and Impacts on Survival in a Cohort of HIV-Infected Transfusion Recipients,"Vahidnia, Farnaz","Reingold, Arthus L.;",2011,"GB virus C (GBV-C), an RNA virus closely related to hepatitis C virus (HCV), is transmitted through sexual, parenteral, and vertical routes. GBV-C is highly prevalent among patients receiving blood products and those at high risk of sexual or parenteral exposure. Unlike HCV, GBV-C replicates mainly in lymphocytes; many attempts to find an association between GBV-C infection and human disease have been unsuccessful. Therefore, donated blood is not routinely screened for GBV-C infection. In vitro and clinical studies have suggested that GBV-C co-infection may inhibit human immunodeficiency virus (HIV) replication by several different biological mechanisms. Some previous studies, but not all, have shown an association between GBV-C infection and both lower HIV viral load (VL) and better survival among HIV-infected patients.  Few studies describe predictors of acute GBV-C infection following transfusion in HIV-infected patients. Reports on survival benefits associated with co-infection after advent of highly active retroviral therapy (HAART) are inconclusive. An open question in many previous reports is the temporal relationship between GBV-C infection and HIV disease markers.  To address some of the currently unanswered questions concerning GBV-C and HIV co-infection, we used a limited access database obtained from the National Heart, Lung, and Blood Institute. The Viral Activation Transfusion Study (VATS) was a randomized controlled trial comparing leukoreduced (LR) vs. non-LR transfusions given to anemic HIV-infected transfusion-naÃ¯ve patients. Pre- and post-transfusion samples from 489 subjects were tested for GBV-C markers. We used the VATS dataset and the results of GBV-C testing to examine two hypotheses. First, we tested the hypothesis that GBV-C is transmitted to HIV-infected VATS subjects (n=294) via transfusion. We estimated the risk of acquiring GBV-C RNA per unit of blood transfused and examined the predictors of GBV-C acquisition. We found an incidence of 39 GBV-C infections per 100 person-years during follow-up in this population and an 8% increased risk of acquiring GBV-C associated with each additional unit of blood transfused, controlling for HAART status and baseline HIV VL. A lower HIV VL, use of HAART and white race were associated with an increased risk of subsequent GBV-C acquisition. Second, we examined the hypothesis that GBV-C co-infection is associated with lower mortality and lower HIV VL in 489 HIV-infected VATS subjects and in two VATS sub-cohorts. GBV-C viremia was associated with significantly lower mortality and HIV VL in unadjusted analyses. We found a non-significant trend towards lower mortality and lower HIV VL among HIV-infected VATS subjects, after adjusting for HIV risk behavior and time-updated E2 antibody, HAART status, HIV VL, and CD4 cell count. Acquisition of GBV-C was associated with lower mortality in the sub-cohort of individuals who were GBV-C RNA and antibody negative at baseline (n=294), adjusting for time-updated covariates (HR= 0.31, 95% CI 0.11, 0.86). Our results suggest high rates of GBV-C transmission by transfusion among HIV-infected subjects and an increased hazard of GBV-C acquisition with lower pre-transfusion HIV VL and current use of HAART. Our results also indicate that GBV-C viremia is associated with a trend towards lower mortality and lower HIV VL, and GBV-C acquisition via transfusion is associated with a significant reduction in mortality in HIV-infected individuals, after adjusting for HIV disease markers. These findings confirm previous reports that GBV-C infection inhibits HIV replication in vitro and in vivo.",ucb,,https://escholarship.org/uc/item/00p0412d,,,eng,REGULAR,0,0
